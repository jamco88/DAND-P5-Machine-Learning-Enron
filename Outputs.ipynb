{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run 4 times and find best combination of PCA and SKB for each Algo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "-\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "with n_splits=10 done in  11.77264152898988\n",
    "Best F1 Score:\n",
    "0.3613997114\n",
    "Best parameters:\n",
    "\tcombined__pca__n_components: 9\n",
    "\tcombined__skb__k: 5\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "with n_splits=10 done in  12.573212480744587\n",
    "Best F1 Score:\n",
    "0.0571428571429\n",
    "Best parameters:\n",
    "\tcombined__pca__n_components: 1\n",
    "\tcombined__skb__k: 6\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "with n_splits=10 done in  12.312909654171108\n",
    "Best F1 Score:\n",
    "0.276817626818\n",
    "Best parameters:\n",
    "\tcombined__pca__n_components: 1\n",
    "\tcombined__skb__k: 4\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "with n_splits=10 done in  46.6457469292086\n",
    "Best F1 Score:\n",
    "0.245952380952\n",
    "Best parameters:\n",
    "\tcombined__pca__n_components: 2\n",
    "\tcombined__skb__k: 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#ok lets try a bigger range, see how that compares.\n",
    "\n",
    "prm_grid = dict(combined__pca__n_components=range(1, 15),\n",
    "               combined__skb__k=range(1, 15))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with n_splits=10 done in  28.533104465855104\n",
    "Best F1 Score:\n",
    "0.3613997114\n",
    "Best parameters:\n",
    "\tcombined__pca__n_components: 9\n",
    "\tcombined__skb__k: 5\n",
    "\n",
    "        GAUSS NO CHANGE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with n_splits=10 done in  30.638848728105586\n",
    "Best F1 Score:\n",
    "0.0571428571429\n",
    "Best parameters:\n",
    "\tcombined__pca__n_components: 1\n",
    "\tcombined__skb__k: 6\n",
    "\n",
    "SVC terrible accyract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with n_splits=10 done in  30.044307081329862\n",
    "Best F1 Score:\n",
    "0.304949494949\n",
    "Best parameters:\n",
    "\tcombined__pca__n_components: 14\n",
    "\tcombined__skb__k: 1\n",
    "\n",
    "Dtree not bad but kinda rubbish        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with n_splits=10 done in  112.86884445540363\n",
    "Best F1 Score:\n",
    "0.245952380952\n",
    "Best parameters:\n",
    "\tcombined__pca__n_components: 2\n",
    "\tcombined__skb__k: 9\n",
    "\n",
    "Random forest not great.        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK so after doing that we have our optimum featsel parameters for each algo:\n",
    "    \n",
    "    \n",
    "    Gauss: PCA 9  SKB 5\n",
    "    SVC: PCA1 SKB 6\n",
    "    DTREE: PCA 14 SKB 1\n",
    "    Rforest: PCA 2 SKB 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "first investigation of SVC\n",
    "\n",
    "prm_grid2 = dict(combined__pca__n_components=[1],\n",
    "               combined__skb__k=[6],\n",
    "                clf__C = [0.5, 1.0, 1.5, 2.0],\n",
    "               clf__kernel = [\"rbf\", \"linear\", \"poly\", \"sigmoid\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with n_splits=10 done in  2.6441922350695677\n",
    "Best F1 Score:\n",
    "0.0904761904762\n",
    "Best parameters:\n",
    "\tclf__C: 1.5\n",
    "\tclf__kernel: 'linear'\n",
    "\tcombined__pca__n_components: 1\n",
    "\tcombined__skb__k: 6\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "second investigation of SVC\n",
    "\n",
    "set the kernel to linear\n",
    "try more values of C centered on 1.5\n",
    "try additional Parameters - class_weight\n",
    "\n",
    "\n",
    "prm_grid2 = dict(combined__pca__n_components=[1],\n",
    "               combined__skb__k=[6],\n",
    "                clf__C = [1.2, 1.4, 1.5, 1.6, 1.8],\n",
    "               clf__kernel = [\"linear\"],\n",
    "                class_weight__ = [\"balanced\", \"None\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result:\n",
    "\n",
    "with n_splits=10 done in  1.7567480686993804\n",
    "Best F1 Score:\n",
    "0.229051503192\n",
    "Best parameters:\n",
    "\tclf__C: 1.5\n",
    "\tclf__class_weight: 'balanced'\n",
    "\tclf__kernel: 'linear'\n",
    "\tcombined__pca__n_components: 1\n",
    "\tcombined__skb__k: 6\n",
    "        \n",
    "Result wasn't very good. Doesn't look like there's many other parameters to tune for SVC. SVC DISQUALIFIED'    \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "First investigation of DecsitionTree\n",
    "\n",
    "prm_grid3 = dict(combined__pca__n_components=[14],\n",
    "               combined__skb__k=[1],\n",
    "                clf__criterion=[\"gini\", \"entropy\"],\n",
    "                clf__max_features=[\"auto\", \"sqrt\", \"log2\", None],\n",
    "                clf__max_depth = [10,20,30],\n",
    "                CLF__class_weight = [\"balanced\", None],)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "First result\n",
    "\n",
    "with n_splits=10 done in  8.19087374429364\n",
    "Best F1 Score:\n",
    "0.304949494949\n",
    "Best parameters:\n",
    "\tclf__class_weight: None\n",
    "\tclf__criterion: 'gini'\n",
    "\tclf__max_depth: 10\n",
    "\tclf__max_features: None\n",
    "\tcombined__pca__n_components: 14\n",
    "\tcombined__skb__k: 1\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "try just tuning existing\n",
    "\n",
    "\n",
    "prm_grid3 = dict(combined__pca__n_components=[14],\n",
    "               combined__skb__k=[1],\n",
    "                clf__criterion=[\"gini\", \"entropy\"],\n",
    "                clf__max_features=[\"auto\", \"sqrt\", \"log2\", None],\n",
    "                clf__max_depth = [4,6, 8, 10, 12, 14],\n",
    "                CLF__class_weight = [\"balanced\", None],)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result 2: \n",
    "    \n",
    "with n_splits=10 done in  16.43763356060299\n",
    "Best F1 Score:\n",
    "0.304949494949\n",
    "Best parameters:\n",
    "\tclf__class_weight: None\n",
    "\tclf__criterion: 'gini'\n",
    "\tclf__max_depth: 6\n",
    "\tclf__max_features: None\n",
    "\tcombined__pca__n_components: 14\n",
    "\tcombined__skb__k: 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Try adding more params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prm_grid3 = dict(combined__pca__n_components=[14],\n",
    "               combined__skb__k=[1],\n",
    "                clf__criterion=[\"gini\", \"entropy\"],\n",
    "                clf__max_features=[\"auto\", \"log2\", None],\n",
    "                clf__max_depth = [4,6, 8, 10, 12, 14],\n",
    "                clf__class_weight = [\"balanced\", None],\n",
    "                clf__min_samples_split = [2, 3, 4, 5],\n",
    "                clf__splitter = [\"best\", \"random\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Result 3:\n",
    "    \n",
    "    \n",
    "with n_splits=10 done in  101.01742587821661\n",
    "Best F1 Score:\n",
    "0.344077311577\n",
    "Best parameters:\n",
    "\tclf__class_weight: 'balanced'\n",
    "\tclf__criterion: 'entropy'\n",
    "\tclf__max_depth: 8\n",
    "\tclf__max_features: None\n",
    "\tclf__min_samples_split: 4\n",
    "\tclf__splitter: 'random'\n",
    "\tcombined__pca__n_components: 14\n",
    "\tcombined__skb__k: 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-1-b9b9d0642b6e>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-1-b9b9d0642b6e>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    This is interesting - by adding in a few new options we are starting to get noticeable increases in accuracy.\u001b[0m\n\u001b[0m                                  ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "This is interesting - by adding in a few new options we are starting to get noticeable increases in accuracy. \n",
    "\n",
    "There doesn't seem to be much more in the way of relevant parameters to add. Scanning through the SKlearn documentation\n",
    "I get the feeling I've run out of easy tweaks.\n",
    "\n",
    "\n",
    "However - what if we were to mess with the\n",
    "feature selection parameters? After all, we've seen above how the addition of further parameters can alter the optimum\n",
    "setup.\n",
    "\n",
    "The first step is to strip down the existing setup so that it takes less time to run:\n",
    "    \n",
    "    \n",
    "prm_grid3 = dict(combined__pca__n_components=[14],\n",
    "               combined__skb__k=[1],\n",
    "                clf__criterion=[\"gini\", \"entropy\"],\n",
    "                clf__max_features=[\"auto\", \"log2\", None],\n",
    "                clf__max_depth = [4, 8, 12,],\n",
    "                clf__class_weight = [\"balanced\", None],\n",
    "                clf__min_samples_split = [2, 4, 6],\n",
    "                clf__splitter = [\"best\", \"random\"])    \n",
    "    \n",
    " \n",
    "DT result4\n",
    "\n",
    "\n",
    "with n_splits=10 done in  38.15422813380712\n",
    "Best F1 Score:\n",
    "0.344077311577\n",
    "Best parameters:\n",
    "\tclf__class_weight: 'balanced'\n",
    "\tclf__criterion: 'entropy'\n",
    "\tclf__max_depth: 8\n",
    "\tclf__max_features: None\n",
    "\tclf__min_samples_split: 4\n",
    "\tclf__splitter: 'random'\n",
    "\tcombined__pca__n_components: 14\n",
    "\tcombined__skb__k: 1\n",
    "\n",
    "\n",
    "Not bad - 40 seconds for each iteration means that it's practical to test out my idea.\n",
    "\n",
    "PCA was 14 and SKB was 1 - lets see what happens when we try: mixing it up a little.\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Dtree iteration 5:\n",
    "\n",
    "\n",
    "prm_grid3 = dict(combined__pca__n_components=[8,11,14],\n",
    "               combined__skb__k=[1,4,7],\n",
    "                clf__criterion=[\"gini\", \"entropy\"],\n",
    "                clf__max_features=[\"auto\", \"log2\", None],\n",
    "                clf__max_depth = [4, 8, 12,],\n",
    "                clf__class_weight = [\"balanced\", None],\n",
    "                clf__min_samples_split = [2, 4, 6],\n",
    "                clf__splitter = [\"best\", \"random\"])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DT result number 5:\n",
    "    \n",
    "with n_splits=10 done in  343.6053750030551\n",
    "Best F1 Score:\n",
    "0.378834498834\n",
    "Best parameters:\n",
    "\tclf__class_weight: 'balanced'\n",
    "\tclf__criterion: 'gini'\n",
    "\tclf__max_depth: 12\n",
    "\tclf__max_features: 'auto'\n",
    "\tclf__min_samples_split: 4\n",
    "\tclf__splitter: 'random'\n",
    "\tcombined__pca__n_components: 8\n",
    "\tcombined__skb__k: 4\n",
    "\n",
    "a not insignificant improvement, and one that seems to have made much more of an impact than our previous tunes.\n",
    "\n",
    "Let's continue our exploration by tuning thsese even further"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prm_grid3 = dict(combined__pca__n_components=[2, 4,6,8,10],\n",
    "               combined__skb__k=[2, 4, 6, 8, 10],\n",
    "                clf__criterion=[\"gini\", \"entropy\"],\n",
    "                clf__max_features=[\"auto\", \"log2\", None],\n",
    "                clf__max_depth = [4, 8, 12,],\n",
    "                clf__class_weight = [\"balanced\", None],\n",
    "                clf__min_samples_split = [2, 4, 6],\n",
    "                clf__splitter = [\"best\", \"random\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DT result 6:\n",
    "\n",
    "with n_splits=10 done in  944.5183616339232\n",
    "Best F1 Score:\n",
    "0.403865546218\n",
    "Best parameters:\n",
    "\tclf__class_weight: 'balanced'\n",
    "\tclf__criterion: 'gini'\n",
    "\tclf__max_depth: 12\n",
    "\tclf__max_features: 'auto'\n",
    "\tclf__min_samples_split: 6\n",
    "\tclf__splitter: 'random'\n",
    "\tcombined__pca__n_components: 6\n",
    "\tcombined__skb__k: 6\n",
    "\n",
    "        \n",
    "        \n",
    "Well it took 15 minutes to run but we managed to get the f1 score over 0.4\n",
    "\n",
    "One last tune. I notice that best result for max depth has been 12 but I didn't tune it last time. Let's do a quick\n",
    "check to see how adjusting that parameter alone changes the result. For this one I'm going to set everything else at\n",
    "it's best value, to reduce runtime and give us a clear comparison. \n",
    "\n",
    "prm_grid3 = dict(combined__pca__n_components=[6],\n",
    "               combined__skb__k=[6],\n",
    "                clf__criterion=[\"gini\"],\n",
    "                clf__max_features=[\"auto\"],\n",
    "                clf__max_depth = [8,9,10,11,12,13,14,15],\n",
    "                clf__class_weight = [\"balanced\"],\n",
    "                clf__min_samples_split = [6],\n",
    "                clf__splitter = [\"random\"])\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DT result 7: \n",
    "    \n",
    "with n_splits=10 done in  1.4455744123024488\n",
    "Best F1 Score:\n",
    "0.41497665733\n",
    "Best parameters:\n",
    "\tclf__class_weight: 'balanced'\n",
    "\tclf__criterion: 'gini'\n",
    "\tclf__max_depth: 9\n",
    "\tclf__max_features: 'auto'\n",
    "\tclf__min_samples_split: 6\n",
    "\tclf__splitter: 'random'\n",
    "\tcombined__pca__n_components: 6\n",
    "\tcombined__skb__k: 6\n",
    "  \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-2-822ae674269e>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-2-822ae674269e>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    Decision Tree conclusion: We managed to get the F1 - Score up from 0.3 to 0.4 through parameter tuning. Importantly, we\u001b[0m\n\u001b[0m                ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "Decision Tree conclusion: We managed to get the F1 - Score up from 0.3 to 0.4 through parameter tuning. Importantly, we\n",
    "also showed that it isn't possible to assume the optimal feature selection parameters will be those given by\n",
    "running on a blank algorithim without any tuning.\n",
    "\n",
    "This means that we could always go back to the previous classifiers\n",
    "and try out different values of PCA_n_components and Skb_K.\n",
    "\n",
    "However for now lets continue on to the randomforest classifier.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RANDOM FOREST CLASSIFIER:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "starting point is supposed to be pca- 2 and SKB 9 -but we know that that's bunk, so it makes sense to add\n",
    "a range for this.\n",
    "\n",
    "We could cut down on training time by cutting n splits down to 3 from 10, allowing us more speace to check parameters.\n",
    "However changing this at this point would make all my previous results inconsistent.\n",
    "   \n",
    "Starting Point: (Using some settings that proved successful for DT)\n",
    "\n",
    "    First we'll use these other parameters fixed to get us feature selection paramenters. Then in step two we;ll use the best feature selectin parameters\n",
    "    and try out differnet params as for step 5'\n",
    "    \n",
    "\n",
    "\n",
    "prm_grid4 = dict(combined__pca__n_components=[4,6,8,10,14],\n",
    "               combined__skb__k=[4,6,8,10,14],\n",
    "                clf__criterion=[\"gini\"],\n",
    "                clf__max_features=[\"auto\"],\n",
    "                clf__max_depth = [5,10,15,20,25],\n",
    "                clf__class_weight = [\"balanced\"],\n",
    "                clf__min_samples_split = [2, 6, 10],\n",
    "                )\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result 1: with n_splits=10 done in  226.32817968984637\n",
    "Best F1 Score:\n",
    "0.29873015873\n",
    "Best parameters:\n",
    "\tclf__class_weight: 'balanced'\n",
    "\tclf__criterion: 'gini'\n",
    "\tclf__max_depth: 5\n",
    "\tclf__max_features: 'auto'\n",
    "\tclf__min_samples_split: 6\n",
    "\tcombined__pca__n_components: 4\n",
    "\tcombined__skb__k: 10\n",
    "\n",
    "Ok, so the best combination isn't a mile off what my initial test suggested after all.  Best Pca is 4 rather than 2;\n",
    "SKB is 10 rather than 9.      \n",
    "        \n",
    "Let's set those and start expermenting with the other parameters. \n",
    "\n",
    "                clf__criterion=[\"gini\", \"entropy\"],\n",
    "                clf__max_features=[\"auto\", \"log2\", None],\n",
    "                clf__max_depth = [4, 8, 12,],\n",
    "                clf__class_weight = [\"balanced\", None],\n",
    "                clf__min_samples_split = [2, 4, 6],\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test 2:\n",
    "prm_grid4 = dict(combined__pca__n_components=[4],\n",
    "               combined__skb__k=[10],\n",
    "                clf__criterion=[\"gini\", \"entropy\"],\n",
    "                clf__max_features=[\"auto\", \"log2\", None],\n",
    "                clf__max_depth = [3, 5, 7, 9, 12],\n",
    "                clf__class_weight = [\"balanced\", None],\n",
    "                clf__min_samples_split = [4, 5, 6, 7, 8],\n",
    "                )"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "result 2:\n",
    "\n",
    "with n_splits=10 done in  181.33334529648528\n",
    "Best F1 Score:\n",
    "0.29873015873\n",
    "Best parameters:\n",
    "\tclf__class_weight: 'balanced'\n",
    "\tclf__criterion: 'gini'\n",
    "\tclf__max_depth: 5\n",
    "\tclf__max_features: 'auto'\n",
    "\tclf__min_samples_split: 6\n",
    "\tcombined__pca__n_components: 4\n",
    "\tcombined__skb__k: 10\n",
    "\n",
    "writeup:\n",
    "\n",
    "no change in overall score. This is perplexing.\n",
    "\n",
    "Criterion, Maxdepth, Maxfeatures, Min_samples split remain the same as they were\n",
    "for Dtree.\n",
    "\n",
    "\n",
    "As we did before, lets combine the two approaches. Whilst this will increase runtime, it will help us be sure of our feature selection parameters. To save time however, I'll reduce the integer parameters to only 3 possible values:\n",
    "\n",
    "the best, 2 above and 2 below.\n",
    "\n",
    "And I'll set the selection parameters to the best scores achieved in the previous run.\n",
    "\n",
    "prm_grid4 = dict(combined__pca__n_components=[2, 4, 6],\n",
    "               combined__skb__k=[8, 10, 12],\n",
    "                clf__criterion=[\"gini\"],\n",
    "                clf__max_features=[\"auto\"],\n",
    "                clf__max_depth = [3, 5, 7],\n",
    "                clf__class_weight = [\"balanced\"],\n",
    "                clf__min_samples_split = [4, 6, 8],\n",
    "                )\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result3:\n",
    "    \n",
    " with n_splits=10 done in  48.70410040137358\n",
    "Best F1 Score:\n",
    "0.308928848929\n",
    "Best parameters:\n",
    "\tclf__class_weight: 'balanced'\n",
    "\tclf__criterion: 'gini'\n",
    "\tclf__max_depth: 3\n",
    "\tclf__max_features: 'auto'\n",
    "\tclf__min_samples_split: 8\n",
    "\tcombined__pca__n_components: 2\n",
    "\tcombined__skb__k: 8\n",
    " \n",
    "\n",
    "Almost no increase in accuracy. The runtime isn't too bad however. What if we try re running this but with the categorical\n",
    "parameters tuned as well?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test 4:\n",
    "    \n",
    "    prm_grid4 = dict(combined__pca__n_components=[2, 4, 6],\n",
    "               combined__skb__k=[8, 10, 12],\n",
    "                clf__criterion=[\"gini\", \"entropy\"],\n",
    "                clf__max_features=[\"auto\", \"log2\", None],\n",
    "                clf__max_depth = [3, 5, 7],\n",
    "                clf__class_weight = [\"balanced\", None],\n",
    "                clf__min_samples_split = [4, 6, 8],\n",
    "                )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result 4:\n",
    "    \n",
    "with n_splits=10 done in  589.8879803424779\n",
    "Best F1 Score:\n",
    "0.308928848929\n",
    "Best parameters:\n",
    "\tclf__class_weight: 'balanced'\n",
    "\tclf__criterion: 'gini'\n",
    "\tclf__max_depth: 3\n",
    "\tclf__max_features: 'auto'\n",
    "\tclf__min_samples_split: 8\n",
    "\tcombined__pca__n_components: 2\n",
    "\tcombined__skb__k: 8\n",
    "\n",
    "        \n",
    "Massive increase in runtime for the same accuracy result. Perhaps Im not covering sufficient range?\n",
    "\n",
    "Try again, but with 5, 10, 15 for each parameter to get a sense of this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test5:     prm_grid4 = dict(combined__pca__n_components=[5,10,15],\n",
    "               combined__skb__k=[5, 10, 15],\n",
    "                clf__criterion=[\"gini\", \"entropy\"],\n",
    "                clf__max_features=[\"auto\", \"log2\", None],\n",
    "                clf__max_depth = [5, 10, 15],\n",
    "                clf__class_weight = [\"balanced\", None],\n",
    "                clf__min_samples_split = [5, 10, 15],\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with n_splits=10 done in  596.148160649871\n",
    "Best F1 Score:\n",
    "0.32973970474\n",
    "Best parameters:\n",
    "\tclf__class_weight: 'balanced'\n",
    "\tclf__criterion: 'gini'\n",
    "\tclf__max_depth: 5\n",
    "\tclf__max_features: 'log2'\n",
    "\tclf__min_samples_split: 15\n",
    "\tcombined__pca__n_components: 15\n",
    "\tcombined__skb__k: 15\n",
    "        \n",
    "        \n",
    "        Finally, some movement!\n",
    "        \n",
    "        let's lock in our categoricals.\n",
    "        \n",
    "        \n",
    "        each linear will have the best plus one additional value in the direction implied by this result.\n",
    "        \n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test6:     \n",
    "    \n",
    "prm_grid4 = dict(combined__pca__n_components=[15,18],\n",
    "               combined__skb__k=[15,18],\n",
    "                clf__criterion=[\"gini\"],\n",
    "                clf__max_features=[\"log2\"],\n",
    "                clf__max_depth = [3, 5],\n",
    "                clf__class_weight = [\"balanced\"],\n",
    "                clf__min_samples_split = [15,20],\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result 6:with n_splits=10 done in  9.742931556022086\n",
    "Best F1 Score:\n",
    "0.344871794872\n",
    "Best parameters:\n",
    "\tclf__class_weight: 'balanced'\n",
    "\tclf__criterion: 'gini'\n",
    "\tclf__max_depth: 3\n",
    "\tclf__max_features: 'log2'\n",
    "\tclf__min_samples_split: 15\n",
    "\tcombined__pca__n_components: 15\n",
    "\tcombined__skb__k: 15\n",
    "\n",
    "   More progress! Let's lock in everything and try the range of PCA and K once again     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test7:\n",
    "   \n",
    "prm_grid4 = dict(combined__pca__n_components=range(1,16),\n",
    "               combined__skb__k=range(1,16),\n",
    "                clf__criterion=[\"gini\"],\n",
    "                clf__max_features=[\"log2\"],\n",
    "                clf__max_depth = [3],\n",
    "                clf__class_weight = [\"balanced\"],\n",
    "                clf__min_samples_split = [15],\n",
    "                )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result 7:\n",
    "\n",
    "with n_splits=10 done in  137.1161738621413\n",
    "Best F1 Score:\n",
    "0.368124098124\n",
    "Best parameters:\n",
    "\tclf__class_weight: 'balanced'\n",
    "\tclf__criterion: 'gini'\n",
    "\tclf__max_depth: 3\n",
    "\tclf__max_features: 'log2'\n",
    "\tclf__min_samples_split: 15\n",
    "\tcombined__pca__n_components: 2\n",
    "\tcombined__skb__k: 3  \n",
    "    \n",
    "Ok we'ev increased our accuracy yet again, and also come across something quite significant. Min_Samples_split\n",
    "appears to have a significant change on what range of PCA and SKB return the best result. Let's lock in PCA and K,and\n",
    "everything else, and experiment  with Min_Sample_split.       \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test 8:\n",
    "\n",
    "prm_grid4 = dict(combined__pca__n_components=[2],\n",
    "               combined__skb__k=[3],\n",
    "                clf__criterion=[\"gini\"],\n",
    "                clf__max_features=[\"log2\"],\n",
    "                clf__max_depth = [3],\n",
    "                clf__class_weight = [\"balanced\"],\n",
    "                clf__min_samples_split = [5, 10, 14, 15, 16, 17, 20, 25, 30, 35],\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result 8:\n",
    "    \n",
    "    with n_splits=10 done in  6.093427990743294\n",
    "Best F1 Score:\n",
    "0.36924963925\n",
    "Best parameters:\n",
    "\tclf__class_weight: 'balanced'\n",
    "\tclf__criterion: 'gini'\n",
    "\tclf__max_depth: 3\n",
    "\tclf__max_features: 'log2'\n",
    "\tclf__min_samples_split: 16\n",
    "\tcombined__pca__n_components: 2\n",
    "\tcombined__skb__k: 3\n",
    "\n",
    "        \n",
    "A miniscule increase in accuracy. perhaps Min_samples isn't the key.        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "The other alternative is that I'm not looking at the correct parameters.' Let's take a step back, and see what happens\n",
    "when we include n_estimators into the mix' \n",
    "I will revert back to 5  10 15 for this one and see if we can't' blindly stagger towards a better score.\n",
    "\n",
    "The best comparison for this will be test 5.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test9:\n",
    "    \n",
    " prm_grid4 = dict(combined__pca__n_components=[5,10,15],\n",
    "               combined__skb__k=[5, 10, 15],\n",
    "                clf__criterion=[\"gini\", \"entropy\"],\n",
    "                clf__max_features=[\"auto\", \"log2\", None],\n",
    "                clf__max_depth = [5, 10, 15],\n",
    "                clf__class_weight = [\"balanced\", None],\n",
    "                clf__min_samples_split = [5, 10, 15],\n",
    "                clf__n_estimators = [5, 10, 15]\n",
    "                )    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result9 = 30 minutes later!!\n",
    "\n",
    "with n_splits=10 done in  1799.9408977995117\n",
    "Best F1 Score:\n",
    "0.397475465711\n",
    "Best parameters:\n",
    "\tclf__class_weight: 'balanced'\n",
    "\tclf__criterion: 'gini'\n",
    "\tclf__max_depth: 5\n",
    "\tclf__max_features: None\n",
    "\tclf__min_samples_split: 15\n",
    "\tclf__n_estimators: 5\n",
    "\tcombined__pca__n_components: 5\n",
    "\tcombined__skb__k: 5\n",
    "\n",
    "tune from here:\n",
    "    \n",
    "    with the following protocol\n",
    "    \n",
    "    Balanced and Gini are consistently returned as the best results so can be fixed.\n",
    "    \n",
    "    I will fix max_features at None to save time.\n",
    "    \n",
    "    Variables returning 5 will be replaced with 246\n",
    "    variables returning 15 will get 12 14 16.\n",
    "\n",
    "    This will be the last attempt to increase accuracy of this classifier.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test10:\n",
    "    \n",
    "prm_grid4 = dict(combined__pca__n_components=[2, 4, 6],\n",
    "               combined__skb__k=[2, 4, 6],\n",
    "                clf__criterion=[\"gini\"],\n",
    "                clf__max_features=[None],\n",
    "                clf__max_depth = [2, 4, 6],\n",
    "                clf__class_weight = [\"balanced\"],\n",
    "                clf__min_samples_split = [12,14,16],\n",
    "                clf__n_estimators = [2,4,6]\n",
    "                )    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result 10:\n",
    "with n_splits=10 done in  86.93282081538928\n",
    "Best F1 Score:\n",
    "0.378066378066\n",
    "Best parameters:\n",
    "\tclf__class_weight: 'balanced'\n",
    "\tclf__criterion: 'gini'\n",
    "\tclf__max_depth: 2\n",
    "\tclf__max_features: None\n",
    "\tclf__min_samples_split: 16\n",
    "\tclf__n_estimators: 6\n",
    "\tcombined__pca__n_components: 6\n",
    "\tcombined__skb__k: 4\n",
    "\n",
    "        \n",
    "Slight reduction in accuracy. Perhaps trying a 4x5 split overnight will yield better results.\n",
    "\n",
    "\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
