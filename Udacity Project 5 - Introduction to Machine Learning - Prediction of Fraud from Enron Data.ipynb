{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Machine Learning Project\n",
    "\n",
    "The purpose of this investigation is to use the exiting Enron Financial Data to build a classifier that can predict if an employee is a Person of Interest. The story of Enron needs no introduction from me and is a famous example of corporate malfeasance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\James2SxyBoogaloo\\Anaconda3\\envs\\py27\\lib\\site-packages\\sklearn\\cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import pickle\n",
    "import pandas\n",
    "import numpy as np\n",
    "sys.path.append(\"../tools/\")\n",
    "\n",
    "\n",
    "\n",
    "from feature_format import featureFormat, targetFeatureSplit\n",
    "from tester import dump_classifier_and_data\n",
    "\n",
    "with open(\"final_project_dataset.pkl\", \"r\") as data_file:\n",
    "    data_dict = pickle.load(data_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SECTION 1: INITIAL DATA EXPLORATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('The number of features is:', '21')\n",
      "The total number of PoI's in the initial dataset is 18 out of 146:\n",
      "('The total number of observations is:', '3066')\n",
      "Number of NaN's for each feature:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "bonus                         64\n",
       "deferral_payments            107\n",
       "deferred_income               97\n",
       "director_fees                129\n",
       "email_address                  0\n",
       "exercised_stock_options       44\n",
       "expenses                      51\n",
       "from_messages                 60\n",
       "from_poi_to_this_person       60\n",
       "from_this_person_to_poi       60\n",
       "loan_advances                142\n",
       "long_term_incentive           80\n",
       "other                         53\n",
       "poi                            0\n",
       "restricted_stock              36\n",
       "restricted_stock_deferred    128\n",
       "salary                        51\n",
       "shared_receipt_with_poi       60\n",
       "to_messages                   60\n",
       "total_payments                21\n",
       "total_stock_value             20\n",
       "dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TotalFeatures = len(data_dict[\"SKILLING JEFFREY K\"])\n",
    "people = len(data_dict)\n",
    "TotalObs = TotalFeatures*people\n",
    "\n",
    "print(\"The number of features is:\", str(TotalFeatures))\n",
    "    \n",
    "count = 0\n",
    "for key, value in data_dict.iteritems():\n",
    "\tif data_dict[key][\"poi\"]==1:\n",
    "\t\tcount += 1\n",
    "\n",
    "print \"The total number of PoI's in the initial dataset is {0} out of {1}:\".format(count, people)\n",
    "print(\"The total number of observations is:\", str(TotalObs))\n",
    "#are there any features with many missing values?\n",
    "#for this it's easier to make the switch from a python dictionary to a dataframe\n",
    "df = pandas.DataFrame.from_dict(list(data_dict.values()),dtype=\"float64\")\n",
    "employees = pandas.Series(list(data_dict.keys()))\n",
    "df.set_index(employees, inplace=True)\n",
    "print \"Number of NaN's for each feature:\"\n",
    "df.isnull().sum()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DATA VISUALISATION SECTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bonus</th>\n",
       "      <th>deferral_payments</th>\n",
       "      <th>deferred_income</th>\n",
       "      <th>director_fees</th>\n",
       "      <th>email_address</th>\n",
       "      <th>exercised_stock_options</th>\n",
       "      <th>expenses</th>\n",
       "      <th>from_messages</th>\n",
       "      <th>from_poi_to_this_person</th>\n",
       "      <th>from_this_person_to_poi</th>\n",
       "      <th>...</th>\n",
       "      <th>long_term_incentive</th>\n",
       "      <th>other</th>\n",
       "      <th>poi</th>\n",
       "      <th>restricted_stock</th>\n",
       "      <th>restricted_stock_deferred</th>\n",
       "      <th>salary</th>\n",
       "      <th>shared_receipt_with_poi</th>\n",
       "      <th>to_messages</th>\n",
       "      <th>total_payments</th>\n",
       "      <th>total_stock_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>METTS MARK</th>\n",
       "      <td>600000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>mark.metts@enron.com</td>\n",
       "      <td>NaN</td>\n",
       "      <td>94299.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1740.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>585062.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>365788.0</td>\n",
       "      <td>702.0</td>\n",
       "      <td>807.0</td>\n",
       "      <td>1061827.0</td>\n",
       "      <td>585062.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BAXTER JOHN C</th>\n",
       "      <td>1200000.0</td>\n",
       "      <td>1295738.0</td>\n",
       "      <td>-1386055.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6680544.0</td>\n",
       "      <td>11200.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1586055.0</td>\n",
       "      <td>2660303.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3942714.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>267102.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5634343.0</td>\n",
       "      <td>10623258.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ELLIOTT STEVEN</th>\n",
       "      <td>350000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-400729.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>steven.elliott@enron.com</td>\n",
       "      <td>4890344.0</td>\n",
       "      <td>78552.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12961.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1788391.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>170941.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>211725.0</td>\n",
       "      <td>6678735.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CORDES WILLIAM R</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>bill.cordes@enron.com</td>\n",
       "      <td>651850.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>386335.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>58.0</td>\n",
       "      <td>764.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1038185.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HANNON KEVIN P</th>\n",
       "      <td>1500000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-3117011.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>kevin.hannon@enron.com</td>\n",
       "      <td>5538001.0</td>\n",
       "      <td>34039.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1617011.0</td>\n",
       "      <td>11350.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>853064.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>243293.0</td>\n",
       "      <td>1035.0</td>\n",
       "      <td>1045.0</td>\n",
       "      <td>288682.0</td>\n",
       "      <td>6391065.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      bonus  deferral_payments  deferred_income  \\\n",
       "METTS MARK         600000.0                NaN              NaN   \n",
       "BAXTER JOHN C     1200000.0          1295738.0       -1386055.0   \n",
       "ELLIOTT STEVEN     350000.0                NaN        -400729.0   \n",
       "CORDES WILLIAM R        NaN                NaN              NaN   \n",
       "HANNON KEVIN P    1500000.0                NaN       -3117011.0   \n",
       "\n",
       "                  director_fees             email_address  \\\n",
       "METTS MARK                  NaN      mark.metts@enron.com   \n",
       "BAXTER JOHN C               NaN                       NaN   \n",
       "ELLIOTT STEVEN              NaN  steven.elliott@enron.com   \n",
       "CORDES WILLIAM R            NaN     bill.cordes@enron.com   \n",
       "HANNON KEVIN P              NaN    kevin.hannon@enron.com   \n",
       "\n",
       "                  exercised_stock_options  expenses  from_messages  \\\n",
       "METTS MARK                            NaN   94299.0           29.0   \n",
       "BAXTER JOHN C                   6680544.0   11200.0            NaN   \n",
       "ELLIOTT STEVEN                  4890344.0   78552.0            NaN   \n",
       "CORDES WILLIAM R                 651850.0       NaN           12.0   \n",
       "HANNON KEVIN P                  5538001.0   34039.0           32.0   \n",
       "\n",
       "                  from_poi_to_this_person  from_this_person_to_poi  \\\n",
       "METTS MARK                           38.0                      1.0   \n",
       "BAXTER JOHN C                         NaN                      NaN   \n",
       "ELLIOTT STEVEN                        NaN                      NaN   \n",
       "CORDES WILLIAM R                     10.0                      0.0   \n",
       "HANNON KEVIN P                       32.0                     21.0   \n",
       "\n",
       "                        ...          long_term_incentive      other  poi  \\\n",
       "METTS MARK              ...                          NaN     1740.0  0.0   \n",
       "BAXTER JOHN C           ...                    1586055.0  2660303.0  0.0   \n",
       "ELLIOTT STEVEN          ...                          NaN    12961.0  0.0   \n",
       "CORDES WILLIAM R        ...                          NaN        NaN  0.0   \n",
       "HANNON KEVIN P          ...                    1617011.0    11350.0  1.0   \n",
       "\n",
       "                  restricted_stock  restricted_stock_deferred    salary  \\\n",
       "METTS MARK                585062.0                        NaN  365788.0   \n",
       "BAXTER JOHN C            3942714.0                        NaN  267102.0   \n",
       "ELLIOTT STEVEN           1788391.0                        NaN  170941.0   \n",
       "CORDES WILLIAM R          386335.0                        NaN       NaN   \n",
       "HANNON KEVIN P            853064.0                        NaN  243293.0   \n",
       "\n",
       "                  shared_receipt_with_poi  to_messages  total_payments  \\\n",
       "METTS MARK                          702.0        807.0       1061827.0   \n",
       "BAXTER JOHN C                         NaN          NaN       5634343.0   \n",
       "ELLIOTT STEVEN                        NaN          NaN        211725.0   \n",
       "CORDES WILLIAM R                     58.0        764.0             NaN   \n",
       "HANNON KEVIN P                     1035.0       1045.0        288682.0   \n",
       "\n",
       "                  total_stock_value  \n",
       "METTS MARK                 585062.0  \n",
       "BAXTER JOHN C            10623258.0  \n",
       "ELLIOTT STEVEN            6678735.0  \n",
       "CORDES WILLIAM R          1038185.0  \n",
       "HANNON KEVIN P            6391065.0  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAEQCAYAAABLMTQcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSQX6/0ruHa0l9ZtKAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xa6b57b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x = df[[\"bonus\"]]\n",
    "y = df[[\"salary\"]]\n",
    "cpoi = df[[\"poi\"]]\n",
    "\n",
    "plt.scatter(x,y,c=cpoi)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Outlier removal - clearly there is an issue with one of the feautres. Let's find out what it is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "146"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bonus</th>\n",
       "      <th>deferral_payments</th>\n",
       "      <th>deferred_income</th>\n",
       "      <th>director_fees</th>\n",
       "      <th>email_address</th>\n",
       "      <th>exercised_stock_options</th>\n",
       "      <th>expenses</th>\n",
       "      <th>from_messages</th>\n",
       "      <th>from_poi_to_this_person</th>\n",
       "      <th>from_this_person_to_poi</th>\n",
       "      <th>...</th>\n",
       "      <th>long_term_incentive</th>\n",
       "      <th>other</th>\n",
       "      <th>poi</th>\n",
       "      <th>restricted_stock</th>\n",
       "      <th>restricted_stock_deferred</th>\n",
       "      <th>salary</th>\n",
       "      <th>shared_receipt_with_poi</th>\n",
       "      <th>to_messages</th>\n",
       "      <th>total_payments</th>\n",
       "      <th>total_stock_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>TOTAL</th>\n",
       "      <td>97343619.0</td>\n",
       "      <td>32083396.0</td>\n",
       "      <td>-27992891.0</td>\n",
       "      <td>1398517.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>311764000.0</td>\n",
       "      <td>5235198.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>48521928.0</td>\n",
       "      <td>42667589.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>130322299.0</td>\n",
       "      <td>-7576788.0</td>\n",
       "      <td>26704229.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>309886585.0</td>\n",
       "      <td>434509511.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SKILLING JEFFREY K</th>\n",
       "      <td>5600000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jeff.skilling@enron.com</td>\n",
       "      <td>19250000.0</td>\n",
       "      <td>29336.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1920000.0</td>\n",
       "      <td>22122.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6843672.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1111258.0</td>\n",
       "      <td>2042.0</td>\n",
       "      <td>3627.0</td>\n",
       "      <td>8682716.0</td>\n",
       "      <td>26093672.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LAY KENNETH L</th>\n",
       "      <td>7000000.0</td>\n",
       "      <td>202911.0</td>\n",
       "      <td>-300000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>kenneth.lay@enron.com</td>\n",
       "      <td>34348384.0</td>\n",
       "      <td>99832.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>123.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3600000.0</td>\n",
       "      <td>10359729.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14761694.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1072321.0</td>\n",
       "      <td>2411.0</td>\n",
       "      <td>4273.0</td>\n",
       "      <td>103559793.0</td>\n",
       "      <td>49110078.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FREVERT MARK A</th>\n",
       "      <td>2000000.0</td>\n",
       "      <td>6426990.0</td>\n",
       "      <td>-3367011.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>mark.frevert@enron.com</td>\n",
       "      <td>10433518.0</td>\n",
       "      <td>86987.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1617011.0</td>\n",
       "      <td>7427621.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4188667.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1060932.0</td>\n",
       "      <td>2979.0</td>\n",
       "      <td>3275.0</td>\n",
       "      <td>17252530.0</td>\n",
       "      <td>14622185.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PICKERING MARK R</th>\n",
       "      <td>300000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>mark.pickering@enron.com</td>\n",
       "      <td>28798.0</td>\n",
       "      <td>31653.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>655037.0</td>\n",
       "      <td>728.0</td>\n",
       "      <td>898.0</td>\n",
       "      <td>1386690.0</td>\n",
       "      <td>28798.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         bonus  deferral_payments  deferred_income  \\\n",
       "TOTAL               97343619.0         32083396.0      -27992891.0   \n",
       "SKILLING JEFFREY K   5600000.0                NaN              NaN   \n",
       "LAY KENNETH L        7000000.0           202911.0        -300000.0   \n",
       "FREVERT MARK A       2000000.0          6426990.0       -3367011.0   \n",
       "PICKERING MARK R      300000.0                NaN              NaN   \n",
       "\n",
       "                    director_fees             email_address  \\\n",
       "TOTAL                   1398517.0                       NaN   \n",
       "SKILLING JEFFREY K            NaN   jeff.skilling@enron.com   \n",
       "LAY KENNETH L                 NaN     kenneth.lay@enron.com   \n",
       "FREVERT MARK A                NaN    mark.frevert@enron.com   \n",
       "PICKERING MARK R              NaN  mark.pickering@enron.com   \n",
       "\n",
       "                    exercised_stock_options   expenses  from_messages  \\\n",
       "TOTAL                           311764000.0  5235198.0            NaN   \n",
       "SKILLING JEFFREY K               19250000.0    29336.0          108.0   \n",
       "LAY KENNETH L                    34348384.0    99832.0           36.0   \n",
       "FREVERT MARK A                   10433518.0    86987.0           21.0   \n",
       "PICKERING MARK R                    28798.0    31653.0           67.0   \n",
       "\n",
       "                    from_poi_to_this_person  from_this_person_to_poi  \\\n",
       "TOTAL                                   NaN                      NaN   \n",
       "SKILLING JEFFREY K                     88.0                     30.0   \n",
       "LAY KENNETH L                         123.0                     16.0   \n",
       "FREVERT MARK A                        242.0                      6.0   \n",
       "PICKERING MARK R                        7.0                      0.0   \n",
       "\n",
       "                          ...          long_term_incentive       other  poi  \\\n",
       "TOTAL                     ...                   48521928.0  42667589.0  0.0   \n",
       "SKILLING JEFFREY K        ...                    1920000.0     22122.0  1.0   \n",
       "LAY KENNETH L             ...                    3600000.0  10359729.0  1.0   \n",
       "FREVERT MARK A            ...                    1617011.0   7427621.0  0.0   \n",
       "PICKERING MARK R          ...                          NaN         NaN  0.0   \n",
       "\n",
       "                    restricted_stock  restricted_stock_deferred      salary  \\\n",
       "TOTAL                    130322299.0                 -7576788.0  26704229.0   \n",
       "SKILLING JEFFREY K         6843672.0                        NaN   1111258.0   \n",
       "LAY KENNETH L             14761694.0                        NaN   1072321.0   \n",
       "FREVERT MARK A             4188667.0                        NaN   1060932.0   \n",
       "PICKERING MARK R                 NaN                        NaN    655037.0   \n",
       "\n",
       "                    shared_receipt_with_poi  to_messages  total_payments  \\\n",
       "TOTAL                                   NaN          NaN     309886585.0   \n",
       "SKILLING JEFFREY K                   2042.0       3627.0       8682716.0   \n",
       "LAY KENNETH L                        2411.0       4273.0     103559793.0   \n",
       "FREVERT MARK A                       2979.0       3275.0      17252530.0   \n",
       "PICKERING MARK R                      728.0        898.0       1386690.0   \n",
       "\n",
       "                    total_stock_value  \n",
       "TOTAL                     434509511.0  \n",
       "SKILLING JEFFREY K         26093672.0  \n",
       "LAY KENNETH L              49110078.0  \n",
       "FREVERT MARK A             14622185.0  \n",
       "PICKERING MARK R              28798.0  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = df.sort_values(by='salary', ascending=0)\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LOCKHART EUGENE E                 2\n",
       "GRAMM WENDY L                     4\n",
       "WODRASKA JOHN                     4\n",
       "WHALEY DAVID A                    4\n",
       "SCRIMSHAW MATTHEW                 4\n",
       "THE TRAVEL AGENCY IN THE PARK     4\n",
       "WROBEL BRUCE                      4\n",
       "CHRISTODOULOU DIOMEDES            5\n",
       "WAKEHAM JOHN                      5\n",
       "CLINE KENNETH W                   5\n",
       "SAVAGE FRANK                      5\n",
       "GILLIS JOHN                       5\n",
       "LOWRY CHARLES P                   6\n",
       "YEAP SOON                         6\n",
       "GATHMANN WILLIAM D                6\n",
       "CHAN RONNIE                       6\n",
       "FUGH JOHN L                       6\n",
       "URQUHART JOHN A                   6\n",
       "WINOKUR JR. HERBERT S             6\n",
       "MENDELSOHN JOHN                   6\n",
       "MEYER JEROME J                    6\n",
       "BLAKE JR. NORMAN P                6\n",
       "PEREIRA PAULO V. FERRAZ           6\n",
       "LEMAISTRE CHARLES                 7\n",
       "WALTERS GARETH W                  7\n",
       "DUNCAN JOHN H                     7\n",
       "PRENTICE JAMES                    7\n",
       "GRAY RODNEY                       7\n",
       "NOLES JAMES L                     7\n",
       "BADUM JAMES P                     7\n",
       "                                 ..\n",
       "MCCLELLAN GEORGE                 16\n",
       "DONAHUE JR JEFFREY M             16\n",
       "THORN TERENCE H                  16\n",
       "FITZGERALD JAY L                 16\n",
       "DEFFNER JOSEPH M                 16\n",
       "SHELBY REX                       16\n",
       "BIBI PHILIPPE A                  16\n",
       "MURRAY JULIA H                   16\n",
       "GARLAND C KEVIN                  16\n",
       "CALGER CHRISTOPHER F             16\n",
       "DURAN WILLIAM D                  16\n",
       "TILNEY ELIZABETH A               16\n",
       "DIETRICH JANET R                 16\n",
       "BUCHANAN HAROLD G                16\n",
       "BLACHMAN JEREMY M                16\n",
       "RICE KENNETH D                   17\n",
       "HANNON KEVIN P                   17\n",
       "RIEKER PAULA H                   17\n",
       "BELDEN TIMOTHY N                 17\n",
       "WASAFF GEORGE                    17\n",
       "BUY RICHARD B                    17\n",
       "OLSON CINDY K                    17\n",
       "SHARP VICTORIA T                 17\n",
       "MULLER MARK S                    17\n",
       "DERRICK JR. JAMES V              18\n",
       "PIPER GREGORY F                  18\n",
       "HAEDICKE MARK E                  19\n",
       "ALLEN PHILLIP K                  19\n",
       "FREVERT MARK A                   19\n",
       "LAY KENNETH L                    19\n",
       "Length: 146, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "ps = df2.count(axis=1)\n",
    "ps.sort_values(ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\James2SxyBoogaloo\\Anaconda3\\envs\\py27\\lib\\site-packages\\ipykernel\\__main__.py:1: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "bonus                        NaN\n",
       "deferral_payments            NaN\n",
       "deferred_income              NaN\n",
       "director_fees                NaN\n",
       "email_address                NaN\n",
       "exercised_stock_options      NaN\n",
       "expenses                     NaN\n",
       "from_messages                NaN\n",
       "from_poi_to_this_person      NaN\n",
       "from_this_person_to_poi      NaN\n",
       "loan_advances                NaN\n",
       "long_term_incentive          NaN\n",
       "other                        NaN\n",
       "poi                            0\n",
       "restricted_stock             NaN\n",
       "restricted_stock_deferred    NaN\n",
       "salary                       NaN\n",
       "shared_receipt_with_poi      NaN\n",
       "to_messages                  NaN\n",
       "total_payments               NaN\n",
       "total_stock_value            NaN\n",
       "Name: LOCKHART EUGENE E, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.ix[\"LOCKHART EUGENE E\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each person will have at least 2 values in this DF that are not NaNs - their own name, and PoI. This is borne out by the check on LOCKHART. Therefore Mr Lockhart can be dropped from the data, and we need to think about what to do with \n",
    "the other employees that don't have much information.\n",
    "\n",
    "Although there are multiple employees with few datapoints, due to the small size of the dataset we want to avoid\n",
    "throwing out data unless we have good cause. Therefore I will not impose an arbitrary limit, on the minimum data points required to be included.  However this could be a good approach in different circumestances. We also know that Zero maps to NaN in this context. It is very possible that we could inadvertently deprive our algorithms of useful information, so if any points are to be excluded there must be a concrete reason for doing so. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bonus                           NaN\n",
       "deferral_payments               NaN\n",
       "deferred_income                 NaN\n",
       "director_fees                   NaN\n",
       "email_address                   NaN\n",
       "exercised_stock_options         NaN\n",
       "expenses                        NaN\n",
       "from_messages                   NaN\n",
       "from_poi_to_this_person         NaN\n",
       "from_this_person_to_poi         NaN\n",
       "loan_advances                   NaN\n",
       "long_term_incentive             NaN\n",
       "other                        362096\n",
       "poi                               0\n",
       "restricted_stock                NaN\n",
       "restricted_stock_deferred       NaN\n",
       "salary                          NaN\n",
       "shared_receipt_with_poi         NaN\n",
       "to_messages                     NaN\n",
       "total_payments               362096\n",
       "total_stock_value               NaN\n",
       "Name: THE TRAVEL AGENCY IN THE PARK, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.ix[\"THE TRAVEL AGENCY IN THE PARK\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "143"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = df2.drop({\"LOCKHART EUGENE E\"})\n",
    "df2 = df2.drop([\"TOTAL\"])\n",
    "df2 = df2.drop([\"THE TRAVEL AGENCY IN THE PARK\"])\n",
    "len(df2.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clear EDA requires the removal of Total.\n",
    "\n",
    "For good measure I threw out the Travel Agency entry as well, as this is clearly not an employee and bad data.\n",
    "\n",
    "With those adjustments made, lets do some Data Exploration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZQAAAEJCAYAAACzPdE9AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xa6b58d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = df2.total_stock_value\n",
    "y = df2.salary\n",
    "cpoi = df2.poi\n",
    "\n",
    "plt.scatter(x,y,c=cpoi)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Potentially useful features - there are clear sections where no POI's appear. This will be useful information to our\n",
    "algorithims."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZQAAAEJCAYAAACzPdE9AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nxf8Hatz5KX4N+14AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xc712160>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = df2.total_stock_value\n",
    "y = df2.bonus\n",
    "cpoi = df2.poi\n",
    "\n",
    "plt.scatter(x,y,c=cpoi)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once again we can imagine our algorithim being able to make use of this information. There isn't an immediately obvious\n",
    "correlation however."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW4AAAEQCAYAAACQip4+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nvNoAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xc9ebd68>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = df2.total_stock_value\n",
    "y = df2.loan_advances\n",
    "cpoi = df2.poi\n",
    "\n",
    "plt.scatter(x,y,c=cpoi)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Should have anticipated this result- loan advances only had 4 (non nan's) Non Zero Values in the data!'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY0AAAD8CAYAAACLrvgBAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n5z5lQBltAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xc71e358>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = df2.total_stock_value\n",
    "y = df2.director_fees\n",
    "cpoi = df2.poi\n",
    "\n",
    "plt.scatter(x,y,c=cpoi)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I am unable to explain this output however. There are 4 points on the graph, but the NaN's table showed that 20 people got director fees and 120 had a value for Total_stock_value. It seems odd that only 4 people would show up in both lists. Very confusing!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY0AAAEJCAYAAABohnsfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzt3Xd4VGX2wPHvmZ6EFjoCAooNKxoRVGxYwFXBXVR0VXZX\nRVddV9efvWPF7tqxrMKuIHZsKFgQFRAQUMEWKUoNJRBSpp/fH3ODKZMwqQPJ+TzPPBnee997z2Td\nnHnLfV9RVYwxxphUuNIdgDHGmB2HJQ1jjDEps6RhjDEmZZY0jDHGpMyShjHGmJRZ0jDGGJMySxrG\nGGNSZknDGGNMyixpGGOMSZkn3QHUt/bt22vPnj3THYYxxuxQ5s2bt15VO2zrvCaXNHr27MncuXPT\nHYYxxuxQRGR5KudZ95QxxpiUWdIwxhiTMksaxhhjUmZJwxhjTMosaWzD6qVr+eazxRRs3JLuUIwx\nJu2a3Oyp+lJUUMytf7yPxV/+iNfvJRKKMOyyEzn/7j8jIukOzxhj0sJaGlW4/69PsOiLHwgHIxRt\nLiYcjDD58SlMHTc93aEZY0zaWNJIomhzEbPenUckFC1XHiwK8coDk9MUlTHGpJ8ljSSKCkpwuZP/\nago2FDZyNMYYs/2wpJFE+65tadE6s1K5y+3ioOP2S0NExhizfbCkkYTL5eLypy/En+lDXIlBb4/P\nQ1brTEbedkaaozPGmPSx2VNVGHByDg99djuT7p/M6l/WsN+RffjTFSfTrkt2ukMzxpi0EVVNdwz1\nKicnR23BQmOMqRkRmaeqOds6z7qnjDHGpMyShjHGmJRZ0jDGGJMySxrGGGNSZknDGGNMyixpGGOM\nSZklDWOMMSmzpGGMMSZlljSMMcakzJKGMcaYlFnSMMYYkzJLGsYYY1JmScMYY0zKLGkYY4xJmSUN\nY4wxKbOkYYwxJmXbTBoi0l1EPhGRxSKySET+6ZS3FZGpIvKz8zO7TJ3rRCRXRH4UkRPKlB8kIt86\nx/4tIuKU+0XkZad8toj0LFNnpHOPn0VkZH1+eGOMMTWTSksjClypqn2A/sAlItIHuBb4SFV3Az5y\n/o1zbASwNzAYeEJE3M61ngQuAHZzXoOd8vOAfFXtDTwEjHGu1Ra4BTgE6AfcUjY5GWOMaVzbTBqq\nulpVv3bebwG+B7oCQ4EXndNeBIY574cCE1U1pKpLgVygn4h0AVqp6ixN7DE7rkKd0mu9CgxyWiEn\nAFNVdaOq5gNT+T3RGGOMaWQ1GtNwuo36ArOBTqq62jm0BujkvO8K/Fam2gqnrKvzvmJ5uTqqGgU2\nA+2quZYxxpg0SDlpiEgL4DXgclUtKHvMaTloPceWMhEZJSJzRWTuunXr0hWGMcY0eSklDRHxkkgY\n/1PV153itU6XE87PPKd8JdC9TPVuTtlK533F8nJ1RMQDtAY2VHOtclR1rKrmqGpOhw4dUvlIxhhj\naiGV2VMCPAd8r6oPljk0GSidzTQSeKtM+QhnRlQvEgPeXzldWQUi0t+55rkV6pReazjwsdN6+QA4\nXkSynQHw450yY4wxaeBJ4ZzDgHOAb0VkgVN2PXAPMElEzgOWA6cDqOoiEZkELCYx8+oSVY059S4G\nXgAygPedFySS0ngRyQU2kph9hapuFJHbgTnOeaNVdWMtP6sxxpg6ksQX+qYjJydH586dm+4wjDFm\nhyIi81Q1Z1vn2RPhxhhjUmZJwxhjTMosaRhjjEmZJQ1jjDEps6RhjDEmZZY0jDHGpMyShjHGmJRZ\n0jDGGJMySxrGGGNSZkmjDooKilm9ZC3RSDTdoRhjTKNIZe0pU0GoJMRDo57ms1dn4fa4cHvcjLrv\nHE48/9h0h2aMMQ3KWhq18OAFTzHjtVlEQhGCRSGKNhfzxOUv8NX789MdmjHGNChLGjVUuKmIGa/N\nJhyMlCsPFYeYcNfrVdQyxpimwZJGDW1aV4DH6056LO+39Y0cjTHGNC5LGjXUqUd7EntIledyu9jn\n8D3TEJExxjQeSxo15PV5Oe/uswhk+reWuVyCP9PPObecnsbIjDGm4dnsqVo45eLBdOjenpfuep31\nKzawz+F7MvK2M+i2W5d0h2aMMQ3KkkYtDTg5hwEnb3OTK2OMaVKse8oYY0zKLGkYY4xJmSUNY4wx\nKbOkYYwxJmWWNIwxxqTMkoYxxpiUWdIwxhiTMksaxhhjUmZJwxhjTMosaRhjjEmZJQ1jjDEps6Rh\njDEmZZY0jDHGpMyShjHGmJRZ0jDGGJMySxrGGGNSZknDGGNMyraZNETkeRHJE5HvypTdKiIrRWSB\n8zqxzLHrRCRXRH4UkRPKlB8kIt86x/4tIuKU+0XkZad8toj0LFNnpIj87LxG1teHNsYYUzuptDRe\nAAYnKX9IVQ9wXu8BiEgfYASwt1PnCRFxO+c/CVwA7Oa8Sq95HpCvqr2Bh4AxzrXaArcAhwD9gFtE\nJLvGn9AYY0y92WbSUNXPgI0pXm8oMFFVQ6q6FMgF+olIF6CVqs5SVQXGAcPK1HnRef8qMMhphZwA\nTFXVjaqaD0wlefIyxhjTSOoypvEPEfnG6b4qbQF0BX4rc84Kp6yr875iebk6qhoFNgPtqrlWJSIy\nSkTmisjcdevW1eEjGWOMqU5tk8aTwC7AAcBq4IF6i6gWVHWsquaoak6HDh3SGYoxxjRptUoaqrpW\nVWOqGgeeITHmALAS6F7m1G5O2UrnfcXycnVExAO0BjZUcy1jjDFpUquk4YxRlDoVKJ1ZNRkY4cyI\n6kViwPsrVV0NFIhIf2e84lzgrTJ1SmdGDQc+dsY9PgCOF5Fsp/vreKfMGGNMmni2dYKITACOAtqL\nyAoSM5qOEpEDAAWWARcCqOoiEZkELAaiwCWqGnMudTGJmVgZwPvOC+A5YLyI5JIYcB/hXGujiNwO\nzHHOG62qqQ7IG2OMaQCS+FLfdOTk5OjcuXPTHYYxxuxQRGSequZs6zx7ItwYY0zKttk91ZypKt9M\nX8xP85bQuWcH+p98EF6fN91hGWNM2ljSqEKwOMTVx41m6be/Eg1F8Aa8+DN87DVgDxZ/8QOZrTI5\n9bIhDL10CC6XNdiMMc2DJY0qTLjrdX6Zv5RwMAJANBKjZEuQmW8lxuU3r9/Cc9dPYOm3v/GvZy5K\nZ6jGGNNo7CtyFT4c9+nWhFGVUHGIaf/9jPUrNzRSVMYYk16WNKoQj8ZTOs8X8LLkm18bOBpjjNk+\nWNKowtFnHobXv+3eu2gkSqeetnSJMaZ5sKRRhXNuPo2ddu1MRosAAL4MX6VzvD4Pux24Cz326lbp\nmDHGNEU2EF6FrNZZPDX/Pma+PY+f5uTSuVdH2u3Ulsf/+TwbVm1EFQ75w0Fc+dzf0x2qMcY0Gnsi\nHFj1yxoevfQ55n/0LV6/h0F/HsiF959LRouMSueqKpvWFRDI9CU9bowxO6JUnwhv9i2Ngo1buLT/\ndRTmF6FxJRaN8eGL01n63a88POMOnF1ptxIRsju2RuOFaHQ5uLsgUrnryhhjmqJmP6Yx5flPCBeH\n0fjvLa5IKMKShcv5cfbnaHgOGt+y9ZhqmPjmG9C8/uiGoWjeIcSLnk9H6MYY0+iafdLInb+EUEk4\nyZEQy+dch+ZfhOYdSrzwMQC04C4oeRsIgxaDFsGWR9CSdxo1bmOMSYdmnzR6H9Ar6cwoNM7Ou20B\n3QKEoPAZ4iXvQslrQLDCySVo0ZONEK0xxqRXs08ag/92DP4MX7mxC68vTq+9Sth9/5IyZ5ZA0XNV\nXyhme5MbY5q+Zp80WrVryb9n3sWBx+6Ly+3Cn+Fl0PAt3DVhCRXGwEELwNUiyVUEvPs3RrjGGJNW\nzX72FEC33bpwzwc3kZh+HEXzBoBWXEbEA/4jwXsAbL6B37uoXCB+pOWVjRu0McakQbNvaZQlIoh4\nodUtQAAobWr4wNUayboIV8bJSPaT4D0YXF3AfxzS9lXEu2caIzfGmMZhLY0kXBkno+7uaOFzEP0Z\nPJ0gcDK4WgMg/sMQ/2FpjtIYYxqftTSq4tkddE3iFZ4DW+5E1w1CYyvTHZkxxqSNJY0Kvp3xPZcP\nvJHX7jyRvGWLefjKtpy2zx6c1bcH48YIobVXpTtEY4xJG+ueKmPhp4u44aS7CBWHufK+dfxrWG82\nrvUQiyZy6ytPduD7efnc83EhknQWlTHGNG3W0ihj7NXjCRUnng6fOaU1W/LdWxMGQDjoYtGcTH6a\ntyRdIRpjTFpZ0ihj+aLftr7/7O02BIvdlU8SYck39iCfMaZ5sqRRRruubbe+X7I4A6+v8pavLleA\nTj07NmZYxhiz3bCkUcY5N5+GP9MPQCTkIhIW4PfVb90eF+12assBR++dpgiNMSa9bCC8jGPPPoLi\ngmL+c9NEQsVhXC4hs1UmWzYmlkY/4Jh9uOo/l+ByWa41xjRPtnNfErFYjML8IrJaZ+LxeijcVITb\n47Kd+owxTZbt3FcHbreb1u1bbf13izZZaYzGGGO2H9bPYowxJmWWNIwxxqTMkoYxxpiUWdIwxhiT\nMksaxhhjUrbNpCEiz4tInoh8V6asrYhMFZGfnZ/ZZY5dJyK5IvKjiJxQpvwgEfnWOfZvcTblFhG/\niLzslM8WkZ5l6ox07vGziIysrw9tjDFNiYa/Jr75FuKbb0RDM2nIRylSaWm8AAyuUHYt8JGq7gZ8\n5PwbEekDjAD2duo8ISKlCzg9CVwA7Oa8Sq95HpCvqr2Bh4AxzrXaArcAhwD9gFvKJqeGMmfKfK4b\nfAcXHXgV426bxJb8woa+pTHG1Fq84H5041+hZCKUTEI3XYQW3Nxg99tm0lDVz4CNFYqHAi86718E\nhpUpn6iqIVVdCuQC/USkC9BKVWdpIgWOq1Cn9FqvAoOcVsgJwFRV3aiq+cBUKievevXyvW8yevgD\nzP1wIb8sWMbEMW9y0YFXUbS5qCFva4wxtaLRpVD8IlDC1iWPtARKJqORbxrknrUd0+ikqqud92uA\nTs77rsBvZc5b4ZR1dd5XLC9XR1WjwGagXTXXahBFm4sYd+skgsWhrWWRYIT8tZu566xH+M9NE/h2\nxveVmn2xWIyfv17Ckm+WN2iT0BhjKglNp+z6eGUOoMGPG+SWdX4iXFVVRNL611JERgGjAHbeeeda\nXeOneUvw+r2Eg5Fy5ZFghDlTFvDV+/N5/eF3OXhwX258+QpcLhcLP13EHSMeJFQSRuNKq3Ytue2N\nq+ndt1edP5MxxmyTBIAkWzjgBmmYZY9q29JY63Q54fzMc8pXAt3LnNfNKVvpvK9YXq6OiHiA1sCG\naq5ViaqOVdUcVc3p0KFDrT5Qm46tiUZiSY+VtiCCRSHmTJnPjNdmk792EzeefDeb8goo2RIkWBQi\n79f1XDXotnKtFWOMaTCB40ne0nAhgT80yC1rmzQmA6WzmUYCb5UpH+HMiOpFYsD7K6crq0BE+jvj\nFedWqFN6reHAx864xwfA8SKS7QyAH++UNYhe++xM196dQao/L1gUYtr46Uz73wziscr7bcSiMb58\na04DRWmMMb8TV1ukzUNAACQr8cIPre5APN22Vb1Wttk9JSITgKOA9iKygsSMpnuASSJyHrAcOB1A\nVReJyCRgMRAFLlHV0q/vF5OYiZUBvO+8AJ4DxotILokB9xHOtTaKyO1A6V/g0apacUC+Xl366Hn8\n66htzzpwuV3kr8mv1JUFEI3E2LR2c0OEZ4wxlUhgEHT8EsIzQGPgH4i4WjfY/baZNFT1zCoODari\n/DuBO5OUzwX2SVIeBE6r4lrPA89vK8b6smZpHoHMAMGiYJXnBLL8nPDXo/F4Pbzz1FRKCsuf63K7\n2O/IPg0dqjHGbCWuFhAY0ij3sqXRy2jXtS1SRYedy+XC6/dw9IjDGXByDqrKbgfuwo9zcwkVh4FE\nQjnkDwfZQLgxpsmypFHG/kf1oVXbloSKQsTjvw8ueXwezrh6KEeeNoBe+/YAQES458Mbee/Zj5g2\nbjpur5sh5w3iuHOPTFf4xhjT4GznvgrWLl/H6NMeYOl3v+JyuWiRncW14/7BAUdX6lkztbBp3Wam\nT5pJyZYSck44wFplxmwnUt25z5JGFdav3ECwOEzX3p1xlsmqMY0Xo8XjIfgOSADJPBMCw5Cq+sCa\nuNnvfc3tpz8Ampgw4PG5OeasgVzx9IW1/h0bY+qHbfdaR+27tgMgGolSXFBCi+wsXK7U/9irhtGN\nZ0J0CZB4bkMLfoLwbKT1mIYIebsWKglx54iHto7/QGJ68icTPuewYf045MQD0xidMSZVzfMrbwpi\nsRjPXDOeU1qdw2mdz2dYm5FMfqoGj4kEP4TockoTBuCsCfMeGl1S7/Fu7xZ+uhhxVW5NBItCTB0/\nPQ0RGWNqw5JGFZ6+8kUm3T+ZSChKPBanpDDIoxc/y9tPfZhSfQ1/ARQnOeKC8Lx6jXVHUG03aBPr\nIjWmKbOkkUQ0EuWtJz5I+nT+2KvHV1s3HIowddx07r5gM8/c3pWVS33lTxAXuNrXY7Q7hv2P2huN\nV/6Fur1uNq3dzOQnPqCksCQNkRljasKSRhJFm4uJRysvEQIQLAwSjUSTHispLOHSftfy70ue4dNX\n1/Hms+34+7F7MHtaS+cMAckE/8AGinz7Fcj0c/1Ll+PP8OELeLd2VWlMWTh9Mc9cM56/9bmc/LWb\n0hypMaY6ljSSaNm2RbVrUCXrmwd467EprPx5DcGixDhGNCKESlzcd1kPYtEAuHdB2v6XxLqMNReP\nx/n1h5WsWZa37ZO3Q/1POojxSx7ngjHn0Lp9KyDxmSAxtpG/ZjP/uWliOkM0xmyDJY0kXC4X+w7c\nK+mxfQfuhdudbCli+HTSl4SD4Url0WgGy1Y/iavD+4inds8lLPx0EWftfBGXHHwN5+19BaP2v5KV\nuau3XXE7k92pDcf8+XAKN1Xe2CoWjfHlm7bYY2PSyCLim68hvvEvxAufR+O2U6WpniWNKtz+1jV0\n6tFh6/MDLpfQvms2N036V5V1Aln+pOXxOGS0rv1DbOtWbODGk+9mw6p8gkUhwiVhln33G1cedQux\naPLl3LdnXp+nysFvX4a3kaNpvuIlb6MbzoSStyD8JRQ+jG4YisYL0h2a2Y5Z0kgiHo/z8r1vkZ+3\nGY/PjdfnYdCfBzJ+6ZNkd2pTZb1TLh5cKXGICJ16dKDb7jvVOp4p//mYWIUxFlWlZEuQuR8urPV1\n0yWjRQZ9j9kXt7d8i82X4ePEC45NU1TNi2oYCm4BgkDpf1tBiK1Fi16spqZp7ixpJDHxnjd4/ZH3\nCJeEiYSiRMJRZrw2m/efnVZtvaNHHMZx5x6JL+Alo0WAjJYZtNspm9FvXVOnePJ+XU8kVHkZ9lgs\nzoZV+XW6drpc9cIldO3dmYwWAQItAvgzffQ9Zh/OuHpoukNrHqI/VnEgDKGpjRqK2bHYMiIVqCqn\ntvsLRZsqP2PRoVs7Xvr1qW1eY/XStSz64kfadm7D/kfvXeUYSKo+fmkGD100lmCFZdh9GT6emDuG\nHns1zGYrDU1V+XbG96xdto7efXtuXQzSNDyNLkfXn0yipVGBrz+utuMaPSaTXraMSC3FY3GKNyd7\nKA/yU9xcqUuvTnTp1aneYho4vD8Tx7zJyp9Xb934yZ/p57BhB++wCQMSXXf7HdEHjkh3JM2PeHqg\nnl2cFkfZcbEMJPPcdIVldgDWPVWB2+OmcxV/8Hvu2z1peUPz+rw88sUdnHndqey8V1d69+3F3x8c\nydUvXpqWeEzTINlPgbtn4tkhaQH4IetvSMDGlUzVrHsqiVnvzOOOMx4kVPL79Fl/ho87372e/Y/a\nu64hGrPdUFWILoL4evDuh7japjskkyapdk9ZSyOJ/icdxB3vXMc+A/ekTcfWHHDMPtw77WZLGKbJ\nERHEuw/iP8oShkmJjWlU4YCj97GNl4wxpgJLGmUkmuo/AFHw9EGkbrOejDGmqbGk4dDIYjT/76Cb\nSSw85YM2DyP+AekOzRhjthuWNADVEnTjuaBll08oQjddBO2nIe4O27zGkm+W88NXubTv2paDjt+v\nzs9mGGPM9siSBkDwI8rPVXdoHC2ZjLQ4r8qqsWiM0ac/wLwPFyIILreLrDaZPDh9NJ17dmy4mI0x\nJg1s9hRAfCNo5WU6IATxddVWffOx95n34UJCxWGCxSGKt5SwYeVG7hjxUMPEaowxaWRJA8B3MEl/\nFZKJ+PtXW/XdsVMJFZdfDj0eV5YsXM7GNTvmulDGGFMVSxqAePeCwHEgGUBi1e4f5mfz3kt7MX9G\n9taNgpKJhJLv4icuqfKYMcbsqGxMwyGt74PgZIIbXubGM6P8NN+N4sLlup92O2Xz4PTRSZdFP/L0\nAbz+8LuVEkTr9i1p1b5lpfNrQlVZtug3ijYXs9uBvfBnJN+vwxhjGou1NBwiLiRjGOMeGcJ3s1wE\ni2OEisOUFAZZ9ctaHjj/yaT1zrz2VDr37EigRQAAlzuxadPm9Vs4reN5PHf9/6ptqVRlzbI8zt/n\nCi4bcD03/OEuhnc6nw9e/KT2H9AYY+qBrT1VwZDAmUTDlbuV3B43b21+EV9AoeRdNDIX3D2RjOFE\noq347JWZvP7v91i6cBnRyO8zsfyZfkbedjqnXXlKlfcs2lzEf26ayCcTvwCFo0YcylfvzSdv+Tri\ncS1zLR8PfDqaPXJ2rfXnM8aYZGztqRpa/v0Krjnh9qQJAxK7+UXDG9H1J6IFo6HkNSh8DF1/LF7X\njxx79hGsWbK2XMIACBWHmHTfW1XeNxaLccURN/PeM9MoWL+Fgg1beHfsNNYuK58wAMLBCJMfn1L3\nD2uMMbVkYxrAip9X84/+11Xa5KisjKwAGTwDsbVA6fTcEGgI3XQ1tH+XLfmFSesWbEheDjB3ygLW\nLM0rNyYSiyTf91vjyobV6ZmRpRpHi/8LxeNBC8F3BNLyCsTdOS3xGGPSw1oawP/ueJVQcZjqeuoG\nnjYAQh9QmjC2bHIz7dVsPpjQlg2rVkF8Iz36JN8Qqde+O1d53dwFywgWh1KK05/pY8DJB6V0bn3T\nghthy/0QWw7xDRCcjK4fhsZtWrExzYklDWDxlz8Sj1U9WJ3ZMoO/jD4D8AHw5ZRW/PnAPjx2XVee\nuGknRvbflTcf/4yLH/or/kxfubr+TB9/f+gvVV67yy6dCGRWnhXl8Xlwe35fisSX4aPjzh04/i9H\n1+izhUpCfPryF7z52Pss/XZ5jeqW0thqKJlM+a1BY6BFaPGEWl3TGLNjqlPSEJFlIvKtiCwQkblO\nWVsRmSoiPzs/s8ucf52I5IrIjyJyQpnyg5zr5IrIv0VEnHK/iLzslM8WkZ51ibcqVe3UBxDI8vPI\nzDtpv1NbyDydgvxM7rm4B6Ggi5IiN8FiN5GQi+eue5V2Xdty77RbyDlhfzp0b8fBQ/rywCe3sf+R\nVe/Dcfip/choEcDlkq1l4hJi0RhujwuXO/E66oxDeWz23WRkBVL+XLkLljKi24U8OOopnrl6PP/o\nfz33nPtozWdzRX4A8SU5EILwVzW7ljFmh1YfLY2jVfWAMqPu1wIfqepuwEfOvxGRPsAIYG9gMPCE\n/L72+JPABcBuzmuwU34ekK+qvYGHgDH1EG8lZ13/R9ye5L8KVdiwciMAknUesz7ej2QrpkcjUT5+\naQZ9+u/O3e/fyEvLn+Kud69nj4N7V3tvX8DH0EuHIK4y99fE+EU4GCEeixOPxZk+6UsKqxgzSR63\ncsuweynML6JkS5BwMEKoJMwXb8zmkwlfpHwdANw7gSYbZ/GAu1fNrmWM2aE1RPfUUOBF5/2LwLAy\n5RNVNaSqS4FcoJ+IdAFaqeosTcz/HVehTum1XgUGlbZC6tP+R+2NPyv5g3Oh4hDXDr6Dfwy4jhU/\nrSPqOQfVyufGYnHCwWTrV1Vv6vjpvHTXa8Siv/9RTjYNOh6NM3Xc9JSv+8vCZRRsrJxkgkUh3n1m\nao1iFO8e4N0d8FY8gGSdW6NrGWN2bHVNGgpME5F5IjLKKeukqqud92uA0r6frsBvZequcMq6Ou8r\nlpero6pRYDPQro4xVxKLxSguKKn6BIUfZufyz8NuZJ+Be6JJencCmX4OP/WQGt/7hZtfrrR2VTKR\ncJT8vIJtnlcqFolRVXqtzfImkv0s+I8gkTh84O6GtHka8TS/loYGpxLfcAbxdYOIb74pMeZjTDNR\n1ym3h6vqShHpCEwVkR/KHlRVFZEGf3rQSVijAHbeueqZStVxuVzVDoZD4jmJ72b8wMjRIxh3y8tE\nwlE0rvgzfRzz54H0GbB7yveLhCM8ftnz5C2vfhXdUoEWAQ4efEDK1+/dtxden5cSyk8j9mf6Oe6c\nI1O+TilxtUayn0TjhaBBcLWjARp927144bNQ9Cio8yWj5DU0+AG0fxtxVz02ZkxTUaeWhqqudH7m\nAW8A/YC1TpcTzs885/SVQPcy1bs5ZSud9xXLy9UREQ/QGtiQJI6xqpqjqjkdOmx7w6SK3G43/U86\nCJe7+l9HqDjEytzVnP5/p/DvmXcx/IqTGHbZEO5+/wYuf3JUjf6IPvaP55k2/rOqTyhzqUCWn70O\n2a1GScPtcXPDxCvwZ/rx+hPdShktAux+0C4MOf+YlK9TKSxXC8TdvlkmDI0XQ2GZhAFAFLQQLRqb\ntriMaUy1bmmISBbgUtUtzvvjgdHAZGAkcI/zs/Rx6MnASyLyILATiQHvr1Q1JiIFItIfmA2cCzxa\nps5IYCYwHPhYG2jdk8ufGsU/D7uRtcvXVdniyGgR2LqExy779WCXe8+p1b1KioJMGz+9yjEQf4aP\nky46nl+/X0E4FOHYs4/k2LMH4nLVLMcfOGhfXvjp33z038/YuGYTBw7al5zBB9iugrUV+wXEneiU\nLScKoVnpiMiYRleX7qlOwBvON04P8JKqThGROcAkETkPWA6cDqCqi0RkErAYiAKXqG6dknMx8AKQ\nAbzvvACeA8aLSC6wkcTsqwaR3akND39+OxPHvMlbj08hHq2cOAKZfg47tV+d71Wwfkv52VJluDwu\nrn/pcg4dejDxeJyvp33Lj3Ny+filzxk4vH+NptwCtN+pLWdcPWzbJ5ptc3WoYrMuEjPMjGkGap00\nVHUJsH9z0PysAAAT9UlEQVSS8g3AoCrq3AncmaR8LrBPkvIgcFptY0xVNBLl4YvG8vFLn+P1e6rs\neikqKKZwUzHZHVvX6X7tu7bF43VT8TlwEaH/Hw7i0KEHEyoJcdWxo1n27a8Ei0L4s/w8deWLPDh9\nND337p70uqZhibsz6jvYeTal7OSFDKTFqKqqGdOk2BPhwIu3vMynL39BJBShuKCkyrWfXC4XM9+a\nU+f7uT1uzr/nz/jLPAkuIvgz/fzl9kRj6pX7J/PLgqWUFAZRVYKFQQrzC7nzzIfrfH9Te9LmEfAd\nBvhAMkFaQqtbEN/B6Q7NmEbR7BcsVFXeenxKStNeVZVYNMbimT/y+Rtf4Qt4OfrMw+mxV/I1p6pz\n0oXH07ZLNv+74zXW/baevfrvzl9uH0GvfRKzvz4cN51wSfmuEFVYmbua9as2Jp5QN41OXC2Rtk+j\n8Y0Qzwf3zoh4t13RmCai2SeNeDxe7eq2Zakqi2f9xNNXjSdcEsbldvHKA29zwZizGXbpkBrf+9BT\nDubQU+wb6o5IXG3BZYnbND/NvnvK7XbTbffkg5jiElwuwe1x48vwceKoY/n89dmEikNbWx3hkjBj\nrx5f70uWH3/ukfgC5b/BikDX3l1SamWsWZbHip9XJ3263BhjaqvZtzRUlVAw+dLkJ190Ai3aZOL2\nuTnq9MN4d+zUpN1YbreLr977miHnJR3/r5XT/u8Uvnp/Psu++23rQLjX5+GGCZdXW2/FT6u4bfj9\nrMpdg7iEVu1acsOEK9j70D3qLTZjTPPV7JPGbz+uYnNepecFAfh+5lxueX00cz9YwE9zf0FVEZeg\nsfLf3kUEj7d+f5X+DD8Pf34H8z/6lnVLPqbPgd/QpVcLPC0WoboTkmTVxEg4whVH3MzmdQVbWxjr\nijdw3eA7ePHnR8nu1KZeYzTGND/NPmmUbP4VlzsGVP4jvGbJGv621z8RlwtX6XLl7srLjcRjUfo3\nwOZILpeLvgO+gn3/A4QgqujmGeB9BbLHVkocX703n1BJuFKXVCwa48Nxn3LGVfa8hjGmbpr9mMYu\n+/hJ9pydxxenuMidWFK8OERJYWJ5cSWG1xfHnxEjkBXDH4hzzWPLaZH1fb3HprF1UPgIic2PnESg\nxRCeB6FPKp2/YVV+udVyS4WDEdb9ur7e4zOVxaIxJo55kzO7X8iw7JGMPv0B1izL23ZFY3YQzb6l\nEYn14J/3/sYDl+9MNAqxqItAZgyPVyksqNz68PminH/TKlQFry/OgBMKaJUdQ/MvQj17I5l/hMDJ\nSbuPaiw8i8T/RBXHUYrR4FQkcGy50j4Ddk/6YGJGiwD7VbMRlKk/9/31cT5/Y/bWsa8vXp/Ngo+/\n47nFD9f5oVBjtgfNPmlMemAa4Q1ZPPjWz0x7tS3rVnk56MgCvp7RkhlvZ1c6X4GslnGOGrapwoEt\nEJmFbl4IwQ+hzeN1X9RPMhNTpipNgHKBtKh0eu++vcg5fj/mfvgNIWffcV/Ay069O3PoUJva29DW\nLl/HjNdmlVtTLB5XgkUhJj8xhZG3nlFtfY3loSVvQGw14h8A/kEk1uk0ZvvR7P+L/GTC56zK7cBv\nuT6GX7SOth0jzP20JfNntMTj8xANl997IhYRDjxySzVXLIHQFxD5Gny1G+eIxWLMeX8BuQvW07ld\nSw4fUowvUDZz+JDM4Unr3jTpSt4ZO5X3xk4jEo5yzFmH86crTqr3gXpT2dJvf8Xr91ZaiDISirD4\ny5+qravhOWj++c4OiWE0+GZiV8R2LyGS0YBRG1Mzzf4videX+BXM+rA1sz4s330grhgut6BxxeV2\n4/G6+fuYnrRqm1theeyKQhCeXaukUbS5iCuOuJk1y/IIFoUIZHZn7K3tePidFXTeOZZYMK/lNYh3\nr6T13R43Qy8ezNCLByc9bhpOl106VvqSAeD2utl5r65JaiSoxtFNl5f/b0qLIZqLFo1DWlzYEOEa\nUyvNfiD8DxceV24NqLI0rojLRfc9u3LG1UN5fO4YOu9xOi89/gc+eLkbJUUuym18sZUPXLWb3vrC\nTS/z24+rKNkSRONKSWGYzRu8PPB/hyKt70Y6zsCV9edaXds0rB59urN7zq54/eW/i3l9Hk697MSq\nK8aWgBYlORCCkrfrN0hj6qjZJ41T/n4COcfvhz/Dl/R4LBJj9ZI8zrhmKA9f+DS3/ul+xt2ZyxM3\n7sTZ/Q5h6Q9JBjfFBYGaLysC8PHEzyt9W43HlUUz1xKMHYnUMhmZxnH729dy+KmH4PV5cHvc9OjT\njXs+uImddu1cTS0vSfcQBrB1rcx2ptl3T7k9bm59/WpyFyzlsgE3EAlV3i8hHovx6kPv8MOcXKLO\n/trBohAUwV0XH8gzn8zn9xlOPiT7UcRVeRDdNH1ZrTK5/qXLCYciREIRslplbruSe+fEfhyxpZSf\n9ZABGQ22hYwxtdLsWxqldt2/J7vn7JL0WPc9uzLluU+2JoyyVv2yiby8vqChxHiD/wjw1H7JjqNH\nHIbHVz6Xu1xCn0N3r/EGTCZ9fH5vagmDxIoCkv14YgFEyQICiZf/qConPBiTLs2+pQGJ2Uqjhz9A\n7tdLy5WLCC63ULipiA0rky9IGI1EIfQlic0IgeB7aHQxtHsbkZrn5L/ePoKFny5i7fJ1lBQGyWgR\nIJDp56r/XFLja5kdh3h2hQ7TITQd4uvAeyDi3TPdYRlTiSUN4JMJX/D1tG8IlZR/iC6xHIeL9Ss2\nVlu/TYeyCx5GILYKwl+C//Aax5LVOoun5t/HV+/NZ8nC5XTu1ZGBfzoEXyD5mItpOkR8EDgu3WEY\nUy1LGsCH4z5NjFEkkWxZjrL8GXG8vgpP32kEoj/XKmlAYrn2ASfnMODknGrPy12wlHkffkPL7CwG\nDu9Py+zKD/wZY0x9sqRBYmHA2vBnuPnjqA1UevBbvODZte6BVUFVeeC8J/h00pdEIzG8Xg9P/usF\nbp98LQccXWmrdWOMqTc2EA4M/uvRBLKSP6uRjC/Thy/gY8j5gzjn6hDlf40ecHV09pFuGF++NYfp\nr8wkVBwmFokRLA4RLApx6x/vIxKuPPvLGGPqiyUN4IjTBnDo0IPxZ/rKPKunuD3l5857vHH27lfM\n0zNP5NW8Z7nkkQvwdHwlMWMKN+CFwAlIuwn1s2BhFT544ZOk3Wmqynef/9Bg9zXGGEsaJLqnrvvv\nPxnyt2NwuxNZw58R57IxK8hqFSUjK4bXH2ffAUXc+p8l+F0TyPttA7FoDHHvhCt7LNJpMdLpO1xt\nHkrsH92AKu7nUSpYGOTWP97LVcfexvezf27QGIwxzZONaZQxb+o3xKKJQe0WrRMr2R47PJ+VS/20\nbBPD5VZuP78n338dwOO9Do/Pw+VPjeKI4QPqvqJtDRx37lEs/HRRpdZGPK4UFwRZ8PF3XDXoNu6d\ndjN9+u/eaHEZY5o+SxplxOO/f4PfuNZDSaGb7A5Reuye+OP8jyG78cuiALGoEAkFAbj3L4/hDXhZ\nsyQPt8fNYaf2o12Xhn0afOCfDmHGazOZ/e7XhIor79QHECoO8ew1/+XB6aMbNBZjTPNi3VNlHHv2\nEfgCibEIVeHxG3YiWCzE47DsRz/LfwoQi5b/lYVLItw67F6evfa/jL1qHOfuegkfjvu0QeN0uVzc\nMOEKxnx4E6dfdUqVs79+WbisRtf9cvIcLul3Lad3OZ+bh41h6Xe/1kO0xpimxJJGGcOvPIWe+/TA\n56zW8dVHrRh9fk+Kt7hZv6ZD0j0pVJV4XBPbwpaECQcjPHLRWPLXbqp0bn0SEfoM2IO/3nEmvozk\ni9p16NYu5eu9M3Yqd531CD/N/YX8tZuZ9fY8LhtwgyUOY0w5ljTK+GXBMlblriEcBFDCISEeg4uO\n3YtHr9uTSDi1GVHiEr54c06lclVl8ayfeP3hd5n+ykzCwYrbuNac2+Nm2D+GVFre3Z/p55ybT0vp\nGrFojOeu/d/W3f5KYw0Vh3jhpol1jtEY03TYmIajpCjI9SfeSXFB6UY4gsaF+TNaAZDRcgv9TjyQ\nuVMWECxO/vT4Vlp5hlM0EuXmoWP4dsb3xCIxPH4PvoCPhz4bTfc9qt6gJxV/uX0E8bjy1mNT0Hgc\nX4aPv95xJkeefmhK9dev3EgkyeZBqmqzsIwx5VjScMx+Z17SAeVSoeIwvfv24sjTBvDQhU+XSS6V\nqSoDTim/BMibj77PN9MXb13fKhKOEiwMMvq0B3jmmwfrFLvb7eaCe85m5G1nUJhfSOv2rXB7Un9O\npFX7lmg8+TTejt3b1yk2Y0zTYt1TjuKCEuKxqpOGP9PHznt1Y/+j9iaSZIn0Ur6AjwvuPbvSeML7\nz32UZEFEWJW7hrzf1tct+NJ7+7207Zxdo4QBkJEV4Nhzjqy0EZU/08/ZN9nS3MaY31lLw9F30L5V\nPjQH0KptSwacfBCrl6zF7XUn3awJgZtfu5JDhhxY6VAsmvzaIrLNRREbw6WP/g0RmDpuOuISvH4v\nF4w5m/4n1Xyfc2NM02VJwxGLxXG5kj+g53ILo+47B4/XQywaI1xSxQC2wnPX/i9p0jj27IFMuPsN\nwsHyyaZtl2w69+xY5/jryuvzcvlTF3LhAyPZsrGQdl1q3mIxxjR91j1FYpD6yiNvrtR9VMqf4SdU\nHCYcinDVMbeVewiwohU/rWbD6sobNg2/8hR67N2djBYB55o+MltmcMOEyxv1afJtycgK0LF7e0sY\nxpikrKUBzJmyoMr9NCCxH/iM12axbsV6QsFI+W2ck0g2oB7I9PPozLuY/e7XfPv593Tq0YFjzjqc\nVm1b1jV8Y4xpNDtE0hCRwcAjJJaSfVZV76nP6+ev2VTteIaqMuudecyZMp94vPqM0bV3Z9rvlHzB\nQrfHzaFDD+bQoQfXKV5jjEmX7b57ShJrjD8ODAH6AGeKSJ/6vMdeA3YnXs10W0gkjmgkVm1yATjs\nj4fUZ2jGGLNd2e6TBtAPyFXVJaoaBiYCQ+vzBr322ZlDT8kptxFTVeMMbo8Lt7fq/v6FH39Xn6EZ\nY8x2ZUdIGl2B38r8e4VTtpWIjBKRuSIyd926dbW6ybX/vYyLHhhJ77692HmvrnTfc6ek53n9Xo4e\ncRhSxUwrX6YvabkxxjQFO0LS2CZVHauqOaqa06FDh1pdw+1284dRx/HkvHt5btHDXProeZXWcxIR\n2nXJ5v+evzjpuEUgy89Jo46r1f2NMWZHsCMkjZVA9zL/7uaUNai+x+zLubeejjfgJbNVBhktAnTu\n1YG73r8Bt9vN6MnX0LJtCzJbZuDP9OPL8DHo7IEcbmMaxpgmTKpbb2l7ICIe4CdgEIlkMQc4S1UX\nJTs/JydH586dW2/335JfyPezfqZl2xbs2a93ubGOcCjC7He/ZsuGLex3ZB+67Z68S8sYY7Z3IjJP\nVXO2dd52P+VWVaMicinwAYkpt89XlTAaQsvsFvQb0jfpMZ/fy0BrWRhjmpHtPmkAqOp7wHvpjsMY\nY5q7HWFMwxhjzHbCkoYxxpiUWdIwxhiTMksaxhhjUrbdT7mtKRFZByyvZfX2QP1so7fjaa6f3T53\n82Kfu2o9VHWbT0c3uaRRFyIyN5V5yk1Rc/3s9rmbF/vcdWfdU8YYY1JmScMYY0zKLGmUNzbdAaRR\nc/3s9rmbF/vcdWRjGsYYY1JmLQ1jjDEps6ThEJHBIvKjiOSKyLXpjqcxiMjzIpInIs1qu0ER6S4i\nn4jIYhFZJCL/THdMjUFEAiLylYgsdD73bemOqTGJiFtE5ovIO+mOpbGIyDIR+VZEFohIvSz/bd1T\nbN2H/CfgOBI7A84BzlTVxWkNrIGJyBFAITBOVfdJdzyNRUS6AF1U9WsRaQnMA4Y1g/+9BchS1UIR\n8QKfA/9U1VlpDq1RiMi/gByglaqelO54GoOILANyVLXenk2xlkZCg+9Dvj1S1c+AjemOo7Gp6mpV\n/dp5vwX4ngpbCDdFmlDo/NPrvJrFt0YR6Qb8AXg23bHs6CxpJGxzH3LTNIlIT6AvMDu9kTQOp4tm\nAZAHTFXVZvG5gYeBq4F4ugNpZApME5F5IjKqPi5oScM0WyLSAngNuFxVC9IdT2NQ1ZiqHkBi2+R+\nItLkuyVF5CQgT1XnpTuWNDjc+d97CHCJ0yVdJ5Y0EtKyD7lJH6dP/zXgf6r6errjaWyqugn4BBic\n7lgawWHAKU7//kTgGBH5b3pDahyqutL5mQe8QaIrvk4saSTMAXYTkV4i4gNGAJPTHJNpIM6A8HPA\n96r6YLrjaSwi0kFE2jjvM0hM/PghvVE1PFW9TlW7qWpPEv/f/lhVz05zWA1ORLKciR6ISBZwPFDn\nmZKWNEjsQw6U7kP+PTCpMfchTxcRmQDMBPYQkRUicl66Y2okhwHnkPjGucB5nZjuoBpBF+ATEfmG\nxBelqarabKafNkOdgM9FZCHwFfCuqk6p60Vtyq0xxpiUWUvDGGNMyixpGGOMSZklDWOMMSmzpGGM\nMSZlljSMMWYHV5PFR0XkoTKzBn8SkU01upfNnjLGmB1bbRcfFZF/AH1V9W+p1rGWhjHG7OCSLT4q\nIruKyBRn3akZIrJnkqpnAhNqci9PHeI0xhiz/RoLXKSqP4vIIcATwDGlB0WkB9AL+LgmF7WkYYwx\nTYyzGOehwCuJVXMA8Fc4bQTwqqrGanJtSxrGGNP0uIBNzgq3VRkBXFKbCxtjjGlCnKX+l4rIaZBY\npFNE9i897oxvZJNYe65GLGkYY8wOrorFR/8MnOcsWLiI8ruRjgAmai2mz9qUW2OMMSmzloYxxpiU\nWdIwxhiTMksaxhhjUmZJwxhjTMosaRhjjEmZJQ1jjDEps6RhjDEmZZY0jDHGpOz/AaJvH524D2Ga\nAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xcd005c0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = df2.total_stock_value\n",
    "y = df2.expenses\n",
    "cpoi = df2.poi\n",
    "\n",
    "plt.scatter(x,y,c=cpoi)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we see that whilst no clear relationship is apparent, the data has a definite shape that perhaps an algorithim \n",
    "would be able to take advantage of. For example, nobody under a certain expenses threshold was a POI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAEQCAYAAABLMTQcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIIe7mVkCOdzNzBLo/wMiuZE265ZolAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xccd9550>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = df2.total_stock_value\n",
    "y = df2.exercised_stock_options\n",
    "cpoi = df2.poi\n",
    "\n",
    "plt.scatter(x,y,c=cpoi)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data strongly suggests  a linear relationship between these two variables. If the correlation is too high it might make sense to drop one of them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FEATURE SELECTION "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df2[\"Fromfract\"] = df2.from_poi_to_this_person.divide(df2.from_messages, axis=\"index\").fillna(0)\n",
    "df2[\"Tofract\"] = df2.from_this_person_to_poi.divide(df2.to_messages, axis=\"index\").fillna(0)\n",
    "df2[\"SaltoPay\"] = df2.salary.divide(df2.total_payments, axis=\"index\").fillna(0)\n",
    "df2[\"ESVtoTSV\"] = df2.exercised_stock_options.divide(df2.total_stock_value, axis=\"index\").fillna(0)\n",
    "df2[\"RStoTSV\"] = df2.restricted_stock.divide(df2.total_stock_value, axis=\"index\").fillna(0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. regarding features, its worth remembering that the irrelevant features will be dropped/merged as needed by SelectKbest and PCA. But as our last part of EDA lets see what the cross correlation is of our df as it stands."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bonus</th>\n",
       "      <th>deferral_payments</th>\n",
       "      <th>deferred_income</th>\n",
       "      <th>director_fees</th>\n",
       "      <th>exercised_stock_options</th>\n",
       "      <th>expenses</th>\n",
       "      <th>from_messages</th>\n",
       "      <th>from_poi_to_this_person</th>\n",
       "      <th>from_this_person_to_poi</th>\n",
       "      <th>loan_advances</th>\n",
       "      <th>...</th>\n",
       "      <th>salary</th>\n",
       "      <th>shared_receipt_with_poi</th>\n",
       "      <th>to_messages</th>\n",
       "      <th>total_payments</th>\n",
       "      <th>total_stock_value</th>\n",
       "      <th>Fromfract</th>\n",
       "      <th>Tofract</th>\n",
       "      <th>SaltoPay</th>\n",
       "      <th>ESVtoTSV</th>\n",
       "      <th>RStoTSV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>bonus</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.293543</td>\n",
       "      <td>-0.411659</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.506998</td>\n",
       "      <td>0.033799</td>\n",
       "      <td>0.052725</td>\n",
       "      <td>0.562187</td>\n",
       "      <td>0.354634</td>\n",
       "      <td>0.973826</td>\n",
       "      <td>...</td>\n",
       "      <td>0.523190</td>\n",
       "      <td>0.549102</td>\n",
       "      <td>0.372997</td>\n",
       "      <td>0.569054</td>\n",
       "      <td>0.509441</td>\n",
       "      <td>0.083181</td>\n",
       "      <td>0.178842</td>\n",
       "      <td>-0.324554</td>\n",
       "      <td>0.183681</td>\n",
       "      <td>-0.143934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>deferral_payments</th>\n",
       "      <td>0.293543</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.881500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.019009</td>\n",
       "      <td>0.004800</td>\n",
       "      <td>0.321947</td>\n",
       "      <td>0.424101</td>\n",
       "      <td>0.206993</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.455884</td>\n",
       "      <td>0.356696</td>\n",
       "      <td>0.310129</td>\n",
       "      <td>0.066774</td>\n",
       "      <td>0.075710</td>\n",
       "      <td>0.570496</td>\n",
       "      <td>0.325110</td>\n",
       "      <td>-0.217174</td>\n",
       "      <td>0.143789</td>\n",
       "      <td>-0.030617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>deferred_income</th>\n",
       "      <td>-0.411659</td>\n",
       "      <td>-0.881500</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.464837</td>\n",
       "      <td>-0.308076</td>\n",
       "      <td>0.101181</td>\n",
       "      <td>-0.319995</td>\n",
       "      <td>-0.178951</td>\n",
       "      <td>-0.271673</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.353816</td>\n",
       "      <td>-0.394677</td>\n",
       "      <td>-0.350815</td>\n",
       "      <td>-0.054404</td>\n",
       "      <td>-0.298189</td>\n",
       "      <td>-0.294988</td>\n",
       "      <td>-0.067138</td>\n",
       "      <td>-0.368901</td>\n",
       "      <td>-0.416388</td>\n",
       "      <td>0.148517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>director_fees</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.464837</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.623257</td>\n",
       "      <td>-0.504631</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.317360</td>\n",
       "      <td>0.997476</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.311606</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.242578</td>\n",
       "      <td>0.122766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>exercised_stock_options</th>\n",
       "      <td>0.506998</td>\n",
       "      <td>0.019009</td>\n",
       "      <td>-0.308076</td>\n",
       "      <td>0.623257</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.019412</td>\n",
       "      <td>-0.066129</td>\n",
       "      <td>0.160253</td>\n",
       "      <td>-0.030101</td>\n",
       "      <td>0.960259</td>\n",
       "      <td>...</td>\n",
       "      <td>0.607324</td>\n",
       "      <td>0.154333</td>\n",
       "      <td>0.079568</td>\n",
       "      <td>0.591690</td>\n",
       "      <td>0.963560</td>\n",
       "      <td>0.162210</td>\n",
       "      <td>-0.071531</td>\n",
       "      <td>0.138878</td>\n",
       "      <td>0.152256</td>\n",
       "      <td>-0.156944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>expenses</th>\n",
       "      <td>0.033799</td>\n",
       "      <td>0.004800</td>\n",
       "      <td>0.101181</td>\n",
       "      <td>-0.504631</td>\n",
       "      <td>0.019412</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.094144</td>\n",
       "      <td>-0.059244</td>\n",
       "      <td>0.014964</td>\n",
       "      <td>0.658681</td>\n",
       "      <td>...</td>\n",
       "      <td>0.145364</td>\n",
       "      <td>0.223495</td>\n",
       "      <td>0.155070</td>\n",
       "      <td>0.109798</td>\n",
       "      <td>0.034707</td>\n",
       "      <td>0.082202</td>\n",
       "      <td>-0.049390</td>\n",
       "      <td>-0.065014</td>\n",
       "      <td>-0.074790</td>\n",
       "      <td>0.151776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>from_messages</th>\n",
       "      <td>0.052725</td>\n",
       "      <td>0.321947</td>\n",
       "      <td>-0.319995</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.066129</td>\n",
       "      <td>0.094144</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.186708</td>\n",
       "      <td>0.588687</td>\n",
       "      <td>-0.213768</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.003541</td>\n",
       "      <td>0.230855</td>\n",
       "      <td>0.475450</td>\n",
       "      <td>-0.033089</td>\n",
       "      <td>-0.036310</td>\n",
       "      <td>-0.165410</td>\n",
       "      <td>0.262992</td>\n",
       "      <td>0.015336</td>\n",
       "      <td>0.077577</td>\n",
       "      <td>-0.005982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>from_poi_to_this_person</th>\n",
       "      <td>0.562187</td>\n",
       "      <td>0.424101</td>\n",
       "      <td>-0.178951</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.160253</td>\n",
       "      <td>-0.059244</td>\n",
       "      <td>0.186708</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.445063</td>\n",
       "      <td>0.009878</td>\n",
       "      <td>...</td>\n",
       "      <td>0.179055</td>\n",
       "      <td>0.659264</td>\n",
       "      <td>0.525667</td>\n",
       "      <td>0.154431</td>\n",
       "      <td>0.146366</td>\n",
       "      <td>0.385918</td>\n",
       "      <td>0.087685</td>\n",
       "      <td>-0.010016</td>\n",
       "      <td>0.039395</td>\n",
       "      <td>0.106135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>from_this_person_to_poi</th>\n",
       "      <td>0.354634</td>\n",
       "      <td>0.206993</td>\n",
       "      <td>-0.271673</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.030101</td>\n",
       "      <td>0.014964</td>\n",
       "      <td>0.588687</td>\n",
       "      <td>0.445063</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.934835</td>\n",
       "      <td>...</td>\n",
       "      <td>0.021288</td>\n",
       "      <td>0.475748</td>\n",
       "      <td>0.568506</td>\n",
       "      <td>0.011556</td>\n",
       "      <td>0.001289</td>\n",
       "      <td>-0.162769</td>\n",
       "      <td>0.617118</td>\n",
       "      <td>-0.039627</td>\n",
       "      <td>0.006378</td>\n",
       "      <td>0.077239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loan_advances</th>\n",
       "      <td>0.973826</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.960259</td>\n",
       "      <td>0.658681</td>\n",
       "      <td>-0.213768</td>\n",
       "      <td>0.009878</td>\n",
       "      <td>0.934835</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.535252</td>\n",
       "      <td>0.291501</td>\n",
       "      <td>0.739805</td>\n",
       "      <td>0.991879</td>\n",
       "      <td>0.962026</td>\n",
       "      <td>-0.218806</td>\n",
       "      <td>0.880459</td>\n",
       "      <td>-0.598779</td>\n",
       "      <td>-0.550110</td>\n",
       "      <td>0.550110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>long_term_incentive</th>\n",
       "      <td>0.625259</td>\n",
       "      <td>0.042448</td>\n",
       "      <td>-0.331715</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.500016</td>\n",
       "      <td>-0.100766</td>\n",
       "      <td>-0.071958</td>\n",
       "      <td>0.212538</td>\n",
       "      <td>0.083591</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.484114</td>\n",
       "      <td>0.178944</td>\n",
       "      <td>0.134277</td>\n",
       "      <td>0.518498</td>\n",
       "      <td>0.495485</td>\n",
       "      <td>0.179776</td>\n",
       "      <td>0.028499</td>\n",
       "      <td>-0.150870</td>\n",
       "      <td>0.216794</td>\n",
       "      <td>-0.171976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>other</th>\n",
       "      <td>0.376371</td>\n",
       "      <td>0.385829</td>\n",
       "      <td>-0.185219</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.536248</td>\n",
       "      <td>0.062874</td>\n",
       "      <td>-0.101686</td>\n",
       "      <td>0.111249</td>\n",
       "      <td>-0.110335</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.606903</td>\n",
       "      <td>0.122591</td>\n",
       "      <td>0.040580</td>\n",
       "      <td>0.825589</td>\n",
       "      <td>0.627171</td>\n",
       "      <td>0.363396</td>\n",
       "      <td>-0.097728</td>\n",
       "      <td>-0.232771</td>\n",
       "      <td>0.093553</td>\n",
       "      <td>-0.082525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>poi</th>\n",
       "      <td>0.302384</td>\n",
       "      <td>-0.098428</td>\n",
       "      <td>-0.265698</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.503551</td>\n",
       "      <td>0.060292</td>\n",
       "      <td>-0.074308</td>\n",
       "      <td>0.167722</td>\n",
       "      <td>0.112940</td>\n",
       "      <td>0.999851</td>\n",
       "      <td>...</td>\n",
       "      <td>0.264976</td>\n",
       "      <td>0.228313</td>\n",
       "      <td>0.058954</td>\n",
       "      <td>0.230102</td>\n",
       "      <td>0.366462</td>\n",
       "      <td>0.187259</td>\n",
       "      <td>0.167990</td>\n",
       "      <td>0.136760</td>\n",
       "      <td>-0.017280</td>\n",
       "      <td>0.087592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>restricted_stock</th>\n",
       "      <td>0.376992</td>\n",
       "      <td>0.115088</td>\n",
       "      <td>-0.133895</td>\n",
       "      <td>-0.968483</td>\n",
       "      <td>0.690935</td>\n",
       "      <td>0.042896</td>\n",
       "      <td>0.003145</td>\n",
       "      <td>0.133594</td>\n",
       "      <td>0.049284</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.550824</td>\n",
       "      <td>0.232660</td>\n",
       "      <td>0.195570</td>\n",
       "      <td>0.595728</td>\n",
       "      <td>0.855250</td>\n",
       "      <td>0.103377</td>\n",
       "      <td>-0.053337</td>\n",
       "      <td>-0.008805</td>\n",
       "      <td>0.035777</td>\n",
       "      <td>-0.011035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>restricted_stock_deferred</th>\n",
       "      <td>0.118222</td>\n",
       "      <td>-0.412777</td>\n",
       "      <td>0.173154</td>\n",
       "      <td>0.575257</td>\n",
       "      <td>-0.051644</td>\n",
       "      <td>0.040947</td>\n",
       "      <td>-0.326671</td>\n",
       "      <td>-0.455876</td>\n",
       "      <td>-0.398550</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.592576</td>\n",
       "      <td>-0.348405</td>\n",
       "      <td>-0.359420</td>\n",
       "      <td>0.941613</td>\n",
       "      <td>-0.819225</td>\n",
       "      <td>-0.116844</td>\n",
       "      <td>-0.121230</td>\n",
       "      <td>-0.228339</td>\n",
       "      <td>-0.316915</td>\n",
       "      <td>-0.153637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>salary</th>\n",
       "      <td>0.523190</td>\n",
       "      <td>0.455884</td>\n",
       "      <td>-0.353816</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.607324</td>\n",
       "      <td>0.145364</td>\n",
       "      <td>-0.003541</td>\n",
       "      <td>0.179055</td>\n",
       "      <td>0.021288</td>\n",
       "      <td>0.535252</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.284995</td>\n",
       "      <td>0.187047</td>\n",
       "      <td>0.579260</td>\n",
       "      <td>0.614736</td>\n",
       "      <td>0.331919</td>\n",
       "      <td>-0.012175</td>\n",
       "      <td>-0.045731</td>\n",
       "      <td>0.088880</td>\n",
       "      <td>-0.037833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shared_receipt_with_poi</th>\n",
       "      <td>0.549102</td>\n",
       "      <td>0.356696</td>\n",
       "      <td>-0.394677</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.154333</td>\n",
       "      <td>0.223495</td>\n",
       "      <td>0.230855</td>\n",
       "      <td>0.659264</td>\n",
       "      <td>0.475748</td>\n",
       "      <td>0.291501</td>\n",
       "      <td>...</td>\n",
       "      <td>0.284995</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.847990</td>\n",
       "      <td>0.191069</td>\n",
       "      <td>0.176314</td>\n",
       "      <td>0.085249</td>\n",
       "      <td>0.053525</td>\n",
       "      <td>-0.069747</td>\n",
       "      <td>0.019029</td>\n",
       "      <td>0.144477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>to_messages</th>\n",
       "      <td>0.372997</td>\n",
       "      <td>0.310129</td>\n",
       "      <td>-0.350815</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.079568</td>\n",
       "      <td>0.155070</td>\n",
       "      <td>0.475450</td>\n",
       "      <td>0.525667</td>\n",
       "      <td>0.568506</td>\n",
       "      <td>0.739805</td>\n",
       "      <td>...</td>\n",
       "      <td>0.187047</td>\n",
       "      <td>0.847990</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.133834</td>\n",
       "      <td>0.120864</td>\n",
       "      <td>-0.071724</td>\n",
       "      <td>0.068889</td>\n",
       "      <td>-0.054354</td>\n",
       "      <td>0.011472</td>\n",
       "      <td>0.116968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_payments</th>\n",
       "      <td>0.569054</td>\n",
       "      <td>0.066774</td>\n",
       "      <td>-0.054404</td>\n",
       "      <td>0.317360</td>\n",
       "      <td>0.591690</td>\n",
       "      <td>0.109798</td>\n",
       "      <td>-0.033089</td>\n",
       "      <td>0.154431</td>\n",
       "      <td>0.011556</td>\n",
       "      <td>0.991879</td>\n",
       "      <td>...</td>\n",
       "      <td>0.579260</td>\n",
       "      <td>0.191069</td>\n",
       "      <td>0.133834</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.668166</td>\n",
       "      <td>0.219607</td>\n",
       "      <td>0.012841</td>\n",
       "      <td>-0.126481</td>\n",
       "      <td>0.073381</td>\n",
       "      <td>-0.025158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_stock_value</th>\n",
       "      <td>0.509441</td>\n",
       "      <td>0.075710</td>\n",
       "      <td>-0.298189</td>\n",
       "      <td>0.997476</td>\n",
       "      <td>0.963560</td>\n",
       "      <td>0.034707</td>\n",
       "      <td>-0.036310</td>\n",
       "      <td>0.146366</td>\n",
       "      <td>0.001289</td>\n",
       "      <td>0.962026</td>\n",
       "      <td>...</td>\n",
       "      <td>0.614736</td>\n",
       "      <td>0.176314</td>\n",
       "      <td>0.120864</td>\n",
       "      <td>0.668166</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.151981</td>\n",
       "      <td>-0.044858</td>\n",
       "      <td>0.108068</td>\n",
       "      <td>0.184985</td>\n",
       "      <td>-0.174145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fromfract</th>\n",
       "      <td>0.083181</td>\n",
       "      <td>0.570496</td>\n",
       "      <td>-0.294988</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.162210</td>\n",
       "      <td>0.082202</td>\n",
       "      <td>-0.165410</td>\n",
       "      <td>0.385918</td>\n",
       "      <td>-0.162769</td>\n",
       "      <td>-0.218806</td>\n",
       "      <td>...</td>\n",
       "      <td>0.331919</td>\n",
       "      <td>0.085249</td>\n",
       "      <td>-0.071724</td>\n",
       "      <td>0.219607</td>\n",
       "      <td>0.151981</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.026195</td>\n",
       "      <td>0.054257</td>\n",
       "      <td>0.023504</td>\n",
       "      <td>0.028471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tofract</th>\n",
       "      <td>0.178842</td>\n",
       "      <td>0.325110</td>\n",
       "      <td>-0.067138</td>\n",
       "      <td>0.311606</td>\n",
       "      <td>-0.071531</td>\n",
       "      <td>-0.049390</td>\n",
       "      <td>0.262992</td>\n",
       "      <td>0.087685</td>\n",
       "      <td>0.617118</td>\n",
       "      <td>0.880459</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.012175</td>\n",
       "      <td>0.053525</td>\n",
       "      <td>0.068889</td>\n",
       "      <td>0.012841</td>\n",
       "      <td>-0.044858</td>\n",
       "      <td>-0.026195</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.081929</td>\n",
       "      <td>0.097919</td>\n",
       "      <td>-0.011190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SaltoPay</th>\n",
       "      <td>-0.324554</td>\n",
       "      <td>-0.217174</td>\n",
       "      <td>-0.368901</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.138878</td>\n",
       "      <td>-0.065014</td>\n",
       "      <td>0.015336</td>\n",
       "      <td>-0.010016</td>\n",
       "      <td>-0.039627</td>\n",
       "      <td>-0.598779</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.045731</td>\n",
       "      <td>-0.069747</td>\n",
       "      <td>-0.054354</td>\n",
       "      <td>-0.126481</td>\n",
       "      <td>0.108068</td>\n",
       "      <td>0.054257</td>\n",
       "      <td>0.081929</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.059432</td>\n",
       "      <td>0.035879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ESVtoTSV</th>\n",
       "      <td>0.183681</td>\n",
       "      <td>0.143789</td>\n",
       "      <td>-0.416388</td>\n",
       "      <td>0.242578</td>\n",
       "      <td>0.152256</td>\n",
       "      <td>-0.074790</td>\n",
       "      <td>0.077577</td>\n",
       "      <td>0.039395</td>\n",
       "      <td>0.006378</td>\n",
       "      <td>-0.550110</td>\n",
       "      <td>...</td>\n",
       "      <td>0.088880</td>\n",
       "      <td>0.019029</td>\n",
       "      <td>0.011472</td>\n",
       "      <td>0.073381</td>\n",
       "      <td>0.184985</td>\n",
       "      <td>0.023504</td>\n",
       "      <td>0.097919</td>\n",
       "      <td>0.059432</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.515542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RStoTSV</th>\n",
       "      <td>-0.143934</td>\n",
       "      <td>-0.030617</td>\n",
       "      <td>0.148517</td>\n",
       "      <td>0.122766</td>\n",
       "      <td>-0.156944</td>\n",
       "      <td>0.151776</td>\n",
       "      <td>-0.005982</td>\n",
       "      <td>0.106135</td>\n",
       "      <td>0.077239</td>\n",
       "      <td>0.550110</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.037833</td>\n",
       "      <td>0.144477</td>\n",
       "      <td>0.116968</td>\n",
       "      <td>-0.025158</td>\n",
       "      <td>-0.174145</td>\n",
       "      <td>0.028471</td>\n",
       "      <td>-0.011190</td>\n",
       "      <td>0.035879</td>\n",
       "      <td>-0.515542</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              bonus  deferral_payments  deferred_income  \\\n",
       "bonus                      1.000000           0.293543        -0.411659   \n",
       "deferral_payments          0.293543           1.000000        -0.881500   \n",
       "deferred_income           -0.411659          -0.881500         1.000000   \n",
       "director_fees                   NaN                NaN        -0.464837   \n",
       "exercised_stock_options    0.506998           0.019009        -0.308076   \n",
       "expenses                   0.033799           0.004800         0.101181   \n",
       "from_messages              0.052725           0.321947        -0.319995   \n",
       "from_poi_to_this_person    0.562187           0.424101        -0.178951   \n",
       "from_this_person_to_poi    0.354634           0.206993        -0.271673   \n",
       "loan_advances              0.973826          -1.000000         1.000000   \n",
       "long_term_incentive        0.625259           0.042448        -0.331715   \n",
       "other                      0.376371           0.385829        -0.185219   \n",
       "poi                        0.302384          -0.098428        -0.265698   \n",
       "restricted_stock           0.376992           0.115088        -0.133895   \n",
       "restricted_stock_deferred  0.118222          -0.412777         0.173154   \n",
       "salary                     0.523190           0.455884        -0.353816   \n",
       "shared_receipt_with_poi    0.549102           0.356696        -0.394677   \n",
       "to_messages                0.372997           0.310129        -0.350815   \n",
       "total_payments             0.569054           0.066774        -0.054404   \n",
       "total_stock_value          0.509441           0.075710        -0.298189   \n",
       "Fromfract                  0.083181           0.570496        -0.294988   \n",
       "Tofract                    0.178842           0.325110        -0.067138   \n",
       "SaltoPay                  -0.324554          -0.217174        -0.368901   \n",
       "ESVtoTSV                   0.183681           0.143789        -0.416388   \n",
       "RStoTSV                   -0.143934          -0.030617         0.148517   \n",
       "\n",
       "                           director_fees  exercised_stock_options  expenses  \\\n",
       "bonus                                NaN                 0.506998  0.033799   \n",
       "deferral_payments                    NaN                 0.019009  0.004800   \n",
       "deferred_income                -0.464837                -0.308076  0.101181   \n",
       "director_fees                   1.000000                 0.623257 -0.504631   \n",
       "exercised_stock_options         0.623257                 1.000000  0.019412   \n",
       "expenses                       -0.504631                 0.019412  1.000000   \n",
       "from_messages                   1.000000                -0.066129  0.094144   \n",
       "from_poi_to_this_person              NaN                 0.160253 -0.059244   \n",
       "from_this_person_to_poi         1.000000                -0.030101  0.014964   \n",
       "loan_advances                        NaN                 0.960259  0.658681   \n",
       "long_term_incentive                  NaN                 0.500016 -0.100766   \n",
       "other                                NaN                 0.536248  0.062874   \n",
       "poi                                  NaN                 0.503551  0.060292   \n",
       "restricted_stock               -0.968483                 0.690935  0.042896   \n",
       "restricted_stock_deferred       0.575257                -0.051644  0.040947   \n",
       "salary                               NaN                 0.607324  0.145364   \n",
       "shared_receipt_with_poi         1.000000                 0.154333  0.223495   \n",
       "to_messages                    -1.000000                 0.079568  0.155070   \n",
       "total_payments                  0.317360                 0.591690  0.109798   \n",
       "total_stock_value               0.997476                 0.963560  0.034707   \n",
       "Fromfract                            NaN                 0.162210  0.082202   \n",
       "Tofract                         0.311606                -0.071531 -0.049390   \n",
       "SaltoPay                             NaN                 0.138878 -0.065014   \n",
       "ESVtoTSV                        0.242578                 0.152256 -0.074790   \n",
       "RStoTSV                         0.122766                -0.156944  0.151776   \n",
       "\n",
       "                           from_messages  from_poi_to_this_person  \\\n",
       "bonus                           0.052725                 0.562187   \n",
       "deferral_payments               0.321947                 0.424101   \n",
       "deferred_income                -0.319995                -0.178951   \n",
       "director_fees                   1.000000                      NaN   \n",
       "exercised_stock_options        -0.066129                 0.160253   \n",
       "expenses                        0.094144                -0.059244   \n",
       "from_messages                   1.000000                 0.186708   \n",
       "from_poi_to_this_person         0.186708                 1.000000   \n",
       "from_this_person_to_poi         0.588687                 0.445063   \n",
       "loan_advances                  -0.213768                 0.009878   \n",
       "long_term_incentive            -0.071958                 0.212538   \n",
       "other                          -0.101686                 0.111249   \n",
       "poi                            -0.074308                 0.167722   \n",
       "restricted_stock                0.003145                 0.133594   \n",
       "restricted_stock_deferred      -0.326671                -0.455876   \n",
       "salary                         -0.003541                 0.179055   \n",
       "shared_receipt_with_poi         0.230855                 0.659264   \n",
       "to_messages                     0.475450                 0.525667   \n",
       "total_payments                 -0.033089                 0.154431   \n",
       "total_stock_value              -0.036310                 0.146366   \n",
       "Fromfract                      -0.165410                 0.385918   \n",
       "Tofract                         0.262992                 0.087685   \n",
       "SaltoPay                        0.015336                -0.010016   \n",
       "ESVtoTSV                        0.077577                 0.039395   \n",
       "RStoTSV                        -0.005982                 0.106135   \n",
       "\n",
       "                           from_this_person_to_poi  loan_advances    ...     \\\n",
       "bonus                                     0.354634       0.973826    ...      \n",
       "deferral_payments                         0.206993      -1.000000    ...      \n",
       "deferred_income                          -0.271673       1.000000    ...      \n",
       "director_fees                             1.000000            NaN    ...      \n",
       "exercised_stock_options                  -0.030101       0.960259    ...      \n",
       "expenses                                  0.014964       0.658681    ...      \n",
       "from_messages                             0.588687      -0.213768    ...      \n",
       "from_poi_to_this_person                   0.445063       0.009878    ...      \n",
       "from_this_person_to_poi                   1.000000       0.934835    ...      \n",
       "loan_advances                             0.934835       1.000000    ...      \n",
       "long_term_incentive                       0.083591       1.000000    ...      \n",
       "other                                    -0.110335       1.000000    ...      \n",
       "poi                                       0.112940       0.999851    ...      \n",
       "restricted_stock                          0.049284       1.000000    ...      \n",
       "restricted_stock_deferred                -0.398550            NaN    ...      \n",
       "salary                                    0.021288       0.535252    ...      \n",
       "shared_receipt_with_poi                   0.475748       0.291501    ...      \n",
       "to_messages                               0.568506       0.739805    ...      \n",
       "total_payments                            0.011556       0.991879    ...      \n",
       "total_stock_value                         0.001289       0.962026    ...      \n",
       "Fromfract                                -0.162769      -0.218806    ...      \n",
       "Tofract                                   0.617118       0.880459    ...      \n",
       "SaltoPay                                 -0.039627      -0.598779    ...      \n",
       "ESVtoTSV                                  0.006378      -0.550110    ...      \n",
       "RStoTSV                                   0.077239       0.550110    ...      \n",
       "\n",
       "                             salary  shared_receipt_with_poi  to_messages  \\\n",
       "bonus                      0.523190                 0.549102     0.372997   \n",
       "deferral_payments          0.455884                 0.356696     0.310129   \n",
       "deferred_income           -0.353816                -0.394677    -0.350815   \n",
       "director_fees                   NaN                 1.000000    -1.000000   \n",
       "exercised_stock_options    0.607324                 0.154333     0.079568   \n",
       "expenses                   0.145364                 0.223495     0.155070   \n",
       "from_messages             -0.003541                 0.230855     0.475450   \n",
       "from_poi_to_this_person    0.179055                 0.659264     0.525667   \n",
       "from_this_person_to_poi    0.021288                 0.475748     0.568506   \n",
       "loan_advances              0.535252                 0.291501     0.739805   \n",
       "long_term_incentive        0.484114                 0.178944     0.134277   \n",
       "other                      0.606903                 0.122591     0.040580   \n",
       "poi                        0.264976                 0.228313     0.058954   \n",
       "restricted_stock           0.550824                 0.232660     0.195570   \n",
       "restricted_stock_deferred -0.592576                -0.348405    -0.359420   \n",
       "salary                     1.000000                 0.284995     0.187047   \n",
       "shared_receipt_with_poi    0.284995                 1.000000     0.847990   \n",
       "to_messages                0.187047                 0.847990     1.000000   \n",
       "total_payments             0.579260                 0.191069     0.133834   \n",
       "total_stock_value          0.614736                 0.176314     0.120864   \n",
       "Fromfract                  0.331919                 0.085249    -0.071724   \n",
       "Tofract                   -0.012175                 0.053525     0.068889   \n",
       "SaltoPay                  -0.045731                -0.069747    -0.054354   \n",
       "ESVtoTSV                   0.088880                 0.019029     0.011472   \n",
       "RStoTSV                   -0.037833                 0.144477     0.116968   \n",
       "\n",
       "                           total_payments  total_stock_value  Fromfract  \\\n",
       "bonus                            0.569054           0.509441   0.083181   \n",
       "deferral_payments                0.066774           0.075710   0.570496   \n",
       "deferred_income                 -0.054404          -0.298189  -0.294988   \n",
       "director_fees                    0.317360           0.997476        NaN   \n",
       "exercised_stock_options          0.591690           0.963560   0.162210   \n",
       "expenses                         0.109798           0.034707   0.082202   \n",
       "from_messages                   -0.033089          -0.036310  -0.165410   \n",
       "from_poi_to_this_person          0.154431           0.146366   0.385918   \n",
       "from_this_person_to_poi          0.011556           0.001289  -0.162769   \n",
       "loan_advances                    0.991879           0.962026  -0.218806   \n",
       "long_term_incentive              0.518498           0.495485   0.179776   \n",
       "other                            0.825589           0.627171   0.363396   \n",
       "poi                              0.230102           0.366462   0.187259   \n",
       "restricted_stock                 0.595728           0.855250   0.103377   \n",
       "restricted_stock_deferred        0.941613          -0.819225  -0.116844   \n",
       "salary                           0.579260           0.614736   0.331919   \n",
       "shared_receipt_with_poi          0.191069           0.176314   0.085249   \n",
       "to_messages                      0.133834           0.120864  -0.071724   \n",
       "total_payments                   1.000000           0.668166   0.219607   \n",
       "total_stock_value                0.668166           1.000000   0.151981   \n",
       "Fromfract                        0.219607           0.151981   1.000000   \n",
       "Tofract                          0.012841          -0.044858  -0.026195   \n",
       "SaltoPay                        -0.126481           0.108068   0.054257   \n",
       "ESVtoTSV                         0.073381           0.184985   0.023504   \n",
       "RStoTSV                         -0.025158          -0.174145   0.028471   \n",
       "\n",
       "                            Tofract  SaltoPay  ESVtoTSV   RStoTSV  \n",
       "bonus                      0.178842 -0.324554  0.183681 -0.143934  \n",
       "deferral_payments          0.325110 -0.217174  0.143789 -0.030617  \n",
       "deferred_income           -0.067138 -0.368901 -0.416388  0.148517  \n",
       "director_fees              0.311606       NaN  0.242578  0.122766  \n",
       "exercised_stock_options   -0.071531  0.138878  0.152256 -0.156944  \n",
       "expenses                  -0.049390 -0.065014 -0.074790  0.151776  \n",
       "from_messages              0.262992  0.015336  0.077577 -0.005982  \n",
       "from_poi_to_this_person    0.087685 -0.010016  0.039395  0.106135  \n",
       "from_this_person_to_poi    0.617118 -0.039627  0.006378  0.077239  \n",
       "loan_advances              0.880459 -0.598779 -0.550110  0.550110  \n",
       "long_term_incentive        0.028499 -0.150870  0.216794 -0.171976  \n",
       "other                     -0.097728 -0.232771  0.093553 -0.082525  \n",
       "poi                        0.167990  0.136760 -0.017280  0.087592  \n",
       "restricted_stock          -0.053337 -0.008805  0.035777 -0.011035  \n",
       "restricted_stock_deferred -0.121230 -0.228339 -0.316915 -0.153637  \n",
       "salary                    -0.012175 -0.045731  0.088880 -0.037833  \n",
       "shared_receipt_with_poi    0.053525 -0.069747  0.019029  0.144477  \n",
       "to_messages                0.068889 -0.054354  0.011472  0.116968  \n",
       "total_payments             0.012841 -0.126481  0.073381 -0.025158  \n",
       "total_stock_value         -0.044858  0.108068  0.184985 -0.174145  \n",
       "Fromfract                 -0.026195  0.054257  0.023504  0.028471  \n",
       "Tofract                    1.000000  0.081929  0.097919 -0.011190  \n",
       "SaltoPay                   0.081929  1.000000  0.059432  0.035879  \n",
       "ESVtoTSV                   0.097919  0.059432  1.000000 -0.515542  \n",
       "RStoTSV                   -0.011190  0.035879 -0.515542  1.000000  \n",
       "\n",
       "[25 rows x 25 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.corr(method=\"pearson\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bonus</th>\n",
       "      <th>deferral_payments</th>\n",
       "      <th>deferred_income</th>\n",
       "      <th>director_fees</th>\n",
       "      <th>email_address</th>\n",
       "      <th>exercised_stock_options</th>\n",
       "      <th>expenses</th>\n",
       "      <th>from_messages</th>\n",
       "      <th>from_poi_to_this_person</th>\n",
       "      <th>from_this_person_to_poi</th>\n",
       "      <th>...</th>\n",
       "      <th>salary</th>\n",
       "      <th>shared_receipt_with_poi</th>\n",
       "      <th>to_messages</th>\n",
       "      <th>total_payments</th>\n",
       "      <th>total_stock_value</th>\n",
       "      <th>Fromfract</th>\n",
       "      <th>Tofract</th>\n",
       "      <th>SaltoPay</th>\n",
       "      <th>ESVtoTSV</th>\n",
       "      <th>RStoTSV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>SKILLING JEFFREY K</th>\n",
       "      <td>5600000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>jeff.skilling@enron.com</td>\n",
       "      <td>19250000.0</td>\n",
       "      <td>29336.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1111258.0</td>\n",
       "      <td>2042.0</td>\n",
       "      <td>3627.0</td>\n",
       "      <td>8682716.0</td>\n",
       "      <td>26093672.0</td>\n",
       "      <td>0.814815</td>\n",
       "      <td>0.008271</td>\n",
       "      <td>0.127985</td>\n",
       "      <td>0.737727</td>\n",
       "      <td>0.262273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LAY KENNETH L</th>\n",
       "      <td>7000000.0</td>\n",
       "      <td>202911.0</td>\n",
       "      <td>-300000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>kenneth.lay@enron.com</td>\n",
       "      <td>34348384.0</td>\n",
       "      <td>99832.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>123.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1072321.0</td>\n",
       "      <td>2411.0</td>\n",
       "      <td>4273.0</td>\n",
       "      <td>103559793.0</td>\n",
       "      <td>49110078.0</td>\n",
       "      <td>3.416667</td>\n",
       "      <td>0.003744</td>\n",
       "      <td>0.010355</td>\n",
       "      <td>0.699416</td>\n",
       "      <td>0.300584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FREVERT MARK A</th>\n",
       "      <td>2000000.0</td>\n",
       "      <td>6426990.0</td>\n",
       "      <td>-3367011.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>mark.frevert@enron.com</td>\n",
       "      <td>10433518.0</td>\n",
       "      <td>86987.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1060932.0</td>\n",
       "      <td>2979.0</td>\n",
       "      <td>3275.0</td>\n",
       "      <td>17252530.0</td>\n",
       "      <td>14622185.0</td>\n",
       "      <td>11.523810</td>\n",
       "      <td>0.001832</td>\n",
       "      <td>0.061494</td>\n",
       "      <td>0.713540</td>\n",
       "      <td>0.286460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PICKERING MARK R</th>\n",
       "      <td>300000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>mark.pickering@enron.com</td>\n",
       "      <td>28798.0</td>\n",
       "      <td>31653.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>655037.0</td>\n",
       "      <td>728.0</td>\n",
       "      <td>898.0</td>\n",
       "      <td>1386690.0</td>\n",
       "      <td>28798.0</td>\n",
       "      <td>0.104478</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.472375</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WHALLEY LAWRENCE G</th>\n",
       "      <td>3000000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>greg.whalley@enron.com</td>\n",
       "      <td>3282960.0</td>\n",
       "      <td>57838.0</td>\n",
       "      <td>556.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>...</td>\n",
       "      <td>510364.0</td>\n",
       "      <td>3920.0</td>\n",
       "      <td>6019.0</td>\n",
       "      <td>4677574.0</td>\n",
       "      <td>6079137.0</td>\n",
       "      <td>0.334532</td>\n",
       "      <td>0.003987</td>\n",
       "      <td>0.109109</td>\n",
       "      <td>0.540037</td>\n",
       "      <td>0.459963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DERRICK JR. JAMES V</th>\n",
       "      <td>800000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1284000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>james.derrick@enron.com</td>\n",
       "      <td>8831913.0</td>\n",
       "      <td>51124.0</td>\n",
       "      <td>909.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>...</td>\n",
       "      <td>492375.0</td>\n",
       "      <td>1401.0</td>\n",
       "      <td>2181.0</td>\n",
       "      <td>550981.0</td>\n",
       "      <td>8831913.0</td>\n",
       "      <td>0.070407</td>\n",
       "      <td>0.009170</td>\n",
       "      <td>0.893633</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.202377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FASTOW ANDREW S</th>\n",
       "      <td>1300000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1386055.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>andrew.fastow@enron.com</td>\n",
       "      <td>0.0</td>\n",
       "      <td>55921.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>440698.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2424083.0</td>\n",
       "      <td>1794412.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.181800</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SHERRIFF JOHN R</th>\n",
       "      <td>1500000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>john.sherriff@enron.com</td>\n",
       "      <td>1835558.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>...</td>\n",
       "      <td>428780.0</td>\n",
       "      <td>2103.0</td>\n",
       "      <td>3187.0</td>\n",
       "      <td>4335388.0</td>\n",
       "      <td>3128982.0</td>\n",
       "      <td>0.304348</td>\n",
       "      <td>0.007217</td>\n",
       "      <td>0.098902</td>\n",
       "      <td>0.586631</td>\n",
       "      <td>0.413369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RICE KENNETH D</th>\n",
       "      <td>1750000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-3504386.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>ken.rice@enron.com</td>\n",
       "      <td>19794175.0</td>\n",
       "      <td>46950.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>420636.0</td>\n",
       "      <td>864.0</td>\n",
       "      <td>905.0</td>\n",
       "      <td>505050.0</td>\n",
       "      <td>22542539.0</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>0.004420</td>\n",
       "      <td>0.832860</td>\n",
       "      <td>0.878081</td>\n",
       "      <td>0.121919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CAUSEY RICHARD A</th>\n",
       "      <td>1000000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-235000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>richard.causey@enron.com</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30674.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>...</td>\n",
       "      <td>415189.0</td>\n",
       "      <td>1585.0</td>\n",
       "      <td>1892.0</td>\n",
       "      <td>1868758.0</td>\n",
       "      <td>2502063.0</td>\n",
       "      <td>1.183673</td>\n",
       "      <td>0.006342</td>\n",
       "      <td>0.222174</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KEAN STEVEN J</th>\n",
       "      <td>1000000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>steven.kean@enron.com</td>\n",
       "      <td>2022048.0</td>\n",
       "      <td>41953.0</td>\n",
       "      <td>6759.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>387.0</td>\n",
       "      <td>...</td>\n",
       "      <td>404338.0</td>\n",
       "      <td>3639.0</td>\n",
       "      <td>12754.0</td>\n",
       "      <td>1747522.0</td>\n",
       "      <td>6153642.0</td>\n",
       "      <td>0.020713</td>\n",
       "      <td>0.030343</td>\n",
       "      <td>0.231378</td>\n",
       "      <td>0.328594</td>\n",
       "      <td>0.671406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HAEDICKE MARK E</th>\n",
       "      <td>1150000.0</td>\n",
       "      <td>2157527.0</td>\n",
       "      <td>-934484.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>mark.haedicke@enron.com</td>\n",
       "      <td>608750.0</td>\n",
       "      <td>76169.0</td>\n",
       "      <td>1941.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>...</td>\n",
       "      <td>374125.0</td>\n",
       "      <td>1847.0</td>\n",
       "      <td>4009.0</td>\n",
       "      <td>3859065.0</td>\n",
       "      <td>803094.0</td>\n",
       "      <td>0.092736</td>\n",
       "      <td>0.015216</td>\n",
       "      <td>0.096947</td>\n",
       "      <td>0.758006</td>\n",
       "      <td>0.652687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MCMAHON JEFFREY</th>\n",
       "      <td>2600000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>jeffrey.mcmahon@enron.com</td>\n",
       "      <td>1104054.0</td>\n",
       "      <td>137108.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>...</td>\n",
       "      <td>370448.0</td>\n",
       "      <td>2228.0</td>\n",
       "      <td>2355.0</td>\n",
       "      <td>4099771.0</td>\n",
       "      <td>1662855.0</td>\n",
       "      <td>1.208333</td>\n",
       "      <td>0.011040</td>\n",
       "      <td>0.090358</td>\n",
       "      <td>0.663951</td>\n",
       "      <td>0.336049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>METTS MARK</th>\n",
       "      <td>600000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>mark.metts@enron.com</td>\n",
       "      <td>0.0</td>\n",
       "      <td>94299.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>365788.0</td>\n",
       "      <td>702.0</td>\n",
       "      <td>807.0</td>\n",
       "      <td>1061827.0</td>\n",
       "      <td>585062.0</td>\n",
       "      <td>1.310345</td>\n",
       "      <td>0.001239</td>\n",
       "      <td>0.344489</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DELAINEY DAVID W</th>\n",
       "      <td>3000000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>david.delainey@enron.com</td>\n",
       "      <td>2291113.0</td>\n",
       "      <td>86174.0</td>\n",
       "      <td>3069.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>609.0</td>\n",
       "      <td>...</td>\n",
       "      <td>365163.0</td>\n",
       "      <td>2097.0</td>\n",
       "      <td>3093.0</td>\n",
       "      <td>4747979.0</td>\n",
       "      <td>3614261.0</td>\n",
       "      <td>0.021505</td>\n",
       "      <td>0.196896</td>\n",
       "      <td>0.076909</td>\n",
       "      <td>0.633909</td>\n",
       "      <td>0.366091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MCCONNELL MICHAEL S</th>\n",
       "      <td>1100000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>mike.mcconnell@enron.com</td>\n",
       "      <td>1623010.0</td>\n",
       "      <td>81364.0</td>\n",
       "      <td>2742.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>194.0</td>\n",
       "      <td>...</td>\n",
       "      <td>365038.0</td>\n",
       "      <td>2189.0</td>\n",
       "      <td>3329.0</td>\n",
       "      <td>2101364.0</td>\n",
       "      <td>3101279.0</td>\n",
       "      <td>0.033552</td>\n",
       "      <td>0.058276</td>\n",
       "      <td>0.173715</td>\n",
       "      <td>0.523336</td>\n",
       "      <td>0.476664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WALLS JR ROBERT H</th>\n",
       "      <td>850000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>rob.walls@enron.com</td>\n",
       "      <td>4346544.0</td>\n",
       "      <td>50936.0</td>\n",
       "      <td>146.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>357091.0</td>\n",
       "      <td>215.0</td>\n",
       "      <td>671.0</td>\n",
       "      <td>1798780.0</td>\n",
       "      <td>5898997.0</td>\n",
       "      <td>0.116438</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.198518</td>\n",
       "      <td>0.736828</td>\n",
       "      <td>0.263172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MARTIN AMANDA K</th>\n",
       "      <td>0.0</td>\n",
       "      <td>85430.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>a..martin@enron.com</td>\n",
       "      <td>2070306.0</td>\n",
       "      <td>8211.0</td>\n",
       "      <td>230.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>349487.0</td>\n",
       "      <td>477.0</td>\n",
       "      <td>1522.0</td>\n",
       "      <td>8407016.0</td>\n",
       "      <td>2070306.0</td>\n",
       "      <td>0.034783</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.041571</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LAVORATO JOHN J</th>\n",
       "      <td>8000000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>john.lavorato@enron.com</td>\n",
       "      <td>4158995.0</td>\n",
       "      <td>49537.0</td>\n",
       "      <td>2585.0</td>\n",
       "      <td>528.0</td>\n",
       "      <td>411.0</td>\n",
       "      <td>...</td>\n",
       "      <td>339288.0</td>\n",
       "      <td>3962.0</td>\n",
       "      <td>7259.0</td>\n",
       "      <td>10425757.0</td>\n",
       "      <td>5167144.0</td>\n",
       "      <td>0.204255</td>\n",
       "      <td>0.056619</td>\n",
       "      <td>0.032543</td>\n",
       "      <td>0.804892</td>\n",
       "      <td>0.195108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BUY RICHARD B</th>\n",
       "      <td>900000.0</td>\n",
       "      <td>649584.0</td>\n",
       "      <td>-694862.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>rick.buy@enron.com</td>\n",
       "      <td>2542813.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1053.0</td>\n",
       "      <td>156.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>...</td>\n",
       "      <td>330546.0</td>\n",
       "      <td>2333.0</td>\n",
       "      <td>3523.0</td>\n",
       "      <td>2355702.0</td>\n",
       "      <td>3444470.0</td>\n",
       "      <td>0.148148</td>\n",
       "      <td>0.020153</td>\n",
       "      <td>0.140317</td>\n",
       "      <td>0.738231</td>\n",
       "      <td>0.261769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OLSON CINDY K</th>\n",
       "      <td>750000.0</td>\n",
       "      <td>77716.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>cindy.olson@enron.com</td>\n",
       "      <td>1637034.0</td>\n",
       "      <td>63791.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>...</td>\n",
       "      <td>329078.0</td>\n",
       "      <td>856.0</td>\n",
       "      <td>1184.0</td>\n",
       "      <td>1321557.0</td>\n",
       "      <td>2606763.0</td>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.012669</td>\n",
       "      <td>0.249008</td>\n",
       "      <td>0.627995</td>\n",
       "      <td>0.372005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WHITE JR THOMAS E</th>\n",
       "      <td>450000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>thomas.white@enron.com</td>\n",
       "      <td>1297049.0</td>\n",
       "      <td>81353.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>317543.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1934359.0</td>\n",
       "      <td>15144123.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.164159</td>\n",
       "      <td>0.085647</td>\n",
       "      <td>0.914353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>COX DAVID</th>\n",
       "      <td>800000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-41250.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>chip.cox@enron.com</td>\n",
       "      <td>117551.0</td>\n",
       "      <td>27861.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>314288.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>1101393.0</td>\n",
       "      <td>495633.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.039216</td>\n",
       "      <td>0.285355</td>\n",
       "      <td>0.237173</td>\n",
       "      <td>0.762827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KOENIG MARK E</th>\n",
       "      <td>700000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>mark.koenig@enron.com</td>\n",
       "      <td>671737.0</td>\n",
       "      <td>127017.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>...</td>\n",
       "      <td>309946.0</td>\n",
       "      <td>2271.0</td>\n",
       "      <td>2374.0</td>\n",
       "      <td>1587421.0</td>\n",
       "      <td>1920055.0</td>\n",
       "      <td>0.868852</td>\n",
       "      <td>0.006318</td>\n",
       "      <td>0.195251</td>\n",
       "      <td>0.349853</td>\n",
       "      <td>0.650147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FALLON JAMES B</th>\n",
       "      <td>2500000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>jim.fallon@enron.com</td>\n",
       "      <td>940257.0</td>\n",
       "      <td>95924.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>...</td>\n",
       "      <td>304588.0</td>\n",
       "      <td>1604.0</td>\n",
       "      <td>1755.0</td>\n",
       "      <td>3676340.0</td>\n",
       "      <td>2332399.0</td>\n",
       "      <td>0.560000</td>\n",
       "      <td>0.021083</td>\n",
       "      <td>0.082851</td>\n",
       "      <td>0.403129</td>\n",
       "      <td>0.596871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SHANKMAN JEFFREY A</th>\n",
       "      <td>2000000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>jeffrey.shankman@enron.com</td>\n",
       "      <td>1441898.0</td>\n",
       "      <td>178979.0</td>\n",
       "      <td>2681.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>...</td>\n",
       "      <td>304110.0</td>\n",
       "      <td>1730.0</td>\n",
       "      <td>3221.0</td>\n",
       "      <td>3038702.0</td>\n",
       "      <td>2072035.0</td>\n",
       "      <td>0.035062</td>\n",
       "      <td>0.025768</td>\n",
       "      <td>0.100079</td>\n",
       "      <td>0.695885</td>\n",
       "      <td>0.304115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UMANOFF ADAM S</th>\n",
       "      <td>788750.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>adam.umanoff@enron.com</td>\n",
       "      <td>0.0</td>\n",
       "      <td>53122.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>288589.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>1130461.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.255284</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>JACKSON CHARLENE R</th>\n",
       "      <td>250000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>charlene.jackson@enron.com</td>\n",
       "      <td>185063.0</td>\n",
       "      <td>10181.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>...</td>\n",
       "      <td>288558.0</td>\n",
       "      <td>117.0</td>\n",
       "      <td>258.0</td>\n",
       "      <td>551174.0</td>\n",
       "      <td>725735.0</td>\n",
       "      <td>0.446429</td>\n",
       "      <td>0.073643</td>\n",
       "      <td>0.523533</td>\n",
       "      <td>0.255001</td>\n",
       "      <td>0.744999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>COLWELL WESLEY</th>\n",
       "      <td>1200000.0</td>\n",
       "      <td>27610.0</td>\n",
       "      <td>-144062.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>wes.colwell@enron.com</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16514.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>240.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>...</td>\n",
       "      <td>288542.0</td>\n",
       "      <td>1132.0</td>\n",
       "      <td>1758.0</td>\n",
       "      <td>1490344.0</td>\n",
       "      <td>698242.0</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.006257</td>\n",
       "      <td>0.193608</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BOWEN JR RAYMOND M</th>\n",
       "      <td>1350000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-833.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>raymond.bowen@enron.com</td>\n",
       "      <td>0.0</td>\n",
       "      <td>65907.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>...</td>\n",
       "      <td>278601.0</td>\n",
       "      <td>1593.0</td>\n",
       "      <td>1858.0</td>\n",
       "      <td>2669589.0</td>\n",
       "      <td>252055.0</td>\n",
       "      <td>5.185185</td>\n",
       "      <td>0.008073</td>\n",
       "      <td>0.104361</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DUNCAN JOHN H</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-25000.0</td>\n",
       "      <td>102492.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>371750.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>77492.0</td>\n",
       "      <td>371750.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LEMAISTRE CHARLES</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-25000.0</td>\n",
       "      <td>112492.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>412878.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>87492.0</td>\n",
       "      <td>412878.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PIRO JIM</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>jim.piro@enron.com</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>47304.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.017241</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WROBEL BRUCE</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>139130.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>139130.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MEYER JEROME J</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-38346.0</td>\n",
       "      <td>38346.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2151.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2151.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MCDONALD REBECCA</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>rebecca.mcdonald@enron.com</td>\n",
       "      <td>757301.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>720.0</td>\n",
       "      <td>894.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1691366.0</td>\n",
       "      <td>4.153846</td>\n",
       "      <td>0.001119</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.447745</td>\n",
       "      <td>0.552255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SCRIMSHAW MATTHEW</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>matthew.scrimshaw@enron.com</td>\n",
       "      <td>759557.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>759557.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GATHMANN WILLIAM D</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1753766.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1945360.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.901512</td>\n",
       "      <td>0.135714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GILLIS JOHN</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9803.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>85641.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.114466</td>\n",
       "      <td>0.885534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MORAN MICHAEL P</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>michael.moran@enron.com</td>\n",
       "      <td>59539.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>127.0</td>\n",
       "      <td>672.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>221141.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.269235</td>\n",
       "      <td>0.730765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FOY JOE</th>\n",
       "      <td>0.0</td>\n",
       "      <td>181755.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>tracy.foy@enron.com</td>\n",
       "      <td>343434.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>181755.0</td>\n",
       "      <td>343434.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PEREIRA PAULO V. FERRAZ</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-101250.0</td>\n",
       "      <td>101250.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27942.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27942.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BLAKE JR. NORMAN P</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-113784.0</td>\n",
       "      <td>113784.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1279.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1279.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SHERRICK JEFFREY B</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>jeffrey.sherrick@enron.com</td>\n",
       "      <td>1426469.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>583.0</td>\n",
       "      <td>613.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1832468.0</td>\n",
       "      <td>1.560000</td>\n",
       "      <td>0.029364</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.778441</td>\n",
       "      <td>0.221559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PRENTICE JAMES</th>\n",
       "      <td>0.0</td>\n",
       "      <td>564348.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>james.prentice@enron.com</td>\n",
       "      <td>886231.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>564348.0</td>\n",
       "      <td>1095040.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.809314</td>\n",
       "      <td>0.190686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NOLES JAMES L</th>\n",
       "      <td>0.0</td>\n",
       "      <td>774401.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>774401.0</td>\n",
       "      <td>368705.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.256454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FOWLER PEGGY</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>kulvinder.fowler@enron.com</td>\n",
       "      <td>1324578.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>517.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1884748.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.702788</td>\n",
       "      <td>0.297212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CHRISTODOULOU DIOMEDES</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>diomedes.christodoulou@enron.com</td>\n",
       "      <td>5127155.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6077885.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.843576</td>\n",
       "      <td>0.156424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>JAEDICKE ROBERT</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-25000.0</td>\n",
       "      <td>108750.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>431750.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>83750.0</td>\n",
       "      <td>431750.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.102126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WINOKUR JR. HERBERT S</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-25000.0</td>\n",
       "      <td>108579.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1413.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>84992.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BROWN MICHAEL</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>michael.brown@enron.com</td>\n",
       "      <td>0.0</td>\n",
       "      <td>49288.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>761.0</td>\n",
       "      <td>1486.0</td>\n",
       "      <td>49288.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.317073</td>\n",
       "      <td>0.000673</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BADUM JAMES P</th>\n",
       "      <td>0.0</td>\n",
       "      <td>178980.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>257817.0</td>\n",
       "      <td>3486.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>182466.0</td>\n",
       "      <td>257817.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HUGHES JAMES A</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>james.hughes@enron.com</td>\n",
       "      <td>754966.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>589.0</td>\n",
       "      <td>719.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1118394.0</td>\n",
       "      <td>1.029412</td>\n",
       "      <td>0.006954</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.675045</td>\n",
       "      <td>0.324955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BHATNAGAR SANJAY</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>137864.0</td>\n",
       "      <td>sanjay.bhatnagar@enron.com</td>\n",
       "      <td>2604490.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>463.0</td>\n",
       "      <td>523.0</td>\n",
       "      <td>15456290.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001912</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YEAP SOON</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>192758.0</td>\n",
       "      <td>55097.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>55097.0</td>\n",
       "      <td>192758.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HIRKO JOSEPH</th>\n",
       "      <td>0.0</td>\n",
       "      <td>10259.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>joe.hirko@enron.com</td>\n",
       "      <td>30766064.0</td>\n",
       "      <td>77978.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>91093.0</td>\n",
       "      <td>30766064.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HAYSLETT RODERICK J</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>rod.hayslett@enron.com</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1061.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>571.0</td>\n",
       "      <td>2649.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>346663.0</td>\n",
       "      <td>0.032988</td>\n",
       "      <td>0.014345</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FUGH JOHN L</th>\n",
       "      <td>0.0</td>\n",
       "      <td>50591.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>176378.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50591.0</td>\n",
       "      <td>176378.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SAVAGE FRANK</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-121284.0</td>\n",
       "      <td>125034.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3750.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GRAMM WENDY L</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>119292.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>119292.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>143 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             bonus  deferral_payments  deferred_income  \\\n",
       "SKILLING JEFFREY K       5600000.0                0.0              0.0   \n",
       "LAY KENNETH L            7000000.0           202911.0        -300000.0   \n",
       "FREVERT MARK A           2000000.0          6426990.0       -3367011.0   \n",
       "PICKERING MARK R          300000.0                0.0              0.0   \n",
       "WHALLEY LAWRENCE G       3000000.0                0.0              0.0   \n",
       "DERRICK JR. JAMES V       800000.0                0.0       -1284000.0   \n",
       "FASTOW ANDREW S          1300000.0                0.0       -1386055.0   \n",
       "SHERRIFF JOHN R          1500000.0                0.0              0.0   \n",
       "RICE KENNETH D           1750000.0                0.0       -3504386.0   \n",
       "CAUSEY RICHARD A         1000000.0                0.0        -235000.0   \n",
       "KEAN STEVEN J            1000000.0                0.0              0.0   \n",
       "HAEDICKE MARK E          1150000.0          2157527.0        -934484.0   \n",
       "MCMAHON JEFFREY          2600000.0                0.0              0.0   \n",
       "METTS MARK                600000.0                0.0              0.0   \n",
       "DELAINEY DAVID W         3000000.0                0.0              0.0   \n",
       "MCCONNELL MICHAEL S      1100000.0                0.0              0.0   \n",
       "WALLS JR ROBERT H         850000.0                0.0              0.0   \n",
       "MARTIN AMANDA K                0.0            85430.0              0.0   \n",
       "LAVORATO JOHN J          8000000.0                0.0              0.0   \n",
       "BUY RICHARD B             900000.0           649584.0        -694862.0   \n",
       "OLSON CINDY K             750000.0            77716.0              0.0   \n",
       "WHITE JR THOMAS E         450000.0                0.0              0.0   \n",
       "COX DAVID                 800000.0                0.0         -41250.0   \n",
       "KOENIG MARK E             700000.0                0.0              0.0   \n",
       "FALLON JAMES B           2500000.0                0.0              0.0   \n",
       "SHANKMAN JEFFREY A       2000000.0                0.0              0.0   \n",
       "UMANOFF ADAM S            788750.0                0.0              0.0   \n",
       "JACKSON CHARLENE R        250000.0                0.0              0.0   \n",
       "COLWELL WESLEY           1200000.0            27610.0        -144062.0   \n",
       "BOWEN JR RAYMOND M       1350000.0                0.0           -833.0   \n",
       "...                            ...                ...              ...   \n",
       "DUNCAN JOHN H                  0.0                0.0         -25000.0   \n",
       "LEMAISTRE CHARLES              0.0                0.0         -25000.0   \n",
       "PIRO JIM                       0.0                0.0              0.0   \n",
       "WROBEL BRUCE                   0.0                0.0              0.0   \n",
       "MEYER JEROME J                 0.0                0.0         -38346.0   \n",
       "MCDONALD REBECCA               0.0                0.0              0.0   \n",
       "SCRIMSHAW MATTHEW              0.0                0.0              0.0   \n",
       "GATHMANN WILLIAM D             0.0                0.0              0.0   \n",
       "GILLIS JOHN                    0.0                0.0              0.0   \n",
       "MORAN MICHAEL P                0.0                0.0              0.0   \n",
       "FOY JOE                        0.0           181755.0              0.0   \n",
       "PEREIRA PAULO V. FERRAZ        0.0                0.0        -101250.0   \n",
       "BLAKE JR. NORMAN P             0.0                0.0        -113784.0   \n",
       "SHERRICK JEFFREY B             0.0                0.0              0.0   \n",
       "PRENTICE JAMES                 0.0           564348.0              0.0   \n",
       "NOLES JAMES L                  0.0           774401.0              0.0   \n",
       "FOWLER PEGGY                   0.0                0.0              0.0   \n",
       "CHRISTODOULOU DIOMEDES         0.0                0.0              0.0   \n",
       "JAEDICKE ROBERT                0.0                0.0         -25000.0   \n",
       "WINOKUR JR. HERBERT S          0.0                0.0         -25000.0   \n",
       "BROWN MICHAEL                  0.0                0.0              0.0   \n",
       "BADUM JAMES P                  0.0           178980.0              0.0   \n",
       "HUGHES JAMES A                 0.0                0.0              0.0   \n",
       "BHATNAGAR SANJAY               0.0                0.0              0.0   \n",
       "YEAP SOON                      0.0                0.0              0.0   \n",
       "HIRKO JOSEPH                   0.0            10259.0              0.0   \n",
       "HAYSLETT RODERICK J            0.0                0.0              0.0   \n",
       "FUGH JOHN L                    0.0            50591.0              0.0   \n",
       "SAVAGE FRANK                   0.0                0.0        -121284.0   \n",
       "GRAMM WENDY L                  0.0                0.0              0.0   \n",
       "\n",
       "                         director_fees                     email_address  \\\n",
       "SKILLING JEFFREY K                 0.0           jeff.skilling@enron.com   \n",
       "LAY KENNETH L                      0.0             kenneth.lay@enron.com   \n",
       "FREVERT MARK A                     0.0            mark.frevert@enron.com   \n",
       "PICKERING MARK R                   0.0          mark.pickering@enron.com   \n",
       "WHALLEY LAWRENCE G                 0.0            greg.whalley@enron.com   \n",
       "DERRICK JR. JAMES V                0.0           james.derrick@enron.com   \n",
       "FASTOW ANDREW S                    0.0           andrew.fastow@enron.com   \n",
       "SHERRIFF JOHN R                    0.0           john.sherriff@enron.com   \n",
       "RICE KENNETH D                     0.0                ken.rice@enron.com   \n",
       "CAUSEY RICHARD A                   0.0          richard.causey@enron.com   \n",
       "KEAN STEVEN J                      0.0             steven.kean@enron.com   \n",
       "HAEDICKE MARK E                    0.0           mark.haedicke@enron.com   \n",
       "MCMAHON JEFFREY                    0.0         jeffrey.mcmahon@enron.com   \n",
       "METTS MARK                         0.0              mark.metts@enron.com   \n",
       "DELAINEY DAVID W                   0.0          david.delainey@enron.com   \n",
       "MCCONNELL MICHAEL S                0.0          mike.mcconnell@enron.com   \n",
       "WALLS JR ROBERT H                  0.0               rob.walls@enron.com   \n",
       "MARTIN AMANDA K                    0.0               a..martin@enron.com   \n",
       "LAVORATO JOHN J                    0.0           john.lavorato@enron.com   \n",
       "BUY RICHARD B                      0.0                rick.buy@enron.com   \n",
       "OLSON CINDY K                      0.0             cindy.olson@enron.com   \n",
       "WHITE JR THOMAS E                  0.0            thomas.white@enron.com   \n",
       "COX DAVID                          0.0                chip.cox@enron.com   \n",
       "KOENIG MARK E                      0.0             mark.koenig@enron.com   \n",
       "FALLON JAMES B                     0.0              jim.fallon@enron.com   \n",
       "SHANKMAN JEFFREY A                 0.0        jeffrey.shankman@enron.com   \n",
       "UMANOFF ADAM S                     0.0            adam.umanoff@enron.com   \n",
       "JACKSON CHARLENE R                 0.0        charlene.jackson@enron.com   \n",
       "COLWELL WESLEY                     0.0             wes.colwell@enron.com   \n",
       "BOWEN JR RAYMOND M                 0.0           raymond.bowen@enron.com   \n",
       "...                                ...                               ...   \n",
       "DUNCAN JOHN H                 102492.0                               NaN   \n",
       "LEMAISTRE CHARLES             112492.0                               NaN   \n",
       "PIRO JIM                           0.0                jim.piro@enron.com   \n",
       "WROBEL BRUCE                       0.0                               NaN   \n",
       "MEYER JEROME J                 38346.0                               NaN   \n",
       "MCDONALD REBECCA                   0.0        rebecca.mcdonald@enron.com   \n",
       "SCRIMSHAW MATTHEW                  0.0       matthew.scrimshaw@enron.com   \n",
       "GATHMANN WILLIAM D                 0.0                               NaN   \n",
       "GILLIS JOHN                        0.0                               NaN   \n",
       "MORAN MICHAEL P                    0.0           michael.moran@enron.com   \n",
       "FOY JOE                            0.0               tracy.foy@enron.com   \n",
       "PEREIRA PAULO V. FERRAZ       101250.0                               NaN   \n",
       "BLAKE JR. NORMAN P            113784.0                               NaN   \n",
       "SHERRICK JEFFREY B                 0.0        jeffrey.sherrick@enron.com   \n",
       "PRENTICE JAMES                     0.0          james.prentice@enron.com   \n",
       "NOLES JAMES L                      0.0                               NaN   \n",
       "FOWLER PEGGY                       0.0        kulvinder.fowler@enron.com   \n",
       "CHRISTODOULOU DIOMEDES             0.0  diomedes.christodoulou@enron.com   \n",
       "JAEDICKE ROBERT               108750.0                               NaN   \n",
       "WINOKUR JR. HERBERT S         108579.0                               NaN   \n",
       "BROWN MICHAEL                      0.0           michael.brown@enron.com   \n",
       "BADUM JAMES P                      0.0                               NaN   \n",
       "HUGHES JAMES A                     0.0            james.hughes@enron.com   \n",
       "BHATNAGAR SANJAY              137864.0        sanjay.bhatnagar@enron.com   \n",
       "YEAP SOON                          0.0                               NaN   \n",
       "HIRKO JOSEPH                       0.0               joe.hirko@enron.com   \n",
       "HAYSLETT RODERICK J                0.0            rod.hayslett@enron.com   \n",
       "FUGH JOHN L                        0.0                               NaN   \n",
       "SAVAGE FRANK                  125034.0                               NaN   \n",
       "GRAMM WENDY L                 119292.0                               NaN   \n",
       "\n",
       "                         exercised_stock_options  expenses  from_messages  \\\n",
       "SKILLING JEFFREY K                    19250000.0   29336.0          108.0   \n",
       "LAY KENNETH L                         34348384.0   99832.0           36.0   \n",
       "FREVERT MARK A                        10433518.0   86987.0           21.0   \n",
       "PICKERING MARK R                         28798.0   31653.0           67.0   \n",
       "WHALLEY LAWRENCE G                     3282960.0   57838.0          556.0   \n",
       "DERRICK JR. JAMES V                    8831913.0   51124.0          909.0   \n",
       "FASTOW ANDREW S                              0.0   55921.0            0.0   \n",
       "SHERRIFF JOHN R                        1835558.0       0.0           92.0   \n",
       "RICE KENNETH D                        19794175.0   46950.0           18.0   \n",
       "CAUSEY RICHARD A                             0.0   30674.0           49.0   \n",
       "KEAN STEVEN J                          2022048.0   41953.0         6759.0   \n",
       "HAEDICKE MARK E                         608750.0   76169.0         1941.0   \n",
       "MCMAHON JEFFREY                        1104054.0  137108.0           48.0   \n",
       "METTS MARK                                   0.0   94299.0           29.0   \n",
       "DELAINEY DAVID W                       2291113.0   86174.0         3069.0   \n",
       "MCCONNELL MICHAEL S                    1623010.0   81364.0         2742.0   \n",
       "WALLS JR ROBERT H                      4346544.0   50936.0          146.0   \n",
       "MARTIN AMANDA K                        2070306.0    8211.0          230.0   \n",
       "LAVORATO JOHN J                        4158995.0   49537.0         2585.0   \n",
       "BUY RICHARD B                          2542813.0       0.0         1053.0   \n",
       "OLSON CINDY K                          1637034.0   63791.0           52.0   \n",
       "WHITE JR THOMAS E                      1297049.0   81353.0            0.0   \n",
       "COX DAVID                               117551.0   27861.0           33.0   \n",
       "KOENIG MARK E                           671737.0  127017.0           61.0   \n",
       "FALLON JAMES B                          940257.0   95924.0           75.0   \n",
       "SHANKMAN JEFFREY A                     1441898.0  178979.0         2681.0   \n",
       "UMANOFF ADAM S                               0.0   53122.0           18.0   \n",
       "JACKSON CHARLENE R                      185063.0   10181.0           56.0   \n",
       "COLWELL WESLEY                               0.0   16514.0           40.0   \n",
       "BOWEN JR RAYMOND M                           0.0   65907.0           27.0   \n",
       "...                                          ...       ...            ...   \n",
       "DUNCAN JOHN H                           371750.0       0.0            0.0   \n",
       "LEMAISTRE CHARLES                       412878.0       0.0            0.0   \n",
       "PIRO JIM                                     0.0       0.0           16.0   \n",
       "WROBEL BRUCE                            139130.0       0.0            0.0   \n",
       "MEYER JEROME J                               0.0    2151.0            0.0   \n",
       "MCDONALD REBECCA                        757301.0       0.0           13.0   \n",
       "SCRIMSHAW MATTHEW                       759557.0       0.0            0.0   \n",
       "GATHMANN WILLIAM D                     1753766.0       0.0            0.0   \n",
       "GILLIS JOHN                               9803.0       0.0            0.0   \n",
       "MORAN MICHAEL P                          59539.0       0.0           19.0   \n",
       "FOY JOE                                 343434.0       0.0           13.0   \n",
       "PEREIRA PAULO V. FERRAZ                      0.0   27942.0            0.0   \n",
       "BLAKE JR. NORMAN P                           0.0    1279.0            0.0   \n",
       "SHERRICK JEFFREY B                     1426469.0       0.0           25.0   \n",
       "PRENTICE JAMES                          886231.0       0.0            0.0   \n",
       "NOLES JAMES L                                0.0       0.0            0.0   \n",
       "FOWLER PEGGY                           1324578.0       0.0           36.0   \n",
       "CHRISTODOULOU DIOMEDES                 5127155.0       0.0            0.0   \n",
       "JAEDICKE ROBERT                         431750.0       0.0            0.0   \n",
       "WINOKUR JR. HERBERT S                        0.0    1413.0            0.0   \n",
       "BROWN MICHAEL                                0.0   49288.0           41.0   \n",
       "BADUM JAMES P                           257817.0    3486.0            0.0   \n",
       "HUGHES JAMES A                          754966.0       0.0           34.0   \n",
       "BHATNAGAR SANJAY                       2604490.0       0.0           29.0   \n",
       "YEAP SOON                               192758.0   55097.0            0.0   \n",
       "HIRKO JOSEPH                          30766064.0   77978.0            0.0   \n",
       "HAYSLETT RODERICK J                          0.0       0.0         1061.0   \n",
       "FUGH JOHN L                             176378.0       0.0            0.0   \n",
       "SAVAGE FRANK                                 0.0       0.0            0.0   \n",
       "GRAMM WENDY L                                0.0       0.0            0.0   \n",
       "\n",
       "                         from_poi_to_this_person  from_this_person_to_poi  \\\n",
       "SKILLING JEFFREY K                          88.0                     30.0   \n",
       "LAY KENNETH L                              123.0                     16.0   \n",
       "FREVERT MARK A                             242.0                      6.0   \n",
       "PICKERING MARK R                             7.0                      0.0   \n",
       "WHALLEY LAWRENCE G                         186.0                     24.0   \n",
       "DERRICK JR. JAMES V                         64.0                     20.0   \n",
       "FASTOW ANDREW S                              0.0                      0.0   \n",
       "SHERRIFF JOHN R                             28.0                     23.0   \n",
       "RICE KENNETH D                              42.0                      4.0   \n",
       "CAUSEY RICHARD A                            58.0                     12.0   \n",
       "KEAN STEVEN J                              140.0                    387.0   \n",
       "HAEDICKE MARK E                            180.0                     61.0   \n",
       "MCMAHON JEFFREY                             58.0                     26.0   \n",
       "METTS MARK                                  38.0                      1.0   \n",
       "DELAINEY DAVID W                            66.0                    609.0   \n",
       "MCCONNELL MICHAEL S                         92.0                    194.0   \n",
       "WALLS JR ROBERT H                           17.0                      0.0   \n",
       "MARTIN AMANDA K                              8.0                      0.0   \n",
       "LAVORATO JOHN J                            528.0                    411.0   \n",
       "BUY RICHARD B                              156.0                     71.0   \n",
       "OLSON CINDY K                               20.0                     15.0   \n",
       "WHITE JR THOMAS E                            0.0                      0.0   \n",
       "COX DAVID                                    0.0                      4.0   \n",
       "KOENIG MARK E                               53.0                     15.0   \n",
       "FALLON JAMES B                              42.0                     37.0   \n",
       "SHANKMAN JEFFREY A                          94.0                     83.0   \n",
       "UMANOFF ADAM S                              12.0                      0.0   \n",
       "JACKSON CHARLENE R                          25.0                     19.0   \n",
       "COLWELL WESLEY                             240.0                     11.0   \n",
       "BOWEN JR RAYMOND M                         140.0                     15.0   \n",
       "...                                          ...                      ...   \n",
       "DUNCAN JOHN H                                0.0                      0.0   \n",
       "LEMAISTRE CHARLES                            0.0                      0.0   \n",
       "PIRO JIM                                     0.0                      1.0   \n",
       "WROBEL BRUCE                                 0.0                      0.0   \n",
       "MEYER JEROME J                               0.0                      0.0   \n",
       "MCDONALD REBECCA                            54.0                      1.0   \n",
       "SCRIMSHAW MATTHEW                            0.0                      0.0   \n",
       "GATHMANN WILLIAM D                           0.0                      0.0   \n",
       "GILLIS JOHN                                  0.0                      0.0   \n",
       "MORAN MICHAEL P                              0.0                      0.0   \n",
       "FOY JOE                                      0.0                      0.0   \n",
       "PEREIRA PAULO V. FERRAZ                      0.0                      0.0   \n",
       "BLAKE JR. NORMAN P                           0.0                      0.0   \n",
       "SHERRICK JEFFREY B                          39.0                     18.0   \n",
       "PRENTICE JAMES                               0.0                      0.0   \n",
       "NOLES JAMES L                                0.0                      0.0   \n",
       "FOWLER PEGGY                                 0.0                      0.0   \n",
       "CHRISTODOULOU DIOMEDES                       0.0                      0.0   \n",
       "JAEDICKE ROBERT                              0.0                      0.0   \n",
       "WINOKUR JR. HERBERT S                        0.0                      0.0   \n",
       "BROWN MICHAEL                               13.0                      1.0   \n",
       "BADUM JAMES P                                0.0                      0.0   \n",
       "HUGHES JAMES A                              35.0                      5.0   \n",
       "BHATNAGAR SANJAY                             0.0                      1.0   \n",
       "YEAP SOON                                    0.0                      0.0   \n",
       "HIRKO JOSEPH                                 0.0                      0.0   \n",
       "HAYSLETT RODERICK J                         35.0                     38.0   \n",
       "FUGH JOHN L                                  0.0                      0.0   \n",
       "SAVAGE FRANK                                 0.0                      0.0   \n",
       "GRAMM WENDY L                                0.0                      0.0   \n",
       "\n",
       "                           ...        salary  shared_receipt_with_poi  \\\n",
       "SKILLING JEFFREY K         ...     1111258.0                   2042.0   \n",
       "LAY KENNETH L              ...     1072321.0                   2411.0   \n",
       "FREVERT MARK A             ...     1060932.0                   2979.0   \n",
       "PICKERING MARK R           ...      655037.0                    728.0   \n",
       "WHALLEY LAWRENCE G         ...      510364.0                   3920.0   \n",
       "DERRICK JR. JAMES V        ...      492375.0                   1401.0   \n",
       "FASTOW ANDREW S            ...      440698.0                      0.0   \n",
       "SHERRIFF JOHN R            ...      428780.0                   2103.0   \n",
       "RICE KENNETH D             ...      420636.0                    864.0   \n",
       "CAUSEY RICHARD A           ...      415189.0                   1585.0   \n",
       "KEAN STEVEN J              ...      404338.0                   3639.0   \n",
       "HAEDICKE MARK E            ...      374125.0                   1847.0   \n",
       "MCMAHON JEFFREY            ...      370448.0                   2228.0   \n",
       "METTS MARK                 ...      365788.0                    702.0   \n",
       "DELAINEY DAVID W           ...      365163.0                   2097.0   \n",
       "MCCONNELL MICHAEL S        ...      365038.0                   2189.0   \n",
       "WALLS JR ROBERT H          ...      357091.0                    215.0   \n",
       "MARTIN AMANDA K            ...      349487.0                    477.0   \n",
       "LAVORATO JOHN J            ...      339288.0                   3962.0   \n",
       "BUY RICHARD B              ...      330546.0                   2333.0   \n",
       "OLSON CINDY K              ...      329078.0                    856.0   \n",
       "WHITE JR THOMAS E          ...      317543.0                      0.0   \n",
       "COX DAVID                  ...      314288.0                     71.0   \n",
       "KOENIG MARK E              ...      309946.0                   2271.0   \n",
       "FALLON JAMES B             ...      304588.0                   1604.0   \n",
       "SHANKMAN JEFFREY A         ...      304110.0                   1730.0   \n",
       "UMANOFF ADAM S             ...      288589.0                     41.0   \n",
       "JACKSON CHARLENE R         ...      288558.0                    117.0   \n",
       "COLWELL WESLEY             ...      288542.0                   1132.0   \n",
       "BOWEN JR RAYMOND M         ...      278601.0                   1593.0   \n",
       "...                        ...           ...                      ...   \n",
       "DUNCAN JOHN H              ...           0.0                      0.0   \n",
       "LEMAISTRE CHARLES          ...           0.0                      0.0   \n",
       "PIRO JIM                   ...           0.0                      3.0   \n",
       "WROBEL BRUCE               ...           0.0                      0.0   \n",
       "MEYER JEROME J             ...           0.0                      0.0   \n",
       "MCDONALD REBECCA           ...           0.0                    720.0   \n",
       "SCRIMSHAW MATTHEW          ...           0.0                      0.0   \n",
       "GATHMANN WILLIAM D         ...           0.0                      0.0   \n",
       "GILLIS JOHN                ...           0.0                      0.0   \n",
       "MORAN MICHAEL P            ...           0.0                    127.0   \n",
       "FOY JOE                    ...           0.0                      2.0   \n",
       "PEREIRA PAULO V. FERRAZ    ...           0.0                      0.0   \n",
       "BLAKE JR. NORMAN P         ...           0.0                      0.0   \n",
       "SHERRICK JEFFREY B         ...           0.0                    583.0   \n",
       "PRENTICE JAMES             ...           0.0                      0.0   \n",
       "NOLES JAMES L              ...           0.0                      0.0   \n",
       "FOWLER PEGGY               ...           0.0                     10.0   \n",
       "CHRISTODOULOU DIOMEDES     ...           0.0                      0.0   \n",
       "JAEDICKE ROBERT            ...           0.0                      0.0   \n",
       "WINOKUR JR. HERBERT S      ...           0.0                      0.0   \n",
       "BROWN MICHAEL              ...           0.0                    761.0   \n",
       "BADUM JAMES P              ...           0.0                      0.0   \n",
       "HUGHES JAMES A             ...           0.0                    589.0   \n",
       "BHATNAGAR SANJAY           ...           0.0                    463.0   \n",
       "YEAP SOON                  ...           0.0                      0.0   \n",
       "HIRKO JOSEPH               ...           0.0                      0.0   \n",
       "HAYSLETT RODERICK J        ...           0.0                    571.0   \n",
       "FUGH JOHN L                ...           0.0                      0.0   \n",
       "SAVAGE FRANK               ...           0.0                      0.0   \n",
       "GRAMM WENDY L              ...           0.0                      0.0   \n",
       "\n",
       "                         to_messages  total_payments  total_stock_value  \\\n",
       "SKILLING JEFFREY K            3627.0       8682716.0         26093672.0   \n",
       "LAY KENNETH L                 4273.0     103559793.0         49110078.0   \n",
       "FREVERT MARK A                3275.0      17252530.0         14622185.0   \n",
       "PICKERING MARK R               898.0       1386690.0            28798.0   \n",
       "WHALLEY LAWRENCE G            6019.0       4677574.0          6079137.0   \n",
       "DERRICK JR. JAMES V           2181.0        550981.0          8831913.0   \n",
       "FASTOW ANDREW S                  0.0       2424083.0          1794412.0   \n",
       "SHERRIFF JOHN R               3187.0       4335388.0          3128982.0   \n",
       "RICE KENNETH D                 905.0        505050.0         22542539.0   \n",
       "CAUSEY RICHARD A              1892.0       1868758.0          2502063.0   \n",
       "KEAN STEVEN J                12754.0       1747522.0          6153642.0   \n",
       "HAEDICKE MARK E               4009.0       3859065.0           803094.0   \n",
       "MCMAHON JEFFREY               2355.0       4099771.0          1662855.0   \n",
       "METTS MARK                     807.0       1061827.0           585062.0   \n",
       "DELAINEY DAVID W              3093.0       4747979.0          3614261.0   \n",
       "MCCONNELL MICHAEL S           3329.0       2101364.0          3101279.0   \n",
       "WALLS JR ROBERT H              671.0       1798780.0          5898997.0   \n",
       "MARTIN AMANDA K               1522.0       8407016.0          2070306.0   \n",
       "LAVORATO JOHN J               7259.0      10425757.0          5167144.0   \n",
       "BUY RICHARD B                 3523.0       2355702.0          3444470.0   \n",
       "OLSON CINDY K                 1184.0       1321557.0          2606763.0   \n",
       "WHITE JR THOMAS E                0.0       1934359.0         15144123.0   \n",
       "COX DAVID                      102.0       1101393.0           495633.0   \n",
       "KOENIG MARK E                 2374.0       1587421.0          1920055.0   \n",
       "FALLON JAMES B                1755.0       3676340.0          2332399.0   \n",
       "SHANKMAN JEFFREY A            3221.0       3038702.0          2072035.0   \n",
       "UMANOFF ADAM S                 111.0       1130461.0                0.0   \n",
       "JACKSON CHARLENE R             258.0        551174.0           725735.0   \n",
       "COLWELL WESLEY                1758.0       1490344.0           698242.0   \n",
       "BOWEN JR RAYMOND M            1858.0       2669589.0           252055.0   \n",
       "...                              ...             ...                ...   \n",
       "DUNCAN JOHN H                    0.0         77492.0           371750.0   \n",
       "LEMAISTRE CHARLES                0.0         87492.0           412878.0   \n",
       "PIRO JIM                        58.0             0.0            47304.0   \n",
       "WROBEL BRUCE                     0.0             0.0           139130.0   \n",
       "MEYER JEROME J                   0.0          2151.0                0.0   \n",
       "MCDONALD REBECCA               894.0             0.0          1691366.0   \n",
       "SCRIMSHAW MATTHEW                0.0             0.0           759557.0   \n",
       "GATHMANN WILLIAM D               0.0             0.0          1945360.0   \n",
       "GILLIS JOHN                      0.0             0.0            85641.0   \n",
       "MORAN MICHAEL P                672.0             0.0           221141.0   \n",
       "FOY JOE                         57.0        181755.0           343434.0   \n",
       "PEREIRA PAULO V. FERRAZ          0.0         27942.0                0.0   \n",
       "BLAKE JR. NORMAN P               0.0          1279.0                0.0   \n",
       "SHERRICK JEFFREY B             613.0             0.0          1832468.0   \n",
       "PRENTICE JAMES                   0.0        564348.0          1095040.0   \n",
       "NOLES JAMES L                    0.0        774401.0           368705.0   \n",
       "FOWLER PEGGY                   517.0             0.0          1884748.0   \n",
       "CHRISTODOULOU DIOMEDES           0.0             0.0          6077885.0   \n",
       "JAEDICKE ROBERT                  0.0         83750.0           431750.0   \n",
       "WINOKUR JR. HERBERT S            0.0         84992.0                0.0   \n",
       "BROWN MICHAEL                 1486.0         49288.0                0.0   \n",
       "BADUM JAMES P                    0.0        182466.0           257817.0   \n",
       "HUGHES JAMES A                 719.0             0.0          1118394.0   \n",
       "BHATNAGAR SANJAY               523.0      15456290.0                0.0   \n",
       "YEAP SOON                        0.0         55097.0           192758.0   \n",
       "HIRKO JOSEPH                     0.0         91093.0         30766064.0   \n",
       "HAYSLETT RODERICK J           2649.0             0.0           346663.0   \n",
       "FUGH JOHN L                      0.0         50591.0           176378.0   \n",
       "SAVAGE FRANK                     0.0          3750.0                0.0   \n",
       "GRAMM WENDY L                    0.0        119292.0                0.0   \n",
       "\n",
       "                         Fromfract   Tofract  SaltoPay  ESVtoTSV   RStoTSV  \n",
       "SKILLING JEFFREY K        0.814815  0.008271  0.127985  0.737727  0.262273  \n",
       "LAY KENNETH L             3.416667  0.003744  0.010355  0.699416  0.300584  \n",
       "FREVERT MARK A           11.523810  0.001832  0.061494  0.713540  0.286460  \n",
       "PICKERING MARK R          0.104478  0.000000  0.472375  1.000000  0.000000  \n",
       "WHALLEY LAWRENCE G        0.334532  0.003987  0.109109  0.540037  0.459963  \n",
       "DERRICK JR. JAMES V       0.070407  0.009170  0.893633  1.000000  0.202377  \n",
       "FASTOW ANDREW S           0.000000  0.000000  0.181800  0.000000  1.000000  \n",
       "SHERRIFF JOHN R           0.304348  0.007217  0.098902  0.586631  0.413369  \n",
       "RICE KENNETH D            2.333333  0.004420  0.832860  0.878081  0.121919  \n",
       "CAUSEY RICHARD A          1.183673  0.006342  0.222174  0.000000  1.000000  \n",
       "KEAN STEVEN J             0.020713  0.030343  0.231378  0.328594  0.671406  \n",
       "HAEDICKE MARK E           0.092736  0.015216  0.096947  0.758006  0.652687  \n",
       "MCMAHON JEFFREY           1.208333  0.011040  0.090358  0.663951  0.336049  \n",
       "METTS MARK                1.310345  0.001239  0.344489  0.000000  1.000000  \n",
       "DELAINEY DAVID W          0.021505  0.196896  0.076909  0.633909  0.366091  \n",
       "MCCONNELL MICHAEL S       0.033552  0.058276  0.173715  0.523336  0.476664  \n",
       "WALLS JR ROBERT H         0.116438  0.000000  0.198518  0.736828  0.263172  \n",
       "MARTIN AMANDA K           0.034783  0.000000  0.041571  1.000000  0.000000  \n",
       "LAVORATO JOHN J           0.204255  0.056619  0.032543  0.804892  0.195108  \n",
       "BUY RICHARD B             0.148148  0.020153  0.140317  0.738231  0.261769  \n",
       "OLSON CINDY K             0.384615  0.012669  0.249008  0.627995  0.372005  \n",
       "WHITE JR THOMAS E         0.000000  0.000000  0.164159  0.085647  0.914353  \n",
       "COX DAVID                 0.000000  0.039216  0.285355  0.237173  0.762827  \n",
       "KOENIG MARK E             0.868852  0.006318  0.195251  0.349853  0.650147  \n",
       "FALLON JAMES B            0.560000  0.021083  0.082851  0.403129  0.596871  \n",
       "SHANKMAN JEFFREY A        0.035062  0.025768  0.100079  0.695885  0.304115  \n",
       "UMANOFF ADAM S            0.666667  0.000000  0.255284  0.000000  0.000000  \n",
       "JACKSON CHARLENE R        0.446429  0.073643  0.523533  0.255001  0.744999  \n",
       "COLWELL WESLEY            6.000000  0.006257  0.193608  0.000000  1.000000  \n",
       "BOWEN JR RAYMOND M        5.185185  0.008073  0.104361  0.000000  1.000000  \n",
       "...                            ...       ...       ...       ...       ...  \n",
       "DUNCAN JOHN H             0.000000  0.000000  0.000000  1.000000  0.000000  \n",
       "LEMAISTRE CHARLES         0.000000  0.000000  0.000000  1.000000  0.000000  \n",
       "PIRO JIM                  0.000000  0.017241  0.000000  0.000000  1.000000  \n",
       "WROBEL BRUCE              0.000000  0.000000  0.000000  1.000000  0.000000  \n",
       "MEYER JEROME J            0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "MCDONALD REBECCA          4.153846  0.001119  0.000000  0.447745  0.552255  \n",
       "SCRIMSHAW MATTHEW         0.000000  0.000000  0.000000  1.000000  0.000000  \n",
       "GATHMANN WILLIAM D        0.000000  0.000000  0.000000  0.901512  0.135714  \n",
       "GILLIS JOHN               0.000000  0.000000  0.000000  0.114466  0.885534  \n",
       "MORAN MICHAEL P           0.000000  0.000000  0.000000  0.269235  0.730765  \n",
       "FOY JOE                   0.000000  0.000000  0.000000  1.000000  0.000000  \n",
       "PEREIRA PAULO V. FERRAZ   0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "BLAKE JR. NORMAN P        0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "SHERRICK JEFFREY B        1.560000  0.029364  0.000000  0.778441  0.221559  \n",
       "PRENTICE JAMES            0.000000  0.000000  0.000000  0.809314  0.190686  \n",
       "NOLES JAMES L             0.000000  0.000000  0.000000  0.000000  1.256454  \n",
       "FOWLER PEGGY              0.000000  0.000000  0.000000  0.702788  0.297212  \n",
       "CHRISTODOULOU DIOMEDES    0.000000  0.000000  0.000000  0.843576  0.156424  \n",
       "JAEDICKE ROBERT           0.000000  0.000000  0.000000  1.000000  0.102126  \n",
       "WINOKUR JR. HERBERT S     0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "BROWN MICHAEL             0.317073  0.000673  0.000000  0.000000  0.000000  \n",
       "BADUM JAMES P             0.000000  0.000000  0.000000  1.000000  0.000000  \n",
       "HUGHES JAMES A            1.029412  0.006954  0.000000  0.675045  0.324955  \n",
       "BHATNAGAR SANJAY          0.000000  0.001912  0.000000  0.000000  0.000000  \n",
       "YEAP SOON                 0.000000  0.000000  0.000000  1.000000  0.000000  \n",
       "HIRKO JOSEPH              0.000000  0.000000  0.000000  1.000000  0.000000  \n",
       "HAYSLETT RODERICK J       0.032988  0.014345  0.000000  0.000000  1.000000  \n",
       "FUGH JOHN L               0.000000  0.000000  0.000000  1.000000  0.000000  \n",
       "SAVAGE FRANK              0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "GRAMM WENDY L             0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "\n",
       "[143 rows x 26 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#need to recreate the df to drop Nans\n",
    "df2.fillna(0)\n",
    "#create new features list\n",
    "#features_list = df2.columns.values\n",
    "#restructure so that poi is first column so the featureformat function works properly\n",
    "#features_list.remove(\"poi\")\n",
    "#features_list.insert(0, \"poi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#conver float nan to string NaN, otherwise the featureformat function won't deal with it.\n",
    "df2 = df2.replace(np.nan, \"NaN\", regex=True)\n",
    "\n",
    "# create a dictionary from the dataframe\n",
    "data_dict = df2.to_dict('index')\n",
    "\n",
    "my_dataset = data_dict\n",
    "\n",
    "features_list = ['poi','salary', 'bonus', 'expenses', \"total_payments\", \"exercised_stock_options\",\n",
    "\"restricted_stock\", \"long_term_incentive\", \"deferral_payments\", \"deferred_income\", \"director_fees\",\n",
    "\"other\", \"shared_receipt_with_poi\", \"total_payments\", \"total_stock_value\", \"Fromfract\", \"Tofract\",\n",
    "\"SaltoPay\", \"ESVtoTSV\", \"RStoTSV\"]\n",
    "\n",
    "\n",
    "### Extract features and labels from dataset for local testing\n",
    "data = featureFormat(my_dataset, features_list, sort_keys = True)\n",
    "labels, features = targetFeatureSplit(data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#imports\n",
    "from sklearn.preprocessing import MinMaxScaler as MMS\n",
    "from sklearn import feature_selection\n",
    "from sklearn.feature_selection import chi2, f_classif, SelectKBest\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score, train_test_split, StratifiedShuffleSplit\n",
    "from sklearn.metrics import classification_report, precision_score, recall_score, f1_score, accuracy_score\n",
    "from pprint import pprint\n",
    "import timeit\n",
    "import numpy as np\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#feature importances overview was not possible\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.3, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.90697674418604646"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = GaussianNB().fit(X_train, y_train)\n",
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.88372093023255816"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = SVC().fit(X_train, y_train)\n",
    "clf.score(X_test, y_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.81395348837209303"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = DecisionTreeClassifier().fit(X_train, y_train)\n",
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.90697674418604646"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = RandomForestClassifier().fit(X_train, y_train)\n",
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initial results are promising!\n",
    "\n",
    "\n",
    "However, unfortunately, as mentioned by Myles on the forum, the incidence of PoI's in our dataset is 13%. put another way, it would be possible for an algorithim that simply returned NOT A PoI for every single point to achieve an accuracy score of 87%! This means that we should be using recall and precision scores to assess performance instead. For simplicity this will be abbreviated to F1 score (this can be embedded into gridsearch) and then expanded later to recall and precision prior to submission."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Feature Selection Test:Which is better- existing or new featureset? tested on decisiontree with default parameters\n",
    "\n",
    "#create default traintestsplit, featurelist, datadict\n",
    "default_features_list = ['poi','salary', 'bonus', 'expenses', \"total_payments\", \"exercised_stock_options\",\n",
    "\"restricted_stock\", \"long_term_incentive\", \"deferral_payments\", \"deferred_income\", \"director_fees\",\n",
    "\"other\", \"shared_receipt_with_poi\", \"total_payments\", \"total_stock_value\"]\n",
    "default_data =featureFormat(my_dataset, default_features_list, sort_keys = True)\n",
    "dlabels, dfeatures = targetFeatureSplit(default_data)\n",
    "dX_train, dX_test, dy_train, dy_test = train_test_split(dfeatures, dlabels, test_size=0.3, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#create scaler\n",
    "MMSs = MMS()\n",
    "#Create Transformers\n",
    "SKBt = SelectKBest()\n",
    "PCAt = PCA(random_state=42)\n",
    "FUt = FeatureUnion([(\"kbest\", SKBt), (\"pca\", PCAt)])\n",
    "#Create Classifiers\n",
    "GNBc = GaussianNB()\n",
    "SVCc = SVC(kernel=\"linear\", random_state=42)\n",
    "DTCc = DecisionTreeClassifier(random_state=42)\n",
    "RFc = RandomForestClassifier(random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\James2SxyBoogaloo\\Anaconda3\\envs\\py27\\lib\\site-packages\\sklearn\\metrics\\classification.py:1115: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Featureset:\n",
      "0.2525 Recall & 0.26 Precision\n",
      "Old Featureset:\n",
      "0.2075 Recall & 0.22 Precision\n",
      "All features for Updated Featurelist\n",
      "0 feature: salary (0.15157943172)\n",
      "1 feature: bonus (0.132620172679)\n",
      "2 feature: expenses (0.107681830387)\n",
      "3 feature: total_payments (0.086944516033)\n",
      "4 feature: exercised_stock_options (0.0850770882743)\n",
      "5 feature: restricted_stock (0.0768341892247)\n",
      "6 feature: long_term_incentive (0.0578261679248)\n",
      "7 feature: deferral_payments (0.0528884929341)\n",
      "8 feature: deferred_income (0.0491795048977)\n",
      "9 feature: director_fees (0.0465893504185)\n",
      "10 feature: other (0.032468398451)\n",
      "11 feature: shared_receipt_with_poi (0.027776646776)\n",
      "12 feature: total_payments (0.0264091310324)\n",
      "13 feature: total_stock_value (0.0198253318306)\n",
      "14 feature: Fromfract (0.0197769107643)\n",
      "15 feature: Tofract (0.0134790405578)\n",
      "16 feature: SaltoPay (0.00990093895183)\n",
      "17 feature: ESVtoTSV (0.00314285714286)\n",
      "18 feature: RStoTSV (0.0)\n",
      "All features for Default Featurelist\n",
      "0 feature: salary (0.175544188366)\n",
      "1 feature: bonus (0.14936279388)\n",
      "2 feature: expenses (0.123177433902)\n",
      "3 feature: total_payments (0.122743131649)\n",
      "4 feature: exercised_stock_options (0.0879840145662)\n",
      "5 feature: restricted_stock (0.0724505270535)\n",
      "6 feature: long_term_incentive (0.0599602972808)\n",
      "7 feature: deferral_payments (0.0440039743717)\n",
      "8 feature: deferred_income (0.0432044919262)\n",
      "9 feature: director_fees (0.0411053309637)\n",
      "10 feature: other (0.0393209723681)\n",
      "11 feature: shared_receipt_with_poi (0.0246160536685)\n",
      "12 feature: total_payments (0.0165267900047)\n",
      "13 feature: total_stock_value (0.0)\n"
     ]
    }
   ],
   "source": [
    "#Investigate most important features using SSS to ensure robust importance results.\n",
    "#Compare the results for both the default feature list and the feature list I created with my new ratios.\n",
    "#repurposed some of the code from tester.py \n",
    "from sklearn.cross_validation import StratifiedShuffleSplit\n",
    "\n",
    "#Cross validate and access Feature Importances on decisiontreeclassifier with 100 folds\n",
    "clf = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "cv = StratifiedShuffleSplit(labels, 100, random_state = 42)\n",
    "\n",
    "FeatureValue = np.zeros(len(features_list)-1)\n",
    "featrscore = np.zeros(len(features_list)-1)\n",
    "featpscore = np.zeros(len(features_list)-1)\n",
    "\n",
    "for train_idx, test_idx in cv: \n",
    "    features_train = []\n",
    "    features_test  = []\n",
    "    labels_train   = []\n",
    "    labels_test    = []\n",
    "    for ii in train_idx:\n",
    "        features_train.append( features[ii] )\n",
    "        labels_train.append( labels[ii] )\n",
    "    for jj in test_idx:\n",
    "        features_test.append( features[jj] )\n",
    "        labels_test.append( labels[jj] )\n",
    "\n",
    "    fit1 = clf.fit(features_train, labels_train)\n",
    "        #add values to list\n",
    "    FeatureValue += fit1.feature_importances_  \n",
    "    pred = clf.predict(features_test)\n",
    "    featrscore += recall_score(pred, labels_test)  \n",
    "    featpscore += precision_score(pred, labels_test)\n",
    "        \n",
    "clf2 = DecisionTreeClassifier(random_state=42)       \n",
    "\n",
    "\n",
    "FeatureValueDefault = np.zeros(len(default_features_list)-1)\n",
    "featrscored = np.zeros(len(features_list)-1)\n",
    "featpscored = np.zeros(len(features_list)-1)\n",
    "\n",
    "\n",
    "for train_idx, test_idx in cv: \n",
    "    dfeatures_train = []\n",
    "    dfeatures_test  = []\n",
    "    dlabels_train   = []\n",
    "    dlabels_test    = []\n",
    "    for ii in train_idx:\n",
    "        dfeatures_train.append( dfeatures[ii] )\n",
    "        dlabels_train.append( dlabels[ii] )\n",
    "    for jj in test_idx:\n",
    "        dfeatures_test.append( dfeatures[jj] )\n",
    "        dlabels_test.append( dlabels[jj] )\n",
    "\n",
    "    fit2 = clf2.fit(dfeatures_train, dlabels_train)\n",
    " \n",
    "    FeatureValueDefault += fit2.feature_importances_\n",
    "    pred2 = clf2.predict(dfeatures_test)\n",
    "    featrscored += recall_score(pred2, dlabels_test)  \n",
    "    featpscored += precision_score(pred2, dlabels_test)\n",
    "    \n",
    "    \n",
    "    \n",
    "#average over the 100 folds\n",
    "FeatureValue = FeatureValue/100\n",
    "featrscore = featrscore/100\n",
    "featpscore = featpscore/100\n",
    "\n",
    "FeatureValueDefault = FeatureValueDefault/100\n",
    "featrscored = featrscored/100\n",
    "featpscored = featpscored/100\n",
    "\n",
    "\n",
    "print \"New Featureset:\"\n",
    "print \"{} Recall & {} Precision\".format(featrscore[1], featpscore[1])\n",
    "\n",
    "\n",
    "print \"Old Featureset:\"\n",
    "print \"{} Recall & {} Precision\".format(featrscored[1], featpscored[1])\n",
    "\n",
    "ranks1 = np.argsort(FeatureValue)[::-1]\n",
    "print \"All features for Updated Featurelist\"\n",
    "for n in range(len(features_list)-1):\n",
    "    print \"{} feature: {} ({})\".format(n, features_list[n+1], FeatureValue[ranks1[n]])\n",
    "\n",
    "    ranks2 = np.argsort(FeatureValueDefault)[::-1]\n",
    "print \"All features for Default Featurelist\"\n",
    "for n in range(len(default_features_list)-1):\n",
    "    print \"{} feature: {} ({})\".format(n, default_features_list[n+1], FeatureValueDefault[ranks2[n]])  \n",
    "\n",
    "       \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " F1 score based on added features:\n",
      "0.909090909091\n",
      "F1 score with just the default features:\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "pred = fit1.predict(X_test)\n",
    "pred2 = fit2.predict(dX_test)\n",
    "\n",
    "acc = f1_score(pred, y_test)\n",
    "acc2 = f1_score(pred2, dy_test)\n",
    "\n",
    "print\" F1 score based on added features:\"\n",
    "print(acc)\n",
    "print\"F1 score with just the default features:\"\n",
    "print(acc2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These results are confusing - if we are getting perfect accuracy there is no need to do any tuning!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#create scaler\n",
    "MMSs = MMS()\n",
    "#Create Transformers\n",
    "SKBt = SelectKBest()\n",
    "PCAt = PCA(random_state=42)\n",
    "FUt = FeatureUnion([(\"kbest\", SKBt), (\"pca\", PCAt)])\n",
    "#Create Classifiers\n",
    "GNBc = GaussianNB()\n",
    "SVCc = SVC(kernel=\"linear\", random_state=42)\n",
    "DTCc = DecisionTreeClassifier(random_state=42)\n",
    "RFc = RandomForestClassifier(random_state=42)\n",
    "          "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Commentary on methodology.\n",
    "\n",
    "1. Scaler will be minmax scaler throughout, for each step. This is because there are so many values that are of different orders of magnitude, this will not interact well with some of the algorithims. For the same reason, this will precede feature selection. This will not change.\n",
    "2. I will begin by trying to work out the best Feature Selection Method for each algorithim I will use. This means that in the initial run, all algorithim parameters will be set to their defaults.\n",
    "3. I will do this by trying out SKB, PCA and FU for each classifier. This will include using both on their own.\n",
    "\n",
    "A = SKB only\n",
    "B = PCA only\n",
    "C = SKB then PCA\n",
    "D = PCA then SKB\n",
    "E = FeatureUnion\n",
    "\n",
    "1 = Gauss\n",
    "2 = SVC\n",
    "3 = DTC\n",
    "4 = RFC\n",
    "\n",
    "(all without parameters)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#GaussianNB featuresel Tests\n",
    "estpipe1A = [(\"MMSs\", MMSs), (\"SKBt\", SKBt), (\"GNBc\", GNBc)]\n",
    "pipe1A = Pipeline(estpipe1A)\n",
    "estpipe1B = [(\"MMSs\", MMSs), (\"PCAt\", PCAt), (\"GNBc\", GNBc)]\n",
    "pipe1B = Pipeline(estpipe1B)\n",
    "estpipe1C = [(\"MMSs\", MMSs), (\"SKBt\", SKBt), (\"PCAt\", PCAt), (\"GNBc\", GNBc)]\n",
    "pipe1C = Pipeline(estpipe1C)\n",
    "estpipe1D = [(\"MMSs\", MMSs), (\"PCAt\", PCAt), (\"SKBt\", SKBt), (\"GNBc\", GNBc)]\n",
    "pipe1D = Pipeline(estpipe1D)\n",
    "estpipe1E = [(\"MMSs\", MMSs), (\"FUt\", FUt), (\"GNBc\", GNBc)]\n",
    "pipe1E = Pipeline(estpipe1E)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#SVC Scaler featuresel tests\n",
    "estpipe2A = [(\"MMSs\", MMSs), (\"SKBt\", SKBt), (\"SVCc\", SVCc)]\n",
    "pipe2A = Pipeline(estpipe2A)\n",
    "estpipe2B = [(\"MMSs\", MMSs), (\"PCAt\", PCAt), (\"SVCc\", SVCc)]\n",
    "pipe2B = Pipeline(estpipe2B)\n",
    "estpipe2C = [(\"MMSs\", MMSs), (\"SKBt\", SKBt), (\"PCAt\", PCAt), (\"SVCc\", SVCc)]\n",
    "pipe2C = Pipeline(estpipe2C)\n",
    "estpipe2D = [(\"MMSs\", MMSs), (\"PCAt\", PCAt), (\"SKBt\", SKBt), (\"SVCc\", SVCc)]\n",
    "pipe2D = Pipeline(estpipe2D)\n",
    "estpipe2E = [(\"MMSs\", MMSs), (\"FUt\", FUt), (\"SVCc\", SVCc)]\n",
    "pipe2E = Pipeline(estpipe2E)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#DecisionTree featursel tests\n",
    "estpipe3A = [(\"MMSs\", MMSs), (\"SKBt\", SKBt), (\"DTCc\", DTCc)]\n",
    "pipe3A = Pipeline(estpipe3A)\n",
    "estpipe3B = [(\"MMSs\", MMSs), (\"PCAt\", PCAt), (\"DTCc\", DTCc)]\n",
    "pipe3B = Pipeline(estpipe3B)\n",
    "estpipe3C = [(\"MMSs\", MMSs), (\"SKBt\", SKBt), (\"PCAt\", PCAt), (\"DTCc\", DTCc)]\n",
    "pipe3C = Pipeline(estpipe3C)\n",
    "estpipe3D = [(\"MMSs\", MMSs), (\"PCAt\", PCAt), (\"SKBt\", SKBt), (\"DTCc\", DTCc)]\n",
    "pipe3D = Pipeline(estpipe3D)\n",
    "estpipe3E = [(\"MMSs\", MMSs), (\"FUt\", FUt), (\"DTCc\", DTCc)]\n",
    "pipe3E = Pipeline(estpipe3E)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#RFC featuresel tests\n",
    "estpipe4A = [(\"MMSs\", MMSs), (\"SKBt\", SKBt), (\"RFc\", RFc)]\n",
    "pipe4A = Pipeline(estpipe4A)\n",
    "estpipe4B = [(\"MMSs\", MMSs), (\"PCAt\", PCAt), (\"RFc\", RFc)]\n",
    "pipe4B = Pipeline(estpipe4B)\n",
    "estpipe4C = [(\"MMSs\", MMSs), (\"SKBt\", SKBt), (\"PCAt\", PCAt), (\"RFc\", RFc)]\n",
    "pipe4C = Pipeline(estpipe4C)\n",
    "estpipe4D = [(\"MMSs\", MMSs), (\"PCAt\", PCAt), (\"SKBt\", SKBt), (\"RFc\", RFc)]\n",
    "pipe4D = Pipeline(estpipe4D)\n",
    "estpipe4E = [(\"MMSs\", MMSs), (\"FUt\", FUt), (\"RFc\", RFc)]\n",
    "pipe4E = Pipeline(estpipe4E)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "estimatorsA = [estpipe1A, estpipe2A, estpipe3A, estpipe4A]\n",
    "pipesA = [pipe1A, pipe2A, pipe3A, pipe4A]\n",
    "estimatorsB = [estpipe1B, estpipe2B, estpipe3B, estpipe4B]\n",
    "pipesB = [pipe1B, pipe2B, pipe3B, pipe4B]\n",
    "estimatorsC = [estpipe1C, estpipe2C, estpipe3C, estpipe4C]\n",
    "pipesC = [pipe1C, pipe2C, pipe3C, pipe4C]\n",
    "estimatorsD = [estpipe1D, estpipe2D, estpipe3D, estpipe4D]\n",
    "pipesD = [pipe1D, pipe2D, pipe3D, pipe4D]\n",
    "estimatorsE = [estpipe1E, estpipe2E, estpipe3E, estpipe4E]\n",
    "pipesE = [pipe1E, pipe2E, pipe3E, pipe4E]\n",
    "\n",
    "\n",
    "algos = [\"GNB\", \"SVC\", \"DTC\", \"RF\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SKB only results across Algorithims\n",
      "('GNB', 'Recall:', 0.40000000000000002, 'Precision:', 0.40000000000000002, 'F1', 0.40000000000000008)\n",
      "('SVC', 'Recall:', 0.0, 'Precision:', 0.0, 'F1', 0.0)\n",
      "('DTC', 'Recall:', 0.20000000000000001, 'Precision:', 0.20000000000000001, 'F1', 0.20000000000000004)\n",
      "('RF', 'Recall:', 1.0, 'Precision:', 0.20000000000000001, 'F1', 0.33333333333333337)\n",
      "f1 average for comparison: 0.0833333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\James2SxyBoogaloo\\Anaconda3\\envs\\py27\\lib\\site-packages\\sklearn\\metrics\\classification.py:1115: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print \"SKB only results across Algorithims\"\n",
    "cnt= 0\n",
    "scorelist = []\n",
    "for estimator, pipe in zip(estimatorsA, pipesA):\n",
    "    clf = pipe.fit(X_train, y_train)\n",
    "    pred = clf.predict(X_test)\n",
    "    recall = recall_score(pred, y_test)\n",
    "    precision = precision_score(pred, y_test)\n",
    "    f1 = f1_score(pred, y_test)\n",
    "    print(algos[cnt], \"Recall:\", recall, \"Precision:\", precision, \"F1\", f1)\n",
    "    cnt+=1\n",
    "    \n",
    "scorelist.append(f1)\n",
    "comparator = (sum(scorelist)/4)\n",
    "\n",
    "print \"f1 average for comparison:\", comparator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA only results across Algorithims\n",
      "('GNB', 'Recall:', 0.2857142857142857, 'Precision:', 0.40000000000000002, 'F1', 0.33333333333333331)\n",
      "('SVC', 'Recall:', 0.0, 'Precision:', 0.0, 'F1', 0.0)\n",
      "('DTC', 'Recall:', 0.33333333333333331, 'Precision:', 0.59999999999999998, 'F1', 0.42857142857142855)\n",
      "('RF', 'Recall:', 1.0, 'Precision:', 0.20000000000000001, 'F1', 0.33333333333333337)\n",
      "f1 average for comparison: 0.0833333333333\n"
     ]
    }
   ],
   "source": [
    "print \"PCA only results across Algorithims\"\n",
    "cnt = 0\n",
    "scorelist = []\n",
    "for estimator, pipe in zip(estimatorsB, pipesB):\n",
    "    clf = pipe.fit(X_train, y_train)\n",
    "    pred = clf.predict(X_test)\n",
    "    recall = recall_score(pred, y_test)\n",
    "    precision = precision_score(pred, y_test)\n",
    "    f1 = f1_score(pred, y_test)\n",
    "    print(algos[cnt], \"Recall:\", recall, \"Precision:\", precision, \"F1\", f1)\n",
    "    cnt+=1\n",
    "    \n",
    "scorelist.append(f1)\n",
    "comparator = (sum(scorelist)/4)\n",
    "\n",
    "print \"f1 average for comparison:\", comparator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C = SKB then PCA\n",
      "('GNB', 'Recall:', 0.59999999999999998, 'Precision:', 0.59999999999999998, 'F1', 0.59999999999999998)\n",
      "('SVC', 'Recall:', 0.0, 'Precision:', 0.0, 'F1', 0.0)\n",
      "('DTC', 'Recall:', 0.33333333333333331, 'Precision:', 0.40000000000000002, 'F1', 0.36363636363636359)\n",
      "('RF', 'Recall:', 0.33333333333333331, 'Precision:', 0.20000000000000001, 'F1', 0.25)\n",
      "f1 average for comparison: 0.0625\n"
     ]
    }
   ],
   "source": [
    "print \"C = SKB then PCA\"\n",
    "cnt = 0\n",
    "scorelist = []\n",
    "for estimator, pipe in zip(estimatorsC, pipesC):\n",
    "    clf = pipe.fit(X_train, y_train)\n",
    "    pred = clf.predict(X_test)\n",
    "    recall = recall_score(pred, y_test)\n",
    "    precision = precision_score(pred, y_test)\n",
    "    f1 = f1_score(pred, y_test)\n",
    "    print(algos[cnt], \"Recall:\", recall, \"Precision:\", precision, \"F1\", f1)\n",
    "    cnt+=1\n",
    "\n",
    "scorelist.append(f1)\n",
    "comparator = (sum(scorelist)/4)\n",
    "\n",
    "print \"f1 average for comparison:\", comparator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D = PCA then SKB\n",
      "('GNB', 'Recall:', 0.5, 'Precision:', 0.40000000000000002, 'F1', 0.44444444444444448)\n",
      "('SVC', 'Recall:', 0.0, 'Precision:', 0.0, 'F1', 0.0)\n",
      "('DTC', 'Recall:', 0.40000000000000002, 'Precision:', 0.40000000000000002, 'F1', 0.40000000000000008)\n",
      "('RF', 'Recall:', 1.0, 'Precision:', 0.20000000000000001, 'F1', 0.33333333333333337)\n",
      "f1 average for comparison: 0.0833333333333\n"
     ]
    }
   ],
   "source": [
    "print \"D = PCA then SKB\"\n",
    "cnt = 0\n",
    "scorelist = []\n",
    "for estimator, pipe in zip(estimatorsD, pipesD):\n",
    "    clf = pipe.fit(X_train, y_train)\n",
    "    pred = clf.predict(X_test)\n",
    "    recall = recall_score(pred, y_test)\n",
    "    precision = precision_score(pred, y_test)\n",
    "    f1 = f1_score(pred, y_test)\n",
    "    print(algos[cnt], \"Recall:\", recall, \"Precision:\", precision, \"F1\", f1)\n",
    "    cnt+=1\n",
    "\n",
    "scorelist.append(f1)\n",
    "comparator = (sum(scorelist)/4)\n",
    "\n",
    "print \"f1 average for comparison:\", comparator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E = FeatureUnion\n",
      "('GNB', 'Recall:', 0.40000000000000002, 'Precision:', 0.40000000000000002, 'F1', 0.40000000000000008)\n",
      "('SVC', 'Recall:', 0.5, 'Precision:', 0.20000000000000001, 'F1', 0.28571428571428575)\n",
      "('DTC', 'Recall:', 0.375, 'Precision:', 0.59999999999999998, 'F1', 0.46153846153846151)\n",
      "('RF', 'Recall:', 0.33333333333333331, 'Precision:', 0.20000000000000001, 'F1', 0.25)\n",
      "f1 average for comparison: 0.349313186813\n"
     ]
    }
   ],
   "source": [
    "print\"E = FeatureUnion\"\n",
    "cnt = 0\n",
    "scorelist = []\n",
    "for estimator, pipe in zip(estimatorsE, pipesE):\n",
    "    clf = pipe.fit(X_train, y_train)\n",
    "    pred = clf.predict(X_test)\n",
    "    recall = recall_score(pred, y_test)\n",
    "    precision = precision_score(pred, y_test)\n",
    "    f1 = f1_score(pred, y_test)\n",
    "    print(algos[cnt], \"Recall:\", recall, \"Precision:\", precision, \"F1\", f1)\n",
    "    cnt+=1\n",
    "    scorelist.append(f1)\n",
    "comparator = (sum(scorelist)/4)\n",
    "\n",
    "print \"f1 average for comparison:\", comparator\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The primary thing here appears to be that, on average across the four chosen algorithims, using a train_test_split and MinMax Scaling, and default parameters, the FeatureUnion approach is the most accurate. By outputting each of the scores, this gives us a further starting point for subsequent investigation - RF in particular seems to get perfect recall for the PCA and PCA followed by SKB approach. So whilst the immediate intention is to focus on the Feature Union approach due to its consistency, we might circle back on the RF/PCA combination later.\n",
    "\n",
    "Whilst the purpose of this step was to decide on the best featureselection parameters going forward, it would be remiss not to remark on how the GNB classifier has performed - it's actually exceeded the R/P requirements of the project in for each slection method other than PCA / Recall. This doesn't mean it will prove to be the most effective algorithim overall, however it does validate my decision to show the outputs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we've found Feature Union Generalises best on average.\n",
    "\n",
    "OK so after doing that we have our optimum featsel parameters for each algo:\n",
    "    \n",
    "    \n",
    "    Gauss: PCA 9  SKB 5\n",
    "    SVC: PCA1 SKB 6\n",
    "    DTREE: PCA 14 SKB 1\n",
    "    Rforest: PCA 2 SKB 9\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#runner document\n",
    "\n",
    "#create featureunion object\n",
    "combined = FeatureUnion([(\"pca\", PCAt), (\"skb\", SKBt)])\n",
    "\n",
    "#create pipelines, one for each object. Note MMS included.\n",
    "Pipe = Pipeline([(\"MMS\", MMSs),\n",
    "                (\"combined\", combined),\n",
    "                 (\"clf\", GNBc)])\n",
    "\n",
    "Pipe2 = Pipeline([(\"MMS\", MMSs),\n",
    "                (\"combined\", combined),\n",
    "                 (\"clf\", SVCc)])\n",
    "\n",
    "Pipe3 = Pipeline([(\"MMS\", MMSs),\n",
    "                (\"combined\", combined),\n",
    "                 (\"clf\", DTCc)])\n",
    "\n",
    "Pipe4 = Pipeline([(\"MMS\", MMSs),\n",
    "                (\"combined\", combined),\n",
    "                 (\"clf\", RFc)])\n",
    "\n",
    "#Gauss\n",
    "prm_grid = dict(combined__pca__n_components=[9],\n",
    "               combined__skb__k=[5])\n",
    "#SVC\n",
    "prm_grid2 = dict(combined__pca__n_components=[1],\n",
    "               combined__skb__k=[6],\n",
    "                clf__C = [1.2],\n",
    "               clf__kernel = [\"linear\"],\n",
    "                clf__class_weight = [\"balanced\", None])\n",
    "#Dtree\n",
    "prm_grid3 = dict(combined__pca__n_components=[6],\n",
    "               combined__skb__k=[6],\n",
    "                clf__criterion=[\"gini\"],\n",
    "                clf__max_features=[\"auto\"],\n",
    "                clf__max_depth = [9],\n",
    "                clf__class_weight = [\"balanced\"],\n",
    "                clf__min_samples_split = [6],\n",
    "                clf__splitter = [\"random\"])\n",
    "\n",
    "#Rforest\n",
    "prm_grid4 = dict(combined__pca__n_components=[5],\n",
    "               combined__skb__k=[5],\n",
    "                clf__criterion=[\"gini\"],\n",
    "                clf__max_features=[None],\n",
    "                clf__max_depth = [5],\n",
    "                clf__class_weight = [\"balanced\"],\n",
    "                clf__min_samples_split = [15],\n",
    "                clf__n_estimators = [5]\n",
    "                )    \n",
    "    \n",
    "cv_sss = StratifiedShuffleSplit(labels, 10, test_size=0.3, random_state=42)\n",
    "\n",
    "\n",
    "#create a gridsearch object for each algorithim, using a different pipe\n",
    "grid = GridSearchCV(Pipe, prm_grid, cv = cv_sss, scoring =\"f1\")\n",
    "grid2 = GridSearchCV(Pipe2, prm_grid2, cv = cv_sss, scoring =\"f1\")\n",
    "grid3 = GridSearchCV(Pipe3, prm_grid3, cv = cv_sss, scoring =\"f1\")\n",
    "grid4 = GridSearchCV(Pipe4, prm_grid4, cv = cv_sss, scoring =\"f1\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cell above was ran and reran repeatedly to set up each iteration of the parameter grid. I have documented this\n",
    "process in the Outputs Notebook, together with the results for each parameter run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time Taken:  0.16396773910105603\n",
      "Best F1 Score:\n",
      "0.3613997114\n",
      "Best parameters:\n",
      "\tcombined__pca__n_components: 9\n",
      "\tcombined__skb__k: 5\n"
     ]
    }
   ],
   "source": [
    "#GAUSS APPLICATIoN\n",
    "start_time = timeit.default_timer()\n",
    "grid.fit(features, labels)\n",
    "print(\"Time Taken:  %r\" % (timeit.default_timer() - start_time))\n",
    "print \"Best F1 Score:\"\n",
    "print(grid.best_score_)\n",
    "print \"Best parameters:\"\n",
    "best_parameters = grid.best_estimator_.get_params()\n",
    "for param_name in sorted(prm_grid.keys()):\n",
    "       print '\\t%s: %r' % (param_name, best_parameters[param_name])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time Taken:  0.16062445160308253\n",
      "Best F1 Score:\n",
      "0.3613997114\n",
      "Best parameters:\n",
      "\tcombined__pca__n_components: 9\n",
      "\tcombined__skb__k: 5\n"
     ]
    }
   ],
   "source": [
    "#SVC TUNER\n",
    "start_time = timeit.default_timer()\n",
    "grid.fit(features, labels)\n",
    "print(\"Time Taken:  %r\" % (timeit.default_timer() - start_time))\n",
    "#print \"Best Estimator:\"\n",
    "#print(grid.best_estimator_)\n",
    "print \"Best F1 Score:\"\n",
    "print(grid.best_score_)\n",
    "print \"Best parameters:\"\n",
    "best_parameters = grid.best_estimator_.get_params()\n",
    "for param_name in sorted(prm_grid.keys()):\n",
    "       print '\\t%s: %r' % (param_name, best_parameters[param_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time Taken:  0.19925727410997268\n",
      "Best F1 Score:\n",
      "0.41497665733\n",
      "Best parameters:\n",
      "\tclf__class_weight: 'balanced'\n",
      "\tclf__criterion: 'gini'\n",
      "\tclf__max_depth: 9\n",
      "\tclf__max_features: 'auto'\n",
      "\tclf__min_samples_split: 6\n",
      "\tclf__splitter: 'random'\n",
      "\tcombined__pca__n_components: 6\n",
      "\tcombined__skb__k: 6\n"
     ]
    }
   ],
   "source": [
    "#DTREE tuner\n",
    "start_time = timeit.default_timer()\n",
    "grid3.fit(features, labels)\n",
    "print(\"Time Taken:  %r\" % (timeit.default_timer() - start_time))\n",
    "#print \"Best Estimator:\"\n",
    "#print(grid.best_estimator_)\n",
    "print \"Best F1 Score:\"\n",
    "print(grid3.best_score_)\n",
    "print \"Best parameters:\"\n",
    "best_parameters = grid3.best_estimator_.get_params()\n",
    "for param_name in sorted(prm_grid3.keys()):\n",
    "       print '\\t%s: %r' % (param_name, best_parameters[param_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time Taken:  0.43641101830733\n",
      "Best F1 Score:\n",
      "0.397475465711\n",
      "Best parameters:\n",
      "\tclf__class_weight: 'balanced'\n",
      "\tclf__criterion: 'gini'\n",
      "\tclf__max_depth: 5\n",
      "\tclf__max_features: None\n",
      "\tclf__min_samples_split: 15\n",
      "\tclf__n_estimators: 5\n",
      "\tcombined__pca__n_components: 5\n",
      "\tcombined__skb__k: 5\n"
     ]
    }
   ],
   "source": [
    "#Random Forest Classifer\n",
    "start_time = timeit.default_timer()\n",
    "grid4.fit(features, labels)\n",
    "print(\"Time Taken:  %r\" % (timeit.default_timer() - start_time))\n",
    "#print \"Best Estimator:\"\n",
    "#print(grid.best_estimator_)\n",
    "print \"Best F1 Score:\"\n",
    "print(grid4.best_score_)\n",
    "print \"Best parameters:\"\n",
    "best_parameters = grid4.best_estimator_.get_params()\n",
    "for param_name in sorted(prm_grid4.keys()):\n",
    "       print '\\t%s: %r' % (param_name, best_parameters[param_name])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RESULTS OF PARAMETER TUNING:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The parameter tuner that got the highest F1 score was\n",
    "    \n",
    "Decision Tree Classifier, with the following parameters:\n",
    "\n",
    "Best parameters:\n",
    "\tclf__class_weight: 'balanced'\n",
    "\tclf__criterion: 'gini'\n",
    "\tclf__max_depth: 9\n",
    "\tclf__max_features: 'auto'\n",
    "\tclf__min_samples_split: 6\n",
    "\tclf__splitter: 'random'\n",
    "\tcombined__pca__n_components: 6\n",
    "\tcombined__skb__k: 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tester Classification Report\n",
      "Pipeline(steps=[('MMS', MinMaxScaler(copy=True, feature_range=(0, 1))), ('combined', FeatureUnion(n_jobs=1,\n",
      "       transformer_list=[('pca', PCA(copy=True, iterated_power='auto', n_components=6, random_state=42,\n",
      "  svd_solver='auto', tol=0.0, whiten=False)), ('skb', SelectKBest(k=6, score_func=<function f_cla...it=6, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=42, splitter='random'))])\n",
      "\tAccuracy: 0.74373\tPrecision: 0.26002\tRecall: 0.49950\tF1: 0.34201\tF2: 0.42180\n",
      "\tTotal predictions: 15000\tTrue positives:  999\tFalse positives: 2843\tFalse negatives: 1001\tTrue negatives: 10157\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = grid3.best_estimator_\n",
    "#import test_classifier\n",
    "from tester import test_classifier\n",
    "print \"Tester Classification Report\"\n",
    "test_classifier(clf, my_dataset, features_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately, whilst recall is sufficient, we are let down by precision.\n",
    "\n",
    "Let's try our RandomForest Classifier - whilst overall F1 score was lower, maybe recall was over 0.3?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tester Classification Report\n",
      "Pipeline(steps=[('MMS', MinMaxScaler(copy=True, feature_range=(0, 1))), ('combined', FeatureUnion(n_jobs=1,\n",
      "       transformer_list=[('pca', PCA(copy=True, iterated_power='auto', n_components=5, random_state=42,\n",
      "  svd_solver='auto', tol=0.0, whiten=False)), ('skb', SelectKBest(k=5, score_func=<function f_cla...estimators=5, n_jobs=1,\n",
      "            oob_score=False, random_state=42, verbose=0, warm_start=False))])\n",
      "\tAccuracy: 0.80767\tPrecision: 0.33358\tRecall: 0.44350\tF1: 0.38077\tF2: 0.41608\n",
      "\tTotal predictions: 15000\tTrue positives:  887\tFalse positives: 1772\tFalse negatives: 1113\tTrue negatives: 11228\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = grid4.best_estimator_\n",
    "#import test_classifier\n",
    "from tester import test_classifier\n",
    "print \"Tester Classification Report\"\n",
    "test_classifier(clf, my_dataset, features_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After several days of second guessing, we have a winner!\n",
    "\n",
    "Phew!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion and Discussion:\n",
    "\n",
    "Feature selection and importances was handled by Gridsearch - I was unable to pick out the specifics of each feature used because of the decision to use FeatureUnion. I couldn't locate documentation showing the methods to use that would allow me to extract the feature importances / feature scores from a FeatureUnion Object.\n",
    "\n",
    "\n",
    "As mentioned above, MinMaxScaler was chosen because of the wide variance in the dataset.\n",
    "\n",
    "The rationale behind the features I created is basically that there might be information hidden in the ratios between certain features, rather than the features themselves.\n",
    "\n",
    "I ended up using the RandomForest Classifier due to the fact it met the required Recall and Precision scores.\n",
    "\n",
    "I tried the SVC, DecisionTree, Gaussian Naive Bayes and Random Forest algorithims. Gaussian Naive Bayes was the most accurate and wouldn't have required any tuning to meet requirements, according to the preliminary test (f1 score). The test I added just below this text box actually confirms that this is more accurate for  precision, and sufficient (but lower) on recall than the RandomForest Classifier I spent several days tuning.\n",
    "\n",
    "In this context, the importance of parameter tuning appears to be secondary to picking the best algorithim. However in the attached outputs notebook i have attempted to show the process I went through for SVC DTREE and RFOREST classifiers.\n",
    "\n",
    "The primary aid in getting a good result appears to be setting up as wide a parameter search as possible for your initial run, leaving it overnight, and then iterating on that. Running on a more restriceted paramter space in 30 second increments means that you are having to guess about what adjustments to make, and it's a very trial and error approach. This was demonstrated by my decision to go back and tune PCA and SKB, despite initially intending to keep these values as a constant for each algorithim. Parameters were chosen by scanning SKLearn and picking ones that sounded relevant from the list.\n",
    "\n",
    "Validation is the process of checking that your algorithim actually works. This can be done by manually splitting data into the training and test sets, but this leaves the problem of reducing your dataset. As our data is already unbalanced, this can cause performace problems as the classifier is trying to infer information about a very small subsample of the data as it is, without further reducing it. A classic mistake is to train and validate on the same data - this would only measure the bias of your classifer and tell you nothing about it's ability to make predicitions.\n",
    "\n",
    "I validated my analysis by using GridsearchCV's built in CrossValidation StratifiedShuffleSplit method, where subsamples of test and training data are taken from the data a specified number of times, and the results averaged across each test. The stratified sampling approach ensures that each \"fold\" (test) contains roughly equal numbers of each class, in this case meaning that the number of PoIs showing up in each test will be more similar than if it was entirely random, thus helping the algorithim generalise.\n",
    "\n",
    "Analysis of result:\n",
    "\n",
    "This is the  output showing the performance of my chosen classifier\n",
    "\n",
    "Accuracy: 0.80767\tPrecision: 0.33358\tRecall: 0.44350\tF1: 0.38077\tF2: 0.41608\n",
    "\tTotal predictions: 15000\tTrue positives:  887\tFalse positives: 1772\tFalse negatives: 1113\tTrue negatives: 11228\n",
    "\n",
    "Accuracy - the most intuitive output metric. Defined technically as\n",
    "\n",
    "(True positive plus True Negative) /  Total Predictions\n",
    "\n",
    "or alternatively, out of every guess made by the classifier, what proportion was correct? How good is it at correctly determining if someone is a PoI or not?\n",
    "\n",
    "For the reasons given above this is not a useful metric in this context.\n",
    "\n",
    "\n",
    "Precision  = True positives / (True Positives + False Positives)\n",
    "\n",
    "When the classifier identifies someone as a POI, how sure can we be that it is correct?\n",
    "\n",
    "If this is high, we can be confident that anyone flagged as a PoI is actually a PoI.\n",
    "If this is low, this means that we are flagging people as PoIs mistakenly.\n",
    "\n",
    "In this case my precision score was 0.33 which means we are getting lots of false positives.\n",
    "\n",
    "Recall = True Positives / ( True Positives + False Negatives)\n",
    "\n",
    "If this is high, we are able to track down a large percentage of the actual PoIs in the data.\n",
    "If this is low then we often miss real PoIs because the algo is overly cautious.\n",
    "\n",
    "Recall was 0.44 which means that we were also missing real PoIs.\n",
    "\n",
    "It is important to use the full range of validation metrics - if we only looked at accuracy, we would have an unduly high confidence about our ability to make predictions.  Recall and Precision are both independent of any imbalances in the dataset, unlike Accuracy.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tester Classification Report\n",
      "Pipeline(steps=[('MMS', MinMaxScaler(copy=True, feature_range=(0, 1))), ('combined', FeatureUnion(n_jobs=1,\n",
      "       transformer_list=[('pca', PCA(copy=True, iterated_power='auto', n_components=9, random_state=42,\n",
      "  svd_solver='auto', tol=0.0, whiten=False)), ('skb', SelectKBest(k=5, score_func=<function f_classif at 0x000000000CE39F98>))],\n",
      "       transformer_weights=None)), ('clf', GaussianNB(priors=None))])\n",
      "\tAccuracy: 0.84240\tPrecision: 0.40441\tRecall: 0.38500\tF1: 0.39447\tF2: 0.38873\n",
      "\tTotal predictions: 15000\tTrue positives:  770\tFalse positives: 1134\tFalse negatives: 1230\tTrue negatives: 11866\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Gaussian N\n",
    "clf = grid.best_estimator_\n",
    "#import test_classifier\n",
    "from tester import test_classifier\n",
    "print \"Tester Classification Report\"\n",
    "test_classifier(clf, my_dataset, features_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Final Test: How did the inclusion of my new features affect the performance of my final algorithim?\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time Taken:  0.43426786149643704\n",
      "Best F1 Score:\n",
      "0.293097343833\n",
      "Best parameters:\n",
      "\tclf__class_weight: 'balanced'\n",
      "\tclf__criterion: 'gini'\n",
      "\tclf__max_depth: 5\n",
      "\tclf__max_features: None\n",
      "\tclf__min_samples_split: 15\n",
      "\tclf__n_estimators: 5\n",
      "\tcombined__pca__n_components: 5\n",
      "\tcombined__skb__k: 5\n",
      "Tester Classification Report\n",
      "Pipeline(steps=[('MMS', MinMaxScaler(copy=True, feature_range=(0, 1))), ('combined', FeatureUnion(n_jobs=1,\n",
      "       transformer_list=[('pca', PCA(copy=True, iterated_power='auto', n_components=5, random_state=42,\n",
      "  svd_solver='auto', tol=0.0, whiten=False)), ('skb', SelectKBest(k=5, score_func=<function f_cla...estimators=5, n_jobs=1,\n",
      "            oob_score=False, random_state=42, verbose=0, warm_start=False))])\n",
      "\tAccuracy: 0.76573\tPrecision: 0.24391\tRecall: 0.36050\tF1: 0.29096\tF2: 0.32904\n",
      "\tTotal predictions: 15000\tTrue positives:  721\tFalse positives: 2235\tFalse negatives: 1279\tTrue negatives: 10765\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Rforest\n",
    "start_time = timeit.default_timer()\n",
    "grid4.fit(dfeatures, dlabels)\n",
    "print(\"Time Taken:  %r\" % (timeit.default_timer() - start_time))\n",
    "#print \"Best Estimator:\"\n",
    "#print(grid.best_estimator_)\n",
    "print \"Best F1 Score:\"\n",
    "print(grid4.best_score_)\n",
    "print \"Best parameters:\"\n",
    "best_parameters = grid4.best_estimator_.get_params()\n",
    "for param_name in sorted(prm_grid4.keys()):\n",
    "       print '\\t%s: %r' % (param_name, best_parameters[param_name])\n",
    "\n",
    "\n",
    "clf = grid4.best_estimator_\n",
    "#import test_classifier\n",
    "from tester import test_classifier\n",
    "print \"Tester Classification Report\"\n",
    "test_classifier(clf, my_dataset, default_features_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#28/07/2017 RESUBMISSIoN - Output from Testing Notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
