{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Featureset:\n",
      "0.2525 Recall & 0.26 Precision\n",
      "Old Featureset:\n",
      "0.2075 Recall & 0.22 Precision\n",
      "All features for Updated Featurelist\n",
      "0 feature: salary (0.15157943172)\n",
      "1 feature: bonus (0.132620172679)\n",
      "2 feature: expenses (0.107681830387)\n",
      "3 feature: total_payments (0.086944516033)\n",
      "4 feature: exercised_stock_options (0.0850770882743)\n",
      "5 feature: restricted_stock (0.0768341892247)\n",
      "6 feature: long_term_incentive (0.0578261679248)\n",
      "7 feature: deferral_payments (0.0528884929341)\n",
      "8 feature: deferred_income (0.0491795048977)\n",
      "9 feature: director_fees (0.0465893504185)\n",
      "10 feature: other (0.032468398451)\n",
      "11 feature: shared_receipt_with_poi (0.027776646776)\n",
      "12 feature: total_payments (0.0264091310324)\n",
      "13 feature: total_stock_value (0.0198253318306)\n",
      "14 feature: Fromfract (0.0197769107643)\n",
      "15 feature: Tofract (0.0134790405578)\n",
      "16 feature: SaltoPay (0.00990093895183)\n",
      "17 feature: ESVtoTSV (0.00314285714286)\n",
      "18 feature: RStoTSV (0.0)\n",
      "All features for Default Featurelist\n",
      "0 feature: salary (0.175544188366)\n",
      "1 feature: bonus (0.14936279388)\n",
      "2 feature: expenses (0.123177433902)\n",
      "3 feature: total_payments (0.122743131649)\n",
      "4 feature: exercised_stock_options (0.0879840145662)\n",
      "5 feature: restricted_stock (0.0724505270535)\n",
      "6 feature: long_term_incentive (0.0599602972808)\n",
      "7 feature: deferral_payments (0.0440039743717)\n",
      "8 feature: deferred_income (0.0432044919262)\n",
      "9 feature: director_fees (0.0411053309637)\n",
      "10 feature: other (0.0393209723681)\n",
      "11 feature: shared_receipt_with_poi (0.0246160536685)\n",
      "12 feature: total_payments (0.0165267900047)\n",
      "13 feature: total_stock_value (0.0)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import pickle\n",
    "import pandas\n",
    "import numpy as np\n",
    "sys.path.append(\"../tools/\")\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler as MMS\n",
    "from sklearn import feature_selection\n",
    "from sklearn.feature_selection import chi2, f_classif, SelectKBest\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score, train_test_split, StratifiedShuffleSplit\n",
    "from sklearn.metrics import classification_report, precision_score, recall_score, f1_score, accuracy_score\n",
    "from pprint import pprint\n",
    "import timeit\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from feature_format import featureFormat, targetFeatureSplit\n",
    "from tester import dump_classifier_and_data\n",
    "\n",
    "with open(\"final_project_dataset.pkl\", \"r\") as data_file:\n",
    "    data_dict = pickle.load(data_file)\n",
    "    \n",
    "       \n",
    "#convert from dict to df\n",
    "df = pandas.DataFrame.from_dict(list(data_dict.values()),dtype=\"float64\")\n",
    "employees = pandas.Series(list(data_dict.keys()))\n",
    "df.set_index(employees, inplace=True)        \n",
    "df2 = df.sort_values(by='salary', ascending=0)       \n",
    "\n",
    "\n",
    "#remove outliers\n",
    "df2 = df2.drop({\"LOCKHART EUGENE E\"})\n",
    "df2 = df2.drop([\"TOTAL\"])\n",
    "df2 = df2.drop([\"THE TRAVEL AGENCY IN THE PARK\"])        \n",
    "        \n",
    "        \n",
    "#create new features       \n",
    "df2[\"Fromfract\"] = df2.from_poi_to_this_person.divide(df2.from_messages, axis=\"index\").fillna(0)\n",
    "df2[\"Tofract\"] = df2.from_this_person_to_poi.divide(df2.to_messages, axis=\"index\").fillna(0)\n",
    "df2[\"SaltoPay\"] = df2.salary.divide(df2.total_payments, axis=\"index\").fillna(0)\n",
    "df2[\"ESVtoTSV\"] = df2.exercised_stock_options.divide(df2.total_stock_value, axis=\"index\").fillna(0)\n",
    "df2[\"RStoTSV\"] = df2.restricted_stock.divide(df2.total_stock_value, axis=\"index\").fillna(0)\n",
    "\n",
    "\n",
    "#conver float nan to string NaN, otherwise the featureformat function won't deal with it.\n",
    "df2 = df2.replace(np.nan, \"NaN\", regex=True)\n",
    "\n",
    "# create a dictionary from the dataframe\n",
    "data_dict = df2.to_dict('index')\n",
    "\n",
    "my_dataset = data_dict\n",
    "\n",
    "#this is my new featurelist including the 5 new features I made\n",
    "features_list = ['poi','salary', 'bonus', 'expenses', \"total_payments\", \"exercised_stock_options\",\n",
    "\"restricted_stock\", \"long_term_incentive\", \"deferral_payments\", \"deferred_income\", \"director_fees\",\n",
    "\"other\", \"shared_receipt_with_poi\", \"total_payments\", \"total_stock_value\", \"Fromfract\", \"Tofract\",\n",
    "\"SaltoPay\", \"ESVtoTSV\", \"RStoTSV\"]\n",
    "\n",
    "### Extract features and labels from dataset for local testing\n",
    "data = featureFormat(my_dataset, features_list, sort_keys = True)\n",
    "labels, features = targetFeatureSplit(data)\n",
    "\n",
    "\n",
    "\n",
    "###\n",
    "#create default featurelist, datadict for comparison\n",
    "default_features_list = ['poi','salary', 'bonus', 'expenses', \"total_payments\", \"exercised_stock_options\",\n",
    "\"restricted_stock\", \"long_term_incentive\", \"deferral_payments\", \"deferred_income\", \"director_fees\",\n",
    "\"other\", \"shared_receipt_with_poi\", \"total_payments\", \"total_stock_value\"]\n",
    "#passing in the above list means that the new features are ignored\n",
    "default_data =featureFormat(my_dataset, default_features_list, sort_keys = True)\n",
    "#default features, default labels\n",
    "dlabels, dfeatures = targetFeatureSplit(default_data)\n",
    "dX_train, dX_test, dy_train, dy_test = train_test_split(dfeatures, dlabels, test_size=0.3, random_state=42)\n",
    "\n",
    "#Investigate most important features using SSS to ensure robust importance results.\n",
    "#Compare the results for both the default feature list and the feature list I created with my new ratios.\n",
    "#repurposed some of the code from tester.py \n",
    "from sklearn.cross_validation import StratifiedShuffleSplit\n",
    "\n",
    "#Cross validate and access Feature Importances on decisiontreeclassifier with 100 folds\n",
    "clf = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "cv = StratifiedShuffleSplit(labels, 100, random_state = 42)\n",
    "\n",
    "FeatureValue = np.zeros(len(features_list)-1)\n",
    "featrscore = np.zeros(len(features_list)-1)\n",
    "featpscore = np.zeros(len(features_list)-1)\n",
    "\n",
    "for train_idx, test_idx in cv: \n",
    "    features_train = []\n",
    "    features_test  = []\n",
    "    labels_train   = []\n",
    "    labels_test    = []\n",
    "    for ii in train_idx:\n",
    "        features_train.append( features[ii] )\n",
    "        labels_train.append( labels[ii] )\n",
    "    for jj in test_idx:\n",
    "        features_test.append( features[jj] )\n",
    "        labels_test.append( labels[jj] )\n",
    "\n",
    "    fit1 = clf.fit(features_train, labels_train)\n",
    "        #add values to list\n",
    "    FeatureValue += fit1.feature_importances_  \n",
    "    pred = clf.predict(features_test)\n",
    "    featrscore += recall_score(pred, labels_test)  \n",
    "    featpscore += precision_score(pred, labels_test)\n",
    "        \n",
    "clf2 = DecisionTreeClassifier(random_state=42)       \n",
    "\n",
    "\n",
    "FeatureValueDefault = np.zeros(len(default_features_list)-1)\n",
    "featrscored = np.zeros(len(features_list)-1)\n",
    "featpscored = np.zeros(len(features_list)-1)\n",
    "\n",
    "\n",
    "for train_idx, test_idx in cv: \n",
    "    dfeatures_train = []\n",
    "    dfeatures_test  = []\n",
    "    dlabels_train   = []\n",
    "    dlabels_test    = []\n",
    "    for ii in train_idx:\n",
    "        dfeatures_train.append( dfeatures[ii] )\n",
    "        dlabels_train.append( dlabels[ii] )\n",
    "    for jj in test_idx:\n",
    "        dfeatures_test.append( dfeatures[jj] )\n",
    "        dlabels_test.append( dlabels[jj] )\n",
    "\n",
    "    fit2 = clf2.fit(dfeatures_train, dlabels_train)\n",
    " \n",
    "    FeatureValueDefault += fit2.feature_importances_\n",
    "    pred2 = clf2.predict(dfeatures_test)\n",
    "    featrscored += recall_score(pred2, dlabels_test)  \n",
    "    featpscored += precision_score(pred2, dlabels_test)\n",
    "    \n",
    "    \n",
    "    \n",
    "#average over the 100 folds\n",
    "FeatureValue = FeatureValue/100\n",
    "featrscore = featrscore/100\n",
    "featpscore = featpscore/100\n",
    "\n",
    "FeatureValueDefault = FeatureValueDefault/100\n",
    "featrscored = featrscored/100\n",
    "featpscored = featpscored/100\n",
    "\n",
    "\n",
    "print \"New Featureset:\"\n",
    "print \"{} Recall & {} Precision\".format(featrscore[1], featpscore[1])\n",
    "\n",
    "\n",
    "print \"Old Featureset:\"\n",
    "print \"{} Recall & {} Precision\".format(featrscored[1], featpscored[1])\n",
    "\n",
    "ranks1 = np.argsort(FeatureValue)[::-1]\n",
    "print \"All features for Updated Featurelist\"\n",
    "for n in range(len(features_list)-1):\n",
    "    print \"{} feature: {} ({})\".format(n, features_list[n+1], FeatureValue[ranks1[n]])\n",
    "\n",
    "    ranks2 = np.argsort(FeatureValueDefault)[::-1]\n",
    "print \"All features for Default Featurelist\"\n",
    "for n in range(len(default_features_list)-1):\n",
    "    print \"{} feature: {} ({})\".format(n, default_features_list[n+1], FeatureValueDefault[ranks2[n]])  \n",
    "\n",
    "       \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#create scaler\n",
    "MMSs = MMS()\n",
    "#Create Transformers\n",
    "SKBt = SelectKBest(k=6)\n",
    "PCAt = PCA(random_state=42)\n",
    "FUt = FeatureUnion([(\"kbest\", SKBt), (\"pca\", PCAt)])\n",
    "#Create Classifiers\n",
    "GNBc = GaussianNB()\n",
    "SVCc = SVC(kernel=\"linear\", random_state=42)\n",
    "DTCc = DecisionTreeClassifier(random_state=42)\n",
    "RFc = RandomForestClassifier(random_state=42)\n",
    "\n",
    "#create pipelines, one for each object. Note MMS included.\n",
    "Pipe = Pipeline([(\"MMS\", MMSs),\n",
    "                (\"SKB\", SKBt),\n",
    "                 (\"clf\", GNBc)])\n",
    "\n",
    "Pipe2 = Pipeline([(\"MMS\", MMSs),\n",
    "                (\"SKB\", SKBt),\n",
    "                 (\"clf\", SVCc)])\n",
    "\n",
    "Pipe3 = Pipeline([(\"MMS\", MMSs),\n",
    "                (\"SKB\", SKBt),\n",
    "                 (\"clf\", DTCc)])\n",
    "\n",
    "Pipe4 = Pipeline([(\"MMS\", MMSs),\n",
    "                (\"SKB\", SKBt),\n",
    "                 (\"clf\", RFc)])\n",
    "\n",
    "#Test Grid goes here\n",
    "prm_grid = dict(\n",
    "                ) \n",
    "#####\n",
    "\n",
    "cv_sss = StratifiedShuffleSplit(labels, 10, test_size=0.3, random_state=42)\n",
    "\n",
    "\n",
    "#create a gridsearch object for each algorithim, using a different pipe\n",
    "grid = GridSearchCV(Pipe, prm_grid, cv = cv_sss, scoring =\"f1\")\n",
    "grid2 = GridSearchCV(Pipe2, prm_grid, cv = cv_sss, scoring =\"f1\")\n",
    "grid3 = GridSearchCV(Pipe3, prm_grid, cv = cv_sss, scoring =\"f1\")\n",
    "grid4 = GridSearchCV(Pipe4, prm_grid, cv = cv_sss, scoring =\"f1\")\n",
    "\n",
    "\n",
    "#apply the grid to the data\n",
    "start_time = timeit.default_timer()\n",
    "grid.fit(features, labels)\n",
    "print(\"with n_splits=10 done in  %r\" % (timeit.default_timer() - start_time))\n",
    "#print \"Best Estimator:\"\n",
    "#print(grid.best_estimator_)\n",
    "print \"Best F1 Score:\"\n",
    "print(grid.best_score_)\n",
    "print \"Best parameters:\"\n",
    "best_parameters = grid.best_estimator_.get_params()\n",
    "for param_name in sorted(prm_grid.keys()):\n",
    "       print '\\t%s: %r' % (param_name, best_parameters[param_name])\n",
    "        \n",
    "#from pprint import pprint\n",
    "#pprint(grid4.cv_results_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf = grid.best_estimator_\n",
    "#import test_classifier\n",
    "from tester import test_classifier\n",
    "print \"Tester Classification Report\"\n",
    "test_classifier(clf, my_dataset, features_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
